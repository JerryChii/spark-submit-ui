2016-08-19 14:00:55,030 - [INFO] - from play in pool-4-thread-2 
Listening for HTTP on /0:0:0:0:0:0:0:0:9000

2016-08-19 14:01:31,021 - [INFO] - from play in play-internal-execution-context-1 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:01:31,576 - [INFO] - from play in play-internal-execution-context-1 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:01:31,757 - [INFO] - from play in play-internal-execution-context-1 
Application started (Dev)

2016-08-19 14:02:42,208 - [INFO] - from play in play-internal-execution-context-1 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:02:42,925 - [INFO] - from play in play-internal-execution-context-1 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:02:42,934 - [INFO] - from play in play-internal-execution-context-1 
Application started (Dev)

2016-08-19 14:05:16,250 - [INFO] - from play in play-internal-execution-context-1 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:05:16,922 - [INFO] - from play in play-internal-execution-context-1 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:05:16,929 - [INFO] - from play in play-internal-execution-context-1 
Application started (Dev)

2016-08-19 14:05:39,014 - [INFO] - from play in play-internal-execution-context-2 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:05:39,551 - [INFO] - from play in play-internal-execution-context-2 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:05:39,557 - [INFO] - from play in play-internal-execution-context-2 
Application started (Dev)

2016-08-19 14:06:38,541 - [INFO] - from play in play-internal-execution-context-2 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:06:40,841 - [INFO] - from play in play-internal-execution-context-2 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:06:40,847 - [INFO] - from play in play-internal-execution-context-2 
Application started (Dev)

2016-08-19 14:48:52,796 - [INFO] - from play in play-internal-execution-context-2 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:48:53,136 - [INFO] - from play in play-internal-execution-context-2 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:48:53,142 - [INFO] - from play in play-internal-execution-context-2 
Application started (Dev)

2016-08-19 14:52:33,040 - [INFO] - from play in play-internal-execution-context-3 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:52:33,390 - [INFO] - from play in play-internal-execution-context-3 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:52:33,397 - [INFO] - from play in play-internal-execution-context-3 
Application started (Dev)

2016-08-19 14:52:52,956 - [INFO] - from play in play-internal-execution-context-3 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:52:53,440 - [INFO] - from play in play-internal-execution-context-3 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:52:53,446 - [INFO] - from play in play-internal-execution-context-3 
Application started (Dev)

2016-08-19 14:53:27,897 - [INFO] - from play in play-internal-execution-context-3 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:53:28,203 - [INFO] - from play in play-internal-execution-context-3 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:53:28,209 - [INFO] - from play in play-internal-execution-context-3 
Application started (Dev)

2016-08-19 14:53:58,270 - [INFO] - from play in play-internal-execution-context-3 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:53:58,742 - [INFO] - from play in play-internal-execution-context-3 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:53:58,747 - [INFO] - from play in play-internal-execution-context-3 
Application started (Dev)

2016-08-19 14:55:02,046 - [INFO] - from play in play-internal-execution-context-3 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:55:02,549 - [INFO] - from play in play-internal-execution-context-3 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 14:55:02,557 - [INFO] - from play in play-internal-execution-context-3 
Application started (Dev)

2016-08-19 14:57:30,125 - [ERROR] - from application in play-akka.actor.default-dispatcher-72 


! @715im547f - Internal server error, for (GET) [/UserResource?queueName=normal&mem=223+mb&cpu=465+vcores&apps=897] ->

play.api.Application$$anon$1: Execution exception[[FileNotFoundException: tmp/fair-scheduler.xml (No such file or directory)]]
	at play.api.Application$class.handleError(Application.scala:293) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.DefaultApplication.handleError(Application.scala:399) [play_2.10-2.2.6.jar:2.2.6]
	at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$13$$anonfun$apply$1.applyOrElse(PlayDefaultUpstreamHandler.scala:170) [play_2.10-2.2.6.jar:2.2.6]
	at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$13$$anonfun$apply$1.applyOrElse(PlayDefaultUpstreamHandler.scala:167) [play_2.10-2.2.6.jar:2.2.6]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) [scala-library-2.10.4.jar:na]
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:185) [scala-library-2.10.4.jar:na]
	at scala.util.Try$.apply(Try.scala:161) [scala-library-2.10.4.jar:na]
	at scala.util.Failure.recover(Try.scala:185) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [scala-library-2.10.4.jar:na]
	at play.api.libs.iteratee.Execution$$anon$1.execute(Execution.scala:43) [play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Promise$class.complete(Promise.scala:55) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [scala-library-2.10.4.jar:na]
	at play.api.libs.iteratee.Execution$$anon$2.execute(Execution.scala:70) [play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Promise$class.complete(Promise.scala:55) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) [scala-library-2.10.4.jar:na]
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:42) [akka-actor_2.10-2.2.0.jar:2.2.0]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386) [akka-actor_2.10-2.2.0.jar:2.2.0]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library-2.10.4.jar:na]
Caused by: java.io.FileNotFoundException: tmp/fair-scheduler.xml (No such file or directory)
	at java.io.FileInputStream.open0(Native Method) ~[na:1.8.0_45]
	at java.io.FileInputStream.open(FileInputStream.java:195) ~[na:1.8.0_45]
	at java.io.FileInputStream.<init>(FileInputStream.java:138) ~[na:1.8.0_45]
	at java.io.FileInputStream.<init>(FileInputStream.java:93) ~[na:1.8.0_45]
	at scala.xml.Source$.fromFile(XML.scala:21) ~[scala-library-2.10.4.jar:na]
	at scala.xml.factory.XMLLoader$class.loadFile(XMLLoader.scala:49) ~[scala-library-2.10.4.jar:na]
	at scala.xml.XML$.loadFile(XML.scala:57) ~[scala-library-2.10.4.jar:na]
	at models.utils.XmlParse$.XMLParses(XmlParse.scala:35) ~[classes/:na]
	at controllers.Yarn$$anonfun$UserResource$1$$anonfun$apply$5$$anonfun$apply$6.apply(Yarn.scala:26) ~[classes/:na]
	at controllers.Yarn$$anonfun$UserResource$1$$anonfun$apply$5$$anonfun$apply$6.apply(Yarn.scala:25) ~[classes/:na]
	at controllers.Secured$$anonfun$IsAuthenticated$3$$anonfun$apply$1.apply(Secured.scala:27) ~[classes/:na]
	at controllers.Secured$$anonfun$IsAuthenticated$3$$anonfun$apply$1.apply(Secured.scala:27) ~[classes/:na]
	at play.api.mvc.ActionBuilder$$anonfun$apply$10.apply(Action.scala:221) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.ActionBuilder$$anonfun$apply$10.apply(Action.scala:220) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$.invokeBlock(Action.scala:357) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.ActionBuilder$$anon$1.apply(Action.scala:309) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4$$anonfun$apply$5.apply(Action.scala:109) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4$$anonfun$apply$5.apply(Action.scala:109) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.utils.Threads$.withContextClassLoader(Threads.scala:18) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4.apply(Action.scala:108) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4.apply(Action.scala:107) ~[play_2.10-2.2.6.jar:2.2.6]
	at scala.Option.map(Option.scala:145) ~[scala-library-2.10.4.jar:na]
	at play.api.mvc.Action$$anonfun$apply$1.apply(Action.scala:107) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1.apply(Action.scala:100) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$mapM$1.apply(Iteratee.scala:481) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$mapM$1.apply(Iteratee.scala:481) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMapM$1.apply(Iteratee.scala:517) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMapM$1.apply(Iteratee.scala:517) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMap$1$$anonfun$apply$13.apply(Iteratee.scala:493) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMap$1$$anonfun$apply$13.apply(Iteratee.scala:493) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) [scala-library-2.10.4.jar:na]
	... 6 common frames omitted

2016-08-19 14:57:44,135 - [ERROR] - from application in play-akka.actor.default-dispatcher-89 


! @715im5p10 - Internal server error, for (GET) [/UserResource?queueName=default&mem=836+mb&cpu=465+vcores&apps=732] ->

play.api.Application$$anon$1: Execution exception[[FileNotFoundException: tmp/fair-scheduler.xml (No such file or directory)]]
	at play.api.Application$class.handleError(Application.scala:293) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.DefaultApplication.handleError(Application.scala:399) [play_2.10-2.2.6.jar:2.2.6]
	at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$13$$anonfun$apply$1.applyOrElse(PlayDefaultUpstreamHandler.scala:170) [play_2.10-2.2.6.jar:2.2.6]
	at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$13$$anonfun$apply$1.applyOrElse(PlayDefaultUpstreamHandler.scala:167) [play_2.10-2.2.6.jar:2.2.6]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) [scala-library-2.10.4.jar:na]
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:185) [scala-library-2.10.4.jar:na]
	at scala.util.Try$.apply(Try.scala:161) [scala-library-2.10.4.jar:na]
	at scala.util.Failure.recover(Try.scala:185) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [scala-library-2.10.4.jar:na]
	at play.api.libs.iteratee.Execution$$anon$1.execute(Execution.scala:43) [play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Promise$class.complete(Promise.scala:55) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [scala-library-2.10.4.jar:na]
	at play.api.libs.iteratee.Execution$$anon$2.execute(Execution.scala:70) [play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Promise$class.complete(Promise.scala:55) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) [scala-library-2.10.4.jar:na]
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:42) [akka-actor_2.10-2.2.0.jar:2.2.0]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386) [akka-actor_2.10-2.2.0.jar:2.2.0]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library-2.10.4.jar:na]
Caused by: java.io.FileNotFoundException: tmp/fair-scheduler.xml (No such file or directory)
	at java.io.FileInputStream.open0(Native Method) ~[na:1.8.0_45]
	at java.io.FileInputStream.open(FileInputStream.java:195) ~[na:1.8.0_45]
	at java.io.FileInputStream.<init>(FileInputStream.java:138) ~[na:1.8.0_45]
	at java.io.FileInputStream.<init>(FileInputStream.java:93) ~[na:1.8.0_45]
	at scala.xml.Source$.fromFile(XML.scala:21) ~[scala-library-2.10.4.jar:na]
	at scala.xml.factory.XMLLoader$class.loadFile(XMLLoader.scala:49) ~[scala-library-2.10.4.jar:na]
	at scala.xml.XML$.loadFile(XML.scala:57) ~[scala-library-2.10.4.jar:na]
	at models.utils.XmlParse$.XMLParses(XmlParse.scala:35) ~[classes/:na]
	at controllers.Yarn$$anonfun$UserResource$1$$anonfun$apply$5$$anonfun$apply$6.apply(Yarn.scala:26) ~[classes/:na]
	at controllers.Yarn$$anonfun$UserResource$1$$anonfun$apply$5$$anonfun$apply$6.apply(Yarn.scala:25) ~[classes/:na]
	at controllers.Secured$$anonfun$IsAuthenticated$3$$anonfun$apply$1.apply(Secured.scala:27) ~[classes/:na]
	at controllers.Secured$$anonfun$IsAuthenticated$3$$anonfun$apply$1.apply(Secured.scala:27) ~[classes/:na]
	at play.api.mvc.ActionBuilder$$anonfun$apply$10.apply(Action.scala:221) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.ActionBuilder$$anonfun$apply$10.apply(Action.scala:220) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$.invokeBlock(Action.scala:357) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.ActionBuilder$$anon$1.apply(Action.scala:309) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4$$anonfun$apply$5.apply(Action.scala:109) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4$$anonfun$apply$5.apply(Action.scala:109) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.utils.Threads$.withContextClassLoader(Threads.scala:18) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4.apply(Action.scala:108) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4.apply(Action.scala:107) ~[play_2.10-2.2.6.jar:2.2.6]
	at scala.Option.map(Option.scala:145) ~[scala-library-2.10.4.jar:na]
	at play.api.mvc.Action$$anonfun$apply$1.apply(Action.scala:107) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1.apply(Action.scala:100) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$mapM$1.apply(Iteratee.scala:481) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$mapM$1.apply(Iteratee.scala:481) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMapM$1.apply(Iteratee.scala:517) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMapM$1.apply(Iteratee.scala:517) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMap$1$$anonfun$apply$13.apply(Iteratee.scala:493) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMap$1$$anonfun$apply$13.apply(Iteratee.scala:493) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) [scala-library-2.10.4.jar:na]
	... 6 common frames omitted

2016-08-19 14:59:23,389 - [INFO] - from application in play-akka.actor.default-dispatcher-106 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:04:16,253 - [INFO] - from application in play-akka.actor.default-dispatcher-107 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:04:38,654 - [INFO] - from play in play-internal-execution-context-10 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:04:39,067 - [INFO] - from play in play-internal-execution-context-10 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:04:39,072 - [INFO] - from play in play-internal-execution-context-10 
Application started (Dev)

2016-08-19 15:04:50,912 - [INFO] - from application in play-akka.actor.default-dispatcher-115 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:05:05,903 - [INFO] - from application in play-akka.actor.default-dispatcher-111 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:05:05,906 - [INFO] - from application in play-akka.actor.default-dispatcher-111 
文件类型不正确!

2016-08-19 15:05:30,799 - [INFO] - from play in play-internal-execution-context-14 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:05:31,152 - [INFO] - from play in play-internal-execution-context-14 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:05:31,157 - [INFO] - from play in play-internal-execution-context-14 
Application started (Dev)

2016-08-19 15:05:42,524 - [INFO] - from application in play-akka.actor.default-dispatcher-122 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:05:42,552 - [INFO] - from application in play-akka.actor.default-dispatcher-122 
文件类型不正确!

2016-08-19 15:06:25,121 - [INFO] - from application in play-akka.actor.default-dispatcher-120 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:06:35,958 - [INFO] - from application in play-akka.actor.default-dispatcher-120 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:06:57,477 - [INFO] - from application in play-akka.actor.default-dispatcher-119 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:06:57,477 - [INFO] - from application in play-akka.actor.default-dispatcher-119 
文件类型不正确!

2016-08-19 15:07:45,491 - [INFO] - from play in play-internal-execution-context-25 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:07:45,981 - [INFO] - from play in play-internal-execution-context-25 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:07:45,986 - [INFO] - from play in play-internal-execution-context-25 
Application started (Dev)

2016-08-19 15:07:54,787 - [INFO] - from application in play-akka.actor.default-dispatcher-129 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:07:54,816 - [INFO] - from application in play-akka.actor.default-dispatcher-129 
文件类型不正确!

2016-08-19 15:09:09,326 - [INFO] - from application in play-akka.actor.default-dispatcher-127 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:09:50,041 - [INFO] - from play in play-internal-execution-context-29 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:09:50,479 - [INFO] - from play in play-internal-execution-context-29 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:09:50,485 - [INFO] - from play in play-internal-execution-context-29 
Application started (Dev)

2016-08-19 15:10:00,847 - [INFO] - from application in play-akka.actor.default-dispatcher-138 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:10:06,983 - [INFO] - from application in play-akka.actor.default-dispatcher-135 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:10:06,986 - [INFO] - from application in play-akka.actor.default-dispatcher-135 
文件类型不正确!

2016-08-19 15:10:16,526 - [INFO] - from application in play-akka.actor.default-dispatcher-138 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:10:40,611 - [INFO] - from play in play-internal-execution-context-36 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:10:41,161 - [INFO] - from play in play-internal-execution-context-36 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:10:41,167 - [INFO] - from play in play-internal-execution-context-36 
Application started (Dev)

2016-08-19 15:10:52,305 - [INFO] - from application in play-akka.actor.default-dispatcher-134 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:10:57,101 - [INFO] - from application in play-akka.actor.default-dispatcher-144 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:10:57,103 - [INFO] - from application in play-akka.actor.default-dispatcher-144 
文件类型不正确!

2016-08-19 15:11:46,698 - [INFO] - from play in play-internal-execution-context-41 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:11:47,165 - [INFO] - from play in play-internal-execution-context-41 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:11:47,171 - [INFO] - from play in play-internal-execution-context-41 
Application started (Dev)

2016-08-19 15:11:55,174 - [INFO] - from application in play-akka.actor.default-dispatcher-148 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:11:55,198 - [INFO] - from application in play-akka.actor.default-dispatcher-148 
文件类型不正确!

2016-08-19 15:12:05,130 - [INFO] - from application in play-akka.actor.default-dispatcher-140 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:12:11,727 - [INFO] - from application in play-akka.actor.default-dispatcher-143 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:12:18,109 - [INFO] - from application in play-akka.actor.default-dispatcher-140 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:12:18,109 - [INFO] - from application in play-akka.actor.default-dispatcher-140 
文件类型不正确!

2016-08-19 15:12:31,353 - [INFO] - from application in play-akka.actor.default-dispatcher-143 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:13:43,468 - [INFO] - from play in play-internal-execution-context-51 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:13:46,845 - [INFO] - from play in play-internal-execution-context-51 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:13:46,853 - [INFO] - from play in play-internal-execution-context-51 
Application started (Dev)

2016-08-19 15:14:03,156 - [INFO] - from application in play-akka.actor.default-dispatcher-152 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:14:09,600 - [INFO] - from application in play-akka.actor.default-dispatcher-152 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:14:09,602 - [INFO] - from application in play-akka.actor.default-dispatcher-152 
文件类型不正确!

2016-08-19 15:15:26,304 - [INFO] - from play in play-internal-execution-context-51 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:15:27,901 - [INFO] - from play in play-internal-execution-context-51 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:15:27,906 - [INFO] - from play in play-internal-execution-context-51 
Application started (Dev)

2016-08-19 15:22:02,836 - [INFO] - from application in play-akka.actor.default-dispatcher-172 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:22:09,478 - [INFO] - from application in play-akka.actor.default-dispatcher-172 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 15:22:09,481 - [INFO] - from application in play-akka.actor.default-dispatcher-172 
文件类型不正确!

2016-08-19 15:23:36,324 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:23:40,496 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:23:40,503 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 15:24:36,529 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:24:37,410 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:24:37,418 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 15:31:13,270 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:31:14,164 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 15:31:14,171 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 15:31:26,386 - [ERROR] - from application in play-akka.actor.default-dispatcher-201 


! @715j0h0dl - Internal server error, for (GET) [/UserResource?queueName=normal&mem=223+mb&cpu=465+vcores&apps=897] ->

play.api.Application$$anon$1: Execution exception[[FileNotFoundException: tmp/fair-scheduler.xml (No such file or directory)]]
	at play.api.Application$class.handleError(Application.scala:293) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.DefaultApplication.handleError(Application.scala:399) [play_2.10-2.2.6.jar:2.2.6]
	at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$13$$anonfun$apply$1.applyOrElse(PlayDefaultUpstreamHandler.scala:170) [play_2.10-2.2.6.jar:2.2.6]
	at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$13$$anonfun$apply$1.applyOrElse(PlayDefaultUpstreamHandler.scala:167) [play_2.10-2.2.6.jar:2.2.6]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) [scala-library-2.10.4.jar:na]
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:185) [scala-library-2.10.4.jar:na]
	at scala.util.Try$.apply(Try.scala:161) [scala-library-2.10.4.jar:na]
	at scala.util.Failure.recover(Try.scala:185) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [scala-library-2.10.4.jar:na]
	at play.api.libs.iteratee.Execution$$anon$1.execute(Execution.scala:43) [play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Promise$class.complete(Promise.scala:55) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [scala-library-2.10.4.jar:na]
	at play.api.libs.iteratee.Execution$$anon$2.execute(Execution.scala:70) [play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Promise$class.complete(Promise.scala:55) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) [scala-library-2.10.4.jar:na]
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:42) [akka-actor_2.10-2.2.0.jar:2.2.0]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386) [akka-actor_2.10-2.2.0.jar:2.2.0]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library-2.10.4.jar:na]
Caused by: java.io.FileNotFoundException: tmp/fair-scheduler.xml (No such file or directory)
	at java.io.FileInputStream.open0(Native Method) ~[na:1.8.0_45]
	at java.io.FileInputStream.open(FileInputStream.java:195) ~[na:1.8.0_45]
	at java.io.FileInputStream.<init>(FileInputStream.java:138) ~[na:1.8.0_45]
	at java.io.FileInputStream.<init>(FileInputStream.java:93) ~[na:1.8.0_45]
	at scala.xml.Source$.fromFile(XML.scala:21) ~[scala-library-2.10.4.jar:na]
	at scala.xml.factory.XMLLoader$class.loadFile(XMLLoader.scala:49) ~[scala-library-2.10.4.jar:na]
	at scala.xml.XML$.loadFile(XML.scala:57) ~[scala-library-2.10.4.jar:na]
	at models.utils.XmlParse$.XMLParses(XmlParse.scala:35) ~[classes/:na]
	at controllers.Yarn$$anonfun$UserResource$1$$anonfun$apply$5$$anonfun$apply$6.apply(Yarn.scala:26) ~[classes/:na]
	at controllers.Yarn$$anonfun$UserResource$1$$anonfun$apply$5$$anonfun$apply$6.apply(Yarn.scala:25) ~[classes/:na]
	at controllers.Secured$$anonfun$IsAuthenticated$3$$anonfun$apply$1.apply(Secured.scala:27) ~[classes/:na]
	at controllers.Secured$$anonfun$IsAuthenticated$3$$anonfun$apply$1.apply(Secured.scala:27) ~[classes/:na]
	at play.api.mvc.ActionBuilder$$anonfun$apply$10.apply(Action.scala:221) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.ActionBuilder$$anonfun$apply$10.apply(Action.scala:220) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$.invokeBlock(Action.scala:357) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.ActionBuilder$$anon$1.apply(Action.scala:309) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4$$anonfun$apply$5.apply(Action.scala:109) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4$$anonfun$apply$5.apply(Action.scala:109) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.utils.Threads$.withContextClassLoader(Threads.scala:18) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4.apply(Action.scala:108) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4.apply(Action.scala:107) ~[play_2.10-2.2.6.jar:2.2.6]
	at scala.Option.map(Option.scala:145) ~[scala-library-2.10.4.jar:na]
	at play.api.mvc.Action$$anonfun$apply$1.apply(Action.scala:107) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1.apply(Action.scala:100) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$mapM$1.apply(Iteratee.scala:481) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$mapM$1.apply(Iteratee.scala:481) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMapM$1.apply(Iteratee.scala:517) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMapM$1.apply(Iteratee.scala:517) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMap$1$$anonfun$apply$13.apply(Iteratee.scala:493) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMap$1$$anonfun$apply$13.apply(Iteratee.scala:493) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) [scala-library-2.10.4.jar:na]
	... 6 common frames omitted

2016-08-19 16:08:18,444 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:08:19,870 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:08:19,877 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:10:39,773 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:10:42,596 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:10:42,602 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:12:53,173 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:12:54,138 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:12:54,144 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:15:20,821 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:15:21,774 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:15:21,782 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:17:16,997 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:17:20,253 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:17:20,258 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:20:13,709 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:20:14,143 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:20:14,149 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:20:57,789 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:20:58,848 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:20:58,854 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:21:36,390 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:21:37,575 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:21:37,581 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:25:00,681 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:25:02,321 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:25:02,327 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:25:49,292 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:25:50,412 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:25:50,418 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:26:54,791 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:26:55,914 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:26:55,918 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:27:12,882 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:27:13,642 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:27:13,648 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:28:58,577 - [ERROR] - from application in play-akka.actor.default-dispatcher-297 


! @715j85b8b - Internal server error, for (GET) [/UserResource?queueName=normal&mem=223+mb&cpu=465+vcores&apps=897] ->

play.api.Application$$anon$1: Execution exception[[FileNotFoundException: tmp/fair-scheduler.xml (No such file or directory)]]
	at play.api.Application$class.handleError(Application.scala:293) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.DefaultApplication.handleError(Application.scala:399) [play_2.10-2.2.6.jar:2.2.6]
	at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$13$$anonfun$apply$1.applyOrElse(PlayDefaultUpstreamHandler.scala:170) [play_2.10-2.2.6.jar:2.2.6]
	at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$13$$anonfun$apply$1.applyOrElse(PlayDefaultUpstreamHandler.scala:167) [play_2.10-2.2.6.jar:2.2.6]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) [scala-library-2.10.4.jar:na]
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:185) [scala-library-2.10.4.jar:na]
	at scala.util.Try$.apply(Try.scala:161) [scala-library-2.10.4.jar:na]
	at scala.util.Failure.recover(Try.scala:185) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [scala-library-2.10.4.jar:na]
	at play.api.libs.iteratee.Execution$$anon$1.execute(Execution.scala:43) [play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Promise$class.complete(Promise.scala:55) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [scala-library-2.10.4.jar:na]
	at play.api.libs.iteratee.Execution$$anon$2.execute(Execution.scala:70) [play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Promise$class.complete(Promise.scala:55) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) [scala-library-2.10.4.jar:na]
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:42) [akka-actor_2.10-2.2.0.jar:2.2.0]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386) [akka-actor_2.10-2.2.0.jar:2.2.0]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library-2.10.4.jar:na]
Caused by: java.io.FileNotFoundException: tmp/fair-scheduler.xml (No such file or directory)
	at java.io.FileInputStream.open0(Native Method) ~[na:1.8.0_45]
	at java.io.FileInputStream.open(FileInputStream.java:195) ~[na:1.8.0_45]
	at java.io.FileInputStream.<init>(FileInputStream.java:138) ~[na:1.8.0_45]
	at java.io.FileInputStream.<init>(FileInputStream.java:93) ~[na:1.8.0_45]
	at scala.xml.Source$.fromFile(XML.scala:21) ~[scala-library-2.10.4.jar:na]
	at scala.xml.factory.XMLLoader$class.loadFile(XMLLoader.scala:49) ~[scala-library-2.10.4.jar:na]
	at scala.xml.XML$.loadFile(XML.scala:57) ~[scala-library-2.10.4.jar:na]
	at models.utils.XmlParse$.XMLParses(XmlParse.scala:35) ~[classes/:na]
	at controllers.Yarn$$anonfun$UserResource$1$$anonfun$apply$5$$anonfun$apply$6.apply(Yarn.scala:26) ~[classes/:na]
	at controllers.Yarn$$anonfun$UserResource$1$$anonfun$apply$5$$anonfun$apply$6.apply(Yarn.scala:25) ~[classes/:na]
	at controllers.Secured$$anonfun$IsAuthenticated$3$$anonfun$apply$1.apply(Secured.scala:27) ~[classes/:na]
	at controllers.Secured$$anonfun$IsAuthenticated$3$$anonfun$apply$1.apply(Secured.scala:27) ~[classes/:na]
	at play.api.mvc.ActionBuilder$$anonfun$apply$10.apply(Action.scala:221) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.ActionBuilder$$anonfun$apply$10.apply(Action.scala:220) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$.invokeBlock(Action.scala:357) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.ActionBuilder$$anon$1.apply(Action.scala:309) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4$$anonfun$apply$5.apply(Action.scala:109) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4$$anonfun$apply$5.apply(Action.scala:109) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.utils.Threads$.withContextClassLoader(Threads.scala:18) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4.apply(Action.scala:108) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4.apply(Action.scala:107) ~[play_2.10-2.2.6.jar:2.2.6]
	at scala.Option.map(Option.scala:145) ~[scala-library-2.10.4.jar:na]
	at play.api.mvc.Action$$anonfun$apply$1.apply(Action.scala:107) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1.apply(Action.scala:100) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$mapM$1.apply(Iteratee.scala:481) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$mapM$1.apply(Iteratee.scala:481) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMapM$1.apply(Iteratee.scala:517) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMapM$1.apply(Iteratee.scala:517) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMap$1$$anonfun$apply$13.apply(Iteratee.scala:493) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMap$1$$anonfun$apply$13.apply(Iteratee.scala:493) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) [scala-library-2.10.4.jar:na]
	... 6 common frames omitted

2016-08-19 16:29:03,558 - [ERROR] - from application in play-akka.actor.default-dispatcher-311 


! @715j85ii1 - Internal server error, for (GET) [/UserResource?queueName=default&mem=223+mb&cpu=465+vcores&apps=897] ->

play.api.Application$$anon$1: Execution exception[[FileNotFoundException: tmp/fair-scheduler.xml (No such file or directory)]]
	at play.api.Application$class.handleError(Application.scala:293) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.DefaultApplication.handleError(Application.scala:399) [play_2.10-2.2.6.jar:2.2.6]
	at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$13$$anonfun$apply$1.applyOrElse(PlayDefaultUpstreamHandler.scala:170) [play_2.10-2.2.6.jar:2.2.6]
	at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$13$$anonfun$apply$1.applyOrElse(PlayDefaultUpstreamHandler.scala:167) [play_2.10-2.2.6.jar:2.2.6]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) [scala-library-2.10.4.jar:na]
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:185) [scala-library-2.10.4.jar:na]
	at scala.util.Try$.apply(Try.scala:161) [scala-library-2.10.4.jar:na]
	at scala.util.Failure.recover(Try.scala:185) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [scala-library-2.10.4.jar:na]
	at play.api.libs.iteratee.Execution$$anon$1.execute(Execution.scala:43) [play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Promise$class.complete(Promise.scala:55) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [scala-library-2.10.4.jar:na]
	at play.api.libs.iteratee.Execution$$anon$2.execute(Execution.scala:70) [play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248) [scala-library-2.10.4.jar:na]
	at scala.concurrent.Promise$class.complete(Promise.scala:55) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) [scala-library-2.10.4.jar:na]
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:42) [akka-actor_2.10-2.2.0.jar:2.2.0]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386) [akka-actor_2.10-2.2.0.jar:2.2.0]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library-2.10.4.jar:na]
Caused by: java.io.FileNotFoundException: tmp/fair-scheduler.xml (No such file or directory)
	at java.io.FileInputStream.open0(Native Method) ~[na:1.8.0_45]
	at java.io.FileInputStream.open(FileInputStream.java:195) ~[na:1.8.0_45]
	at java.io.FileInputStream.<init>(FileInputStream.java:138) ~[na:1.8.0_45]
	at java.io.FileInputStream.<init>(FileInputStream.java:93) ~[na:1.8.0_45]
	at scala.xml.Source$.fromFile(XML.scala:21) ~[scala-library-2.10.4.jar:na]
	at scala.xml.factory.XMLLoader$class.loadFile(XMLLoader.scala:49) ~[scala-library-2.10.4.jar:na]
	at scala.xml.XML$.loadFile(XML.scala:57) ~[scala-library-2.10.4.jar:na]
	at models.utils.XmlParse$.XMLParses(XmlParse.scala:35) ~[classes/:na]
	at controllers.Yarn$$anonfun$UserResource$1$$anonfun$apply$5$$anonfun$apply$6.apply(Yarn.scala:26) ~[classes/:na]
	at controllers.Yarn$$anonfun$UserResource$1$$anonfun$apply$5$$anonfun$apply$6.apply(Yarn.scala:25) ~[classes/:na]
	at controllers.Secured$$anonfun$IsAuthenticated$3$$anonfun$apply$1.apply(Secured.scala:27) ~[classes/:na]
	at controllers.Secured$$anonfun$IsAuthenticated$3$$anonfun$apply$1.apply(Secured.scala:27) ~[classes/:na]
	at play.api.mvc.ActionBuilder$$anonfun$apply$10.apply(Action.scala:221) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.ActionBuilder$$anonfun$apply$10.apply(Action.scala:220) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$.invokeBlock(Action.scala:357) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.ActionBuilder$$anon$1.apply(Action.scala:309) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4$$anonfun$apply$5.apply(Action.scala:109) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4$$anonfun$apply$5.apply(Action.scala:109) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.utils.Threads$.withContextClassLoader(Threads.scala:18) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4.apply(Action.scala:108) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1$$anonfun$apply$4.apply(Action.scala:107) ~[play_2.10-2.2.6.jar:2.2.6]
	at scala.Option.map(Option.scala:145) ~[scala-library-2.10.4.jar:na]
	at play.api.mvc.Action$$anonfun$apply$1.apply(Action.scala:107) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.mvc.Action$$anonfun$apply$1.apply(Action.scala:100) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$mapM$1.apply(Iteratee.scala:481) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$mapM$1.apply(Iteratee.scala:481) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMapM$1.apply(Iteratee.scala:517) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMapM$1.apply(Iteratee.scala:517) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMap$1$$anonfun$apply$13.apply(Iteratee.scala:493) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at play.api.libs.iteratee.Iteratee$$anonfun$flatMap$1$$anonfun$apply$13.apply(Iteratee.scala:493) ~[play-iteratees_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) [scala-library-2.10.4.jar:na]
	... 6 common frames omitted

2016-08-19 16:30:36,285 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:30:36,910 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:30:36,915 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:30:56,100 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:31:30,605 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:31:30,611 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:32:11,140 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:32:11,559 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:32:11,565 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:32:52,293 - [INFO] - from play in play-internal-execution-context-64 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:32:53,056 - [INFO] - from play in play-internal-execution-context-64 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-19 16:32:53,064 - [INFO] - from play in play-internal-execution-context-64 
Application started (Dev)

2016-08-19 16:35:15,060 - [INFO] - from application in play-akka.actor.default-dispatcher-350 
用户名=>jiazheng1@staff.weibo.com

2016-08-19 16:35:15,089 - [INFO] - from application in play-akka.actor.default-dispatcher-350 
文件类型不正确!

2016-08-25 12:48:26,635 - [INFO] - from play in play-internal-execution-context-34 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-25 12:48:29,414 - [INFO] - from play in play-internal-execution-context-34 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-25 12:48:29,419 - [INFO] - from play in play-internal-execution-context-34 
Application started (Dev)

2016-08-25 12:48:38,061 - [INFO] - from play in New I/O worker #10 
Starting application default Akka system.

2016-08-25 12:48:49,045 - [INFO] - from application in play-akka.actor.default-dispatcher-1160 
用户名=>liangkai1@staff.weibo.com

2016-08-25 12:48:58,339 - [INFO] - from application in play-akka.actor.default-dispatcher-1160 
用户名=>liangkai1@staff.weibo.com

2016-08-25 12:48:58,341 - [INFO] - from application in play-akka.actor.default-dispatcher-1160 
文件类型不正确!

2016-08-25 14:28:57,645 - [INFO] - from application in play-akka.actor.default-dispatcher-1187 
用户名=>liangkai1@staff.weibo.com

2016-08-25 14:29:25,948 - [INFO] - from application in play-akka.actor.default-dispatcher-1185 
执行模式=>yarn-cluster

2016-08-25 14:29:25,951 - [INFO] - from application in jobSystem-akka.actor.default-dispatcher-4 
select mode 1

2016-08-25 14:29:25,961 - [INFO] - from application in pool-684-thread-1 
args ArrayBuffer(/usr/local/spark/bin/spark-submit, --master, yarn-cluster, --class, com.weibo.spark.stream.HDFSWordCount, --num-executors, 2, --executor-memory, 2g, --driver-memory, 2g, --total-executor-cores, 4, /tmp/file/sparkStream.jar, )

2016-08-25 14:29:26,981 - [INFO] - from application in Thread-357 
16/08/25 14:29:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

2016-08-25 14:29:27,098 - [INFO] - from application in Thread-357 
16/08/25 14:29:27 INFO client.RMProxy: Connecting to ResourceManager at /127.0.0.1:8032

2016-08-25 14:29:27,273 - [INFO] - from application in Thread-357 
16/08/25 14:29:27 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers

2016-08-25 14:29:27,299 - [INFO] - from application in Thread-357 
16/08/25 14:29:27 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)

2016-08-25 14:29:27,300 - [INFO] - from application in Thread-357 
16/08/25 14:29:27 INFO yarn.Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead

2016-08-25 14:29:27,301 - [INFO] - from application in Thread-357 
16/08/25 14:29:27 INFO yarn.Client: Setting up container launch context for our AM

2016-08-25 14:29:27,303 - [INFO] - from application in Thread-357 
16/08/25 14:29:27 INFO yarn.Client: Setting up the launch environment for our AM container

2016-08-25 14:29:27,318 - [INFO] - from application in Thread-357 
16/08/25 14:29:27 INFO yarn.Client: Preparing resources for our AM container

2016-08-25 14:29:27,689 - [INFO] - from application in Thread-357 
16/08/25 14:29:27 INFO yarn.Client: Uploading resource file:/usr/local/spark/lib/spark-assembly-1.5.2-hadoop2.6.0.jar -> hdfs://localhost:9000/user/king/.sparkStaging/application_1471502301744_0069/spark-assembly-1.5.2-hadoop2.6.0.jar

2016-08-25 14:29:28,410 - [INFO] - from application in Thread-357 
16/08/25 14:29:28 INFO yarn.Client: Uploading resource file:/tmp/file/sparkStream.jar -> hdfs://localhost:9000/user/king/.sparkStaging/application_1471502301744_0069/sparkStream.jar

2016-08-25 14:29:28,452 - [INFO] - from application in Thread-357 
16/08/25 14:29:28 INFO yarn.Client: Uploading resource file:/private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/spark-b7bcc15d-52fa-4b85-ac2a-bb72713eef58/__spark_conf__5884227601120802106.zip -> hdfs://localhost:9000/user/king/.sparkStaging/application_1471502301744_0069/__spark_conf__5884227601120802106.zip

2016-08-25 14:29:28,486 - [INFO] - from application in Thread-357 
16/08/25 14:29:28 INFO spark.SecurityManager: Changing view acls to: king

2016-08-25 14:29:28,486 - [INFO] - from application in Thread-357 
16/08/25 14:29:28 INFO spark.SecurityManager: Changing modify acls to: king

2016-08-25 14:29:28,487 - [INFO] - from application in Thread-357 
16/08/25 14:29:28 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(king); users with modify permissions: Set(king)

2016-08-25 14:29:28,668 - [INFO] - from application in Thread-357 
16/08/25 14:29:28 INFO yarn.Client: Submitting application 69 to ResourceManager

2016-08-25 14:29:28,694 - [INFO] - from application in play-akka.actor.default-dispatcher-1185 
用户任务Id====>application_1471502301744_0069

2016-08-25 14:29:29,699 - [INFO] - from application in Thread-357 
16/08/25 14:29:29 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:29,702 - [INFO] - from application in Thread-357 
16/08/25 14:29:29 INFO yarn.Client: 

2016-08-25 14:29:29,702 - [INFO] - from application in Thread-357 
	 client token: N/A

2016-08-25 14:29:29,702 - [INFO] - from application in Thread-357 
	 diagnostics: N/A

2016-08-25 14:29:29,702 - [INFO] - from application in Thread-357 
	 ApplicationMaster host: N/A

2016-08-25 14:29:29,702 - [INFO] - from application in Thread-357 
	 ApplicationMaster RPC port: -1

2016-08-25 14:29:29,702 - [INFO] - from application in Thread-357 
	 queue: default

2016-08-25 14:29:29,702 - [INFO] - from application in Thread-357 
	 start time: 1472106568677

2016-08-25 14:29:29,702 - [INFO] - from application in Thread-357 
	 final status: UNDEFINED

2016-08-25 14:29:29,702 - [INFO] - from application in Thread-357 
	 tracking URL: http://10.236.66.144:8088/proxy/application_1471502301744_0069/

2016-08-25 14:29:29,702 - [INFO] - from application in Thread-357 
	 user: king

2016-08-25 14:29:30,706 - [INFO] - from application in Thread-357 
16/08/25 14:29:30 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:31,712 - [INFO] - from application in Thread-357 
16/08/25 14:29:31 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:32,719 - [INFO] - from application in Thread-357 
16/08/25 14:29:32 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:33,724 - [INFO] - from application in Thread-357 
16/08/25 14:29:33 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:34,730 - [INFO] - from application in Thread-357 
16/08/25 14:29:34 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:35,739 - [INFO] - from application in Thread-357 
16/08/25 14:29:35 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:36,747 - [INFO] - from application in Thread-357 
16/08/25 14:29:36 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:37,755 - [INFO] - from application in Thread-357 
16/08/25 14:29:37 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:38,760 - [INFO] - from application in Thread-357 
16/08/25 14:29:38 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:39,768 - [INFO] - from application in Thread-357 
16/08/25 14:29:39 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:40,775 - [INFO] - from application in Thread-357 
16/08/25 14:29:40 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:41,781 - [INFO] - from application in Thread-357 
16/08/25 14:29:41 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:42,785 - [INFO] - from application in Thread-357 
16/08/25 14:29:42 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:43,792 - [INFO] - from application in Thread-357 
16/08/25 14:29:43 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:44,798 - [INFO] - from application in Thread-357 
16/08/25 14:29:44 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:45,806 - [INFO] - from application in Thread-357 
16/08/25 14:29:45 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:46,818 - [INFO] - from application in Thread-357 
16/08/25 14:29:46 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:47,824 - [INFO] - from application in Thread-357 
16/08/25 14:29:47 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:48,829 - [INFO] - from application in Thread-357 
16/08/25 14:29:48 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:49,835 - [INFO] - from application in Thread-357 
16/08/25 14:29:49 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:50,840 - [INFO] - from application in Thread-357 
16/08/25 14:29:50 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:51,848 - [INFO] - from application in Thread-357 
16/08/25 14:29:51 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:52,853 - [INFO] - from application in Thread-357 
16/08/25 14:29:52 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:53,859 - [INFO] - from application in Thread-357 
16/08/25 14:29:53 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:54,864 - [INFO] - from application in Thread-357 
16/08/25 14:29:54 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:55,869 - [INFO] - from application in Thread-357 
16/08/25 14:29:55 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:56,876 - [INFO] - from application in Thread-357 
16/08/25 14:29:56 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:57,881 - [INFO] - from application in Thread-357 
16/08/25 14:29:57 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:58,886 - [INFO] - from application in Thread-357 
16/08/25 14:29:58 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:29:59,893 - [INFO] - from application in Thread-357 
16/08/25 14:29:59 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:00,899 - [INFO] - from application in Thread-357 
16/08/25 14:30:00 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:01,904 - [INFO] - from application in Thread-357 
16/08/25 14:30:01 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:02,909 - [INFO] - from application in Thread-357 
16/08/25 14:30:02 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:03,916 - [INFO] - from application in Thread-357 
16/08/25 14:30:03 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:04,513 - [INFO] - from application in play-akka.actor.default-dispatcher-1196 
执行模式=>standalone

2016-08-25 14:30:04,513 - [INFO] - from application in jobSystem-akka.actor.default-dispatcher-4 
select mode 2

2016-08-25 14:30:04,514 - [INFO] - from application in pool-684-thread-2 
args ArrayBuffer(/usr/local/spark/bin/spark-submit, --master, spark://localhost:7077, --class, com.weibo.spark.stream.HDFSWordCount, --num-executors, 2, --executor-memory, 2g, --driver-memory, 2g, --total-executor-cores, 4, /tmp/file/sparkStream.jar, )

2016-08-25 14:30:04,922 - [INFO] - from application in Thread-357 
16/08/25 14:30:04 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:05,190 - [INFO] - from application in Thread-359 
16/08/25 14:30:05 INFO spark.SparkContext: Running Spark version 1.5.2

2016-08-25 14:30:05,928 - [INFO] - from application in Thread-357 
16/08/25 14:30:05 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:06,585 - [INFO] - from application in Thread-359 
16/08/25 14:30:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

2016-08-25 14:30:06,686 - [INFO] - from application in Thread-359 
16/08/25 14:30:06 INFO spark.SecurityManager: Changing view acls to: king

2016-08-25 14:30:06,687 - [INFO] - from application in Thread-359 
16/08/25 14:30:06 INFO spark.SecurityManager: Changing modify acls to: king

2016-08-25 14:30:06,687 - [INFO] - from application in Thread-359 
16/08/25 14:30:06 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(king); users with modify permissions: Set(king)

2016-08-25 14:30:06,935 - [INFO] - from application in Thread-357 
16/08/25 14:30:06 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:07,181 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO slf4j.Slf4jLogger: Slf4jLogger started

2016-08-25 14:30:07,212 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO Remoting: Starting remoting

2016-08-25 14:30:07,353 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.236.66.144:51385]

2016-08-25 14:30:07,357 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO util.Utils: Successfully started service 'sparkDriver' on port 51385.

2016-08-25 14:30:07,371 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO spark.SparkEnv: Registering MapOutputTracker

2016-08-25 14:30:07,381 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO spark.SparkEnv: Registering BlockManagerMaster

2016-08-25 14:30:07,399 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO storage.DiskBlockManager: Created local directory at /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/blockmgr-001b83c3-d14b-49dd-b286-a9c25f4ae8a6

2016-08-25 14:30:07,404 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO storage.MemoryStore: MemoryStore started with capacity 1060.0 MB

2016-08-25 14:30:07,438 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO spark.HttpFileServer: HTTP File server directory is /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/spark-cf4c1657-3a09-41f3-8515-f8a7a70a88b2/httpd-09de6ac7-1fc2-49d0-b80b-95988a540997

2016-08-25 14:30:07,443 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO spark.HttpServer: Starting HTTP Server

2016-08-25 14:30:07,498 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO server.Server: jetty-8.y.z-SNAPSHOT

2016-08-25 14:30:07,512 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51386

2016-08-25 14:30:07,512 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO util.Utils: Successfully started service 'HTTP file server' on port 51386.

2016-08-25 14:30:07,522 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO spark.SparkEnv: Registering OutputCommitCoordinator

2016-08-25 14:30:07,601 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO server.Server: jetty-8.y.z-SNAPSHOT

2016-08-25 14:30:07,610 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040

2016-08-25 14:30:07,610 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.

2016-08-25 14:30:07,611 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO ui.SparkUI: Started SparkUI at http://10.236.66.144:4040

2016-08-25 14:30:07,641 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO spark.SparkContext: Added JAR file:/tmp/file/sparkStream.jar at http://10.236.66.144:51386/jars/sparkStream.jar with timestamp 1472106607640

2016-08-25 14:30:07,698 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 WARN metrics.MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.

2016-08-25 14:30:07,712 - [INFO] - from application in Thread-359 
16/08/25 14:30:07 INFO client.AppClient$ClientEndpoint: Connecting to master spark://localhost:7077...

2016-08-25 14:30:07,940 - [INFO] - from application in Thread-357 
16/08/25 14:30:07 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:07,989 - [INFO] - from application in play-akka.actor.default-dispatcher-1196 
用户任务Id====>app-20160825143007-0013

2016-08-25 14:30:08,091 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51390.

2016-08-25 14:30:08,091 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO netty.NettyBlockTransferService: Server created on 51390

2016-08-25 14:30:08,092 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO storage.BlockManagerMaster: Trying to register BlockManager

2016-08-25 14:30:08,094 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.236.66.144:51390 with 1060.0 MB RAM, BlockManagerId(driver, 10.236.66.144, 51390)

2016-08-25 14:30:08,096 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO storage.BlockManagerMaster: Registered BlockManager

2016-08-25 14:30:08,230 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO cluster.SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

2016-08-25 14:30:08,499 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FileInputDStream: Duration for remembering RDDs set to 60000 ms for org.apache.spark.streaming.dstream.FileInputDStream@e1e2e5e

2016-08-25 14:30:08,571 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.ForEachDStream: metadataCleanupDelay = -1

2016-08-25 14:30:08,572 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.ShuffledDStream: metadataCleanupDelay = -1

2016-08-25 14:30:08,572 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.MappedDStream: metadataCleanupDelay = -1

2016-08-25 14:30:08,572 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FlatMappedDStream: metadataCleanupDelay = -1

2016-08-25 14:30:08,572 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.MappedDStream: metadataCleanupDelay = -1

2016-08-25 14:30:08,572 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FileInputDStream: metadataCleanupDelay = -1

2016-08-25 14:30:08,572 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FileInputDStream: Slide time = 5000 ms

2016-08-25 14:30:08,573 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FileInputDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 14:30:08,573 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FileInputDStream: Checkpoint interval = null

2016-08-25 14:30:08,573 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FileInputDStream: Remember duration = 60000 ms

2016-08-25 14:30:08,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@e1e2e5e

2016-08-25 14:30:08,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.MappedDStream: Slide time = 5000 ms

2016-08-25 14:30:08,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.MappedDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 14:30:08,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.MappedDStream: Checkpoint interval = null

2016-08-25 14:30:08,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.MappedDStream: Remember duration = 5000 ms

2016-08-25 14:30:08,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@2064ecff

2016-08-25 14:30:08,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FlatMappedDStream: Slide time = 5000 ms

2016-08-25 14:30:08,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FlatMappedDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 14:30:08,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FlatMappedDStream: Checkpoint interval = null

2016-08-25 14:30:08,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FlatMappedDStream: Remember duration = 5000 ms

2016-08-25 14:30:08,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.FlatMappedDStream: Initialized and validated org.apache.spark.streaming.dstream.FlatMappedDStream@6e9fb579

2016-08-25 14:30:08,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.MappedDStream: Slide time = 5000 ms

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.MappedDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.MappedDStream: Checkpoint interval = null

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.MappedDStream: Remember duration = 5000 ms

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@5f7e4377

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.ShuffledDStream: Slide time = 5000 ms

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.ShuffledDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.ShuffledDStream: Checkpoint interval = null

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.ShuffledDStream: Remember duration = 5000 ms

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@27b89417

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.ForEachDStream: Slide time = 5000 ms

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.ForEachDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.ForEachDStream: Checkpoint interval = null

2016-08-25 14:30:08,575 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.ForEachDStream: Remember duration = 5000 ms

2016-08-25 14:30:08,576 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO dstream.ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@20bc970b

2016-08-25 14:30:08,604 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO util.RecurringTimer: Started timer for JobGenerator at time 1472106610000

2016-08-25 14:30:08,604 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO scheduler.JobGenerator: Started JobGenerator at 1472106610000 ms

2016-08-25 14:30:08,604 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO scheduler.JobScheduler: Started JobScheduler

2016-08-25 14:30:08,609 - [INFO] - from application in Thread-359 
16/08/25 14:30:08 INFO streaming.StreamingContext: StreamingContext started

2016-08-25 14:30:08,946 - [INFO] - from application in Thread-357 
16/08/25 14:30:08 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:09,953 - [INFO] - from application in Thread-357 
16/08/25 14:30:09 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:10,572 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO dstream.FileInputDStream: Finding new files took 562 ms

2016-08-25 14:30:10,574 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO dstream.FileInputDStream: New files at time 1472106610000 ms:

2016-08-25 14:30:10,574 - [INFO] - from application in Thread-359 


2016-08-25 14:30:10,600 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO scheduler.JobScheduler: Added jobs for time 1472106610000 ms

2016-08-25 14:30:10,602 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO scheduler.JobScheduler: Starting job streaming job 1472106610000 ms.0 from job set of time 1472106610000 ms

2016-08-25 14:30:10,631 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO spark.SparkContext: Starting job: print at HDFSWordCount.scala:20

2016-08-25 14:30:10,648 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO scheduler.DAGScheduler: Registering RDD 3 (map at HDFSWordCount.scala:17)

2016-08-25 14:30:10,649 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO scheduler.DAGScheduler: Got job 0 (print at HDFSWordCount.scala:20) with 1 output partitions

2016-08-25 14:30:10,650 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO scheduler.DAGScheduler: Final stage: ResultStage 1(print at HDFSWordCount.scala:20)

2016-08-25 14:30:10,650 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)

2016-08-25 14:30:10,651 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO scheduler.DAGScheduler: Missing parents: List()

2016-08-25 14:30:10,656 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at HDFSWordCount.scala:18), which has no missing parents

2016-08-25 14:30:10,753 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO storage.MemoryStore: ensureFreeSpace(2344) called with curMem=0, maxMem=1111511531

2016-08-25 14:30:10,755 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1060.0 MB)

2016-08-25 14:30:10,762 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO storage.MemoryStore: ensureFreeSpace(1435) called with curMem=2344, maxMem=1111511531

2016-08-25 14:30:10,762 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1435.0 B, free 1060.0 MB)

2016-08-25 14:30:10,764 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.236.66.144:51390 (size: 1435.0 B, free: 1060.0 MB)

2016-08-25 14:30:10,766 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861

2016-08-25 14:30:10,768 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at HDFSWordCount.scala:18)

2016-08-25 14:30:10,769 - [INFO] - from application in Thread-359 
16/08/25 14:30:10 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks

2016-08-25 14:30:10,960 - [INFO] - from application in Thread-357 
16/08/25 14:30:10 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:11,966 - [INFO] - from application in Thread-357 
16/08/25 14:30:11 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:12,972 - [INFO] - from application in Thread-357 
16/08/25 14:30:12 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:13,977 - [INFO] - from application in Thread-357 
16/08/25 14:30:13 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:14,985 - [INFO] - from application in Thread-357 
16/08/25 14:30:14 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:15,160 - [INFO] - from application in Thread-359 
16/08/25 14:30:15 INFO dstream.FileInputDStream: Finding new files took 153 ms

2016-08-25 14:30:15,161 - [INFO] - from application in Thread-359 
16/08/25 14:30:15 INFO dstream.FileInputDStream: New files at time 1472106615000 ms:

2016-08-25 14:30:15,161 - [INFO] - from application in Thread-359 


2016-08-25 14:30:15,168 - [INFO] - from application in Thread-359 
16/08/25 14:30:15 INFO scheduler.JobScheduler: Added jobs for time 1472106615000 ms

2016-08-25 14:30:15,989 - [INFO] - from application in Thread-357 
16/08/25 14:30:15 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)

2016-08-25 14:30:16,998 - [INFO] - from application in Thread-357 
16/08/25 14:30:16 INFO yarn.Client: Application report for application_1471502301744_0069 (state: KILLED)

2016-08-25 14:30:16,999 - [INFO] - from application in Thread-357 
16/08/25 14:30:16 INFO yarn.Client: 

2016-08-25 14:30:16,999 - [INFO] - from application in Thread-357 
	 client token: N/A

2016-08-25 14:30:16,999 - [INFO] - from application in Thread-357 
	 diagnostics: Application killed by user.

2016-08-25 14:30:16,999 - [INFO] - from application in Thread-357 
	 ApplicationMaster host: N/A

2016-08-25 14:30:16,999 - [INFO] - from application in Thread-357 
	 ApplicationMaster RPC port: -1

2016-08-25 14:30:16,999 - [INFO] - from application in Thread-357 
	 queue: default

2016-08-25 14:30:16,999 - [INFO] - from application in Thread-357 
	 start time: 1472106568677

2016-08-25 14:30:16,999 - [INFO] - from application in Thread-357 
	 final status: KILLED

2016-08-25 14:30:16,999 - [INFO] - from application in Thread-357 
	 tracking URL: http://10.236.66.144:8088/cluster/app/application_1471502301744_0069

2016-08-25 14:30:16,999 - [INFO] - from application in Thread-357 
	 user: king

2016-08-25 14:30:17,001 - [INFO] - from application in Thread-357 
16/08/25 14:30:17 INFO yarn.Client: Deleting staging directory .sparkStaging/application_1471502301744_0069

2016-08-25 14:30:17,007 - [INFO] - from application in Thread-357 
Exception in thread "main" org.apache.spark.SparkException: Application application_1471502301744_0069 is killed

2016-08-25 14:30:17,008 - [INFO] - from application in Thread-357 
	at org.apache.spark.deploy.yarn.Client.run(Client.scala:929)

2016-08-25 14:30:17,008 - [INFO] - from application in Thread-357 
	at org.apache.spark.deploy.yarn.Client$.main(Client.scala:971)

2016-08-25 14:30:17,008 - [INFO] - from application in Thread-357 
	at org.apache.spark.deploy.yarn.Client.main(Client.scala)

2016-08-25 14:30:17,008 - [INFO] - from application in Thread-357 
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)

2016-08-25 14:30:17,008 - [INFO] - from application in Thread-357 
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)

2016-08-25 14:30:17,008 - [INFO] - from application in Thread-357 
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)

2016-08-25 14:30:17,008 - [INFO] - from application in Thread-357 
	at java.lang.reflect.Method.invoke(Method.java:483)

2016-08-25 14:30:17,008 - [INFO] - from application in Thread-357 
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:674)

2016-08-25 14:30:17,008 - [INFO] - from application in Thread-357 
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)

2016-08-25 14:30:17,008 - [INFO] - from application in Thread-357 
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)

2016-08-25 14:30:17,008 - [INFO] - from application in Thread-357 
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)

2016-08-25 14:30:17,008 - [INFO] - from application in Thread-357 
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

2016-08-25 14:30:17,009 - [INFO] - from application in Thread-357 
16/08/25 14:30:17 INFO util.ShutdownHookManager: Shutdown hook called

2016-08-25 14:30:17,010 - [INFO] - from application in Thread-357 
16/08/25 14:30:17 INFO util.ShutdownHookManager: Deleting directory /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/spark-b7bcc15d-52fa-4b85-ac2a-bb72713eef58

2016-08-25 14:30:17,031 - [ERROR] - from models.JobManagerActor in pool-684-thread-1 
Got Throwable
models.JobRunExecption: 16/08/25 14:29:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/08/25 14:29:27 INFO client.RMProxy: Connecting to ResourceManager at /127.0.0.1:8032
16/08/25 14:29:27 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers
16/08/25 14:29:27 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
16/08/25 14:29:27 INFO yarn.Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
16/08/25 14:29:27 INFO yarn.Client: Setting up container launch context for our AM
16/08/25 14:29:27 INFO yarn.Client: Setting up the launch environment for our AM container
16/08/25 14:29:27 INFO yarn.Client: Preparing resources for our AM container
16/08/25 14:29:27 INFO yarn.Client: Uploading resource file:/usr/local/spark/lib/spark-assembly-1.5.2-hadoop2.6.0.jar -> hdfs://localhost:9000/user/king/.sparkStaging/application_1471502301744_0069/spark-assembly-1.5.2-hadoop2.6.0.jar
16/08/25 14:29:28 INFO yarn.Client: Uploading resource file:/tmp/file/sparkStream.jar -> hdfs://localhost:9000/user/king/.sparkStaging/application_1471502301744_0069/sparkStream.jar
16/08/25 14:29:28 INFO yarn.Client: Uploading resource file:/private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/spark-b7bcc15d-52fa-4b85-ac2a-bb72713eef58/__spark_conf__5884227601120802106.zip -> hdfs://localhost:9000/user/king/.sparkStaging/application_1471502301744_0069/__spark_conf__5884227601120802106.zip
16/08/25 14:29:28 INFO spark.SecurityManager: Changing view acls to: king
16/08/25 14:29:28 INFO spark.SecurityManager: Changing modify acls to: king
16/08/25 14:29:28 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(king); users with modify permissions: Set(king)
16/08/25 14:29:28 INFO yarn.Client: Submitting application 69 to ResourceManager
16/08/25 14:29:28 INFO impl.YarnClientImpl: Submitted application application_1471502301744_0069
16/08/25 14:29:29 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:29 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1472106568677
	 final status: UNDEFINED
	 tracking URL: http://10.236.66.144:8088/proxy/application_1471502301744_0069/
	 user: king
16/08/25 14:29:30 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:31 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:32 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:33 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:34 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:35 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:36 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:37 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:38 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:39 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:40 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:41 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:42 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:43 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:44 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:45 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:46 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:47 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:48 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:49 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:50 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:51 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:52 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:53 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:54 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:55 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:56 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:57 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:58 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:29:59 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:00 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:01 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:02 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:03 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:04 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:05 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:06 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:07 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:08 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:09 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:10 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:11 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:12 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:13 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:14 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:15 INFO yarn.Client: Application report for application_1471502301744_0069 (state: ACCEPTED)
16/08/25 14:30:16 INFO yarn.Client: Application report for application_1471502301744_0069 (state: KILLED)
16/08/25 14:30:16 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: Application killed by user.
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1472106568677
	 final status: KILLED
	 tracking URL: http://10.236.66.144:8088/cluster/app/application_1471502301744_0069
	 user: king
16/08/25 14:30:17 INFO yarn.Client: Deleting staging directory .sparkStaging/application_1471502301744_0069
Exception in thread "main" org.apache.spark.SparkException: Application application_1471502301744_0069 is killed
	at org.apache.spark.deploy.yarn.Client.run(Client.scala:929)
	at org.apache.spark.deploy.yarn.Client$.main(Client.scala:971)
	at org.apache.spark.deploy.yarn.Client.main(Client.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:674)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
16/08/25 14:30:17 INFO util.ShutdownHookManager: Shutdown hook called
16/08/25 14:30:17 INFO util.ShutdownHookManager: Deleting directory /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/spark-b7bcc15d-52fa-4b85-ac2a-bb72713eef58
	at models.JobManagerActor$$anonfun$runJobFuture$2.apply(JobManager.scala:183) [classes/:na]
	at models.JobManagerActor$$anonfun$runJobFuture$2.apply(JobManager.scala:159) [classes/:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) [scala-library-2.10.4.jar:na]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0]
	at java.lang.Thread.run(Thread.java:744) [na:1.8.0]

2016-08-25 14:30:20,010 - [INFO] - from application in Thread-359 
16/08/25 14:30:20 INFO dstream.FileInputDStream: Finding new files took 6 ms

2016-08-25 14:30:20,010 - [INFO] - from application in Thread-359 
16/08/25 14:30:20 INFO dstream.FileInputDStream: New files at time 1472106620000 ms:

2016-08-25 14:30:20,010 - [INFO] - from application in Thread-359 


2016-08-25 14:30:20,015 - [INFO] - from application in Thread-359 
16/08/25 14:30:20 INFO scheduler.JobScheduler: Added jobs for time 1472106620000 ms

2016-08-25 14:30:25,010 - [INFO] - from application in Thread-359 
16/08/25 14:30:25 INFO dstream.FileInputDStream: Finding new files took 6 ms

2016-08-25 14:30:25,010 - [INFO] - from application in Thread-359 
16/08/25 14:30:25 INFO dstream.FileInputDStream: New files at time 1472106625000 ms:

2016-08-25 14:30:25,010 - [INFO] - from application in Thread-359 


2016-08-25 14:30:25,015 - [INFO] - from application in Thread-359 
16/08/25 14:30:25 INFO scheduler.JobScheduler: Added jobs for time 1472106625000 ms

2016-08-25 14:30:25,779 - [INFO] - from application in Thread-359 
16/08/25 14:30:25 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:30:30,038 - [INFO] - from application in Thread-359 
16/08/25 14:30:30 INFO dstream.FileInputDStream: Finding new files took 35 ms

2016-08-25 14:30:30,038 - [INFO] - from application in Thread-359 
16/08/25 14:30:30 INFO dstream.FileInputDStream: New files at time 1472106630000 ms:

2016-08-25 14:30:30,038 - [INFO] - from application in Thread-359 


2016-08-25 14:30:30,044 - [INFO] - from application in Thread-359 
16/08/25 14:30:30 INFO scheduler.JobScheduler: Added jobs for time 1472106630000 ms

2016-08-25 14:30:35,089 - [INFO] - from application in Thread-359 
16/08/25 14:30:35 INFO dstream.FileInputDStream: Finding new files took 83 ms

2016-08-25 14:30:35,089 - [INFO] - from application in Thread-359 
16/08/25 14:30:35 INFO dstream.FileInputDStream: New files at time 1472106635000 ms:

2016-08-25 14:30:35,089 - [INFO] - from application in Thread-359 


2016-08-25 14:30:35,097 - [INFO] - from application in Thread-359 
16/08/25 14:30:35 INFO scheduler.JobScheduler: Added jobs for time 1472106635000 ms

2016-08-25 14:30:40,013 - [INFO] - from application in Thread-359 
16/08/25 14:30:40 INFO dstream.FileInputDStream: Finding new files took 9 ms

2016-08-25 14:30:40,013 - [INFO] - from application in Thread-359 
16/08/25 14:30:40 INFO dstream.FileInputDStream: New files at time 1472106640000 ms:

2016-08-25 14:30:40,013 - [INFO] - from application in Thread-359 


2016-08-25 14:30:40,018 - [INFO] - from application in Thread-359 
16/08/25 14:30:40 INFO scheduler.JobScheduler: Added jobs for time 1472106640000 ms

2016-08-25 14:30:40,777 - [INFO] - from application in Thread-359 
16/08/25 14:30:40 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:30:45,014 - [INFO] - from application in Thread-359 
16/08/25 14:30:45 INFO dstream.FileInputDStream: Finding new files took 10 ms

2016-08-25 14:30:45,014 - [INFO] - from application in Thread-359 
16/08/25 14:30:45 INFO dstream.FileInputDStream: New files at time 1472106645000 ms:

2016-08-25 14:30:45,014 - [INFO] - from application in Thread-359 


2016-08-25 14:30:45,020 - [INFO] - from application in Thread-359 
16/08/25 14:30:45 INFO scheduler.JobScheduler: Added jobs for time 1472106645000 ms

2016-08-25 14:30:50,014 - [INFO] - from application in Thread-359 
16/08/25 14:30:50 INFO dstream.FileInputDStream: Finding new files took 11 ms

2016-08-25 14:30:50,015 - [INFO] - from application in Thread-359 
16/08/25 14:30:50 INFO dstream.FileInputDStream: New files at time 1472106650000 ms:

2016-08-25 14:30:50,015 - [INFO] - from application in Thread-359 


2016-08-25 14:30:50,021 - [INFO] - from application in Thread-359 
16/08/25 14:30:50 INFO scheduler.JobScheduler: Added jobs for time 1472106650000 ms

2016-08-25 14:30:55,011 - [INFO] - from application in Thread-359 
16/08/25 14:30:55 INFO dstream.FileInputDStream: Finding new files took 7 ms

2016-08-25 14:30:55,011 - [INFO] - from application in Thread-359 
16/08/25 14:30:55 INFO dstream.FileInputDStream: New files at time 1472106655000 ms:

2016-08-25 14:30:55,011 - [INFO] - from application in Thread-359 


2016-08-25 14:30:55,016 - [INFO] - from application in Thread-359 
16/08/25 14:30:55 INFO scheduler.JobScheduler: Added jobs for time 1472106655000 ms

2016-08-25 14:30:55,777 - [INFO] - from application in Thread-359 
16/08/25 14:30:55 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:31:00,011 - [INFO] - from application in Thread-359 
16/08/25 14:31:00 INFO dstream.FileInputDStream: Finding new files took 8 ms

2016-08-25 14:31:00,011 - [INFO] - from application in Thread-359 
16/08/25 14:31:00 INFO dstream.FileInputDStream: New files at time 1472106660000 ms:

2016-08-25 14:31:00,011 - [INFO] - from application in Thread-359 


2016-08-25 14:31:00,019 - [INFO] - from application in Thread-359 
16/08/25 14:31:00 INFO scheduler.JobScheduler: Added jobs for time 1472106660000 ms

2016-08-25 14:31:05,052 - [INFO] - from application in Thread-359 
16/08/25 14:31:05 INFO dstream.FileInputDStream: Finding new files took 47 ms

2016-08-25 14:31:05,052 - [INFO] - from application in Thread-359 
16/08/25 14:31:05 INFO dstream.FileInputDStream: New files at time 1472106665000 ms:

2016-08-25 14:31:05,052 - [INFO] - from application in Thread-359 


2016-08-25 14:31:05,057 - [INFO] - from application in Thread-359 
16/08/25 14:31:05 INFO scheduler.JobScheduler: Added jobs for time 1472106665000 ms

2016-08-25 14:31:10,086 - [INFO] - from application in Thread-359 
16/08/25 14:31:10 INFO dstream.FileInputDStream: Finding new files took 82 ms

2016-08-25 14:31:10,086 - [INFO] - from application in Thread-359 
16/08/25 14:31:10 INFO dstream.FileInputDStream: New files at time 1472106670000 ms:

2016-08-25 14:31:10,086 - [INFO] - from application in Thread-359 


2016-08-25 14:31:10,092 - [INFO] - from application in Thread-359 
16/08/25 14:31:10 INFO scheduler.JobScheduler: Added jobs for time 1472106670000 ms

2016-08-25 14:31:10,780 - [INFO] - from application in Thread-359 
16/08/25 14:31:10 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:31:15,010 - [INFO] - from application in Thread-359 
16/08/25 14:31:15 INFO dstream.FileInputDStream: Finding new files took 5 ms

2016-08-25 14:31:15,010 - [INFO] - from application in Thread-359 
16/08/25 14:31:15 INFO dstream.FileInputDStream: New files at time 1472106675000 ms:

2016-08-25 14:31:15,010 - [INFO] - from application in Thread-359 


2016-08-25 14:31:15,015 - [INFO] - from application in Thread-359 
16/08/25 14:31:15 INFO scheduler.JobScheduler: Added jobs for time 1472106675000 ms

2016-08-25 14:31:20,184 - [INFO] - from application in Thread-359 
16/08/25 14:31:20 INFO dstream.FileInputDStream: Finding new files took 179 ms

2016-08-25 14:31:20,184 - [INFO] - from application in Thread-359 
16/08/25 14:31:20 INFO dstream.FileInputDStream: New files at time 1472106680000 ms:

2016-08-25 14:31:20,184 - [INFO] - from application in Thread-359 


2016-08-25 14:31:20,193 - [INFO] - from application in Thread-359 
16/08/25 14:31:20 INFO scheduler.JobScheduler: Added jobs for time 1472106680000 ms

2016-08-25 14:31:25,009 - [INFO] - from application in Thread-359 
16/08/25 14:31:25 INFO dstream.FileInputDStream: Finding new files took 5 ms

2016-08-25 14:31:25,009 - [INFO] - from application in Thread-359 
16/08/25 14:31:25 INFO dstream.FileInputDStream: New files at time 1472106685000 ms:

2016-08-25 14:31:25,009 - [INFO] - from application in Thread-359 


2016-08-25 14:31:25,015 - [INFO] - from application in Thread-359 
16/08/25 14:31:25 INFO scheduler.JobScheduler: Added jobs for time 1472106685000 ms

2016-08-25 14:31:25,778 - [INFO] - from application in Thread-359 
16/08/25 14:31:25 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:31:30,014 - [INFO] - from application in Thread-359 
16/08/25 14:31:30 INFO dstream.FileInputDStream: Finding new files took 9 ms

2016-08-25 14:31:30,014 - [INFO] - from application in Thread-359 
16/08/25 14:31:30 INFO dstream.FileInputDStream: New files at time 1472106690000 ms:

2016-08-25 14:31:30,014 - [INFO] - from application in Thread-359 


2016-08-25 14:31:30,017 - [INFO] - from application in Thread-359 
16/08/25 14:31:30 INFO scheduler.JobScheduler: Added jobs for time 1472106690000 ms

2016-08-25 14:31:35,012 - [INFO] - from application in Thread-359 
16/08/25 14:31:35 INFO dstream.FileInputDStream: Finding new files took 8 ms

2016-08-25 14:31:35,012 - [INFO] - from application in Thread-359 
16/08/25 14:31:35 INFO dstream.FileInputDStream: New files at time 1472106695000 ms:

2016-08-25 14:31:35,012 - [INFO] - from application in Thread-359 


2016-08-25 14:31:35,016 - [INFO] - from application in Thread-359 
16/08/25 14:31:35 INFO scheduler.JobScheduler: Added jobs for time 1472106695000 ms

2016-08-25 14:31:40,094 - [INFO] - from application in Thread-359 
16/08/25 14:31:40 INFO dstream.FileInputDStream: Finding new files took 89 ms

2016-08-25 14:31:40,094 - [INFO] - from application in Thread-359 
16/08/25 14:31:40 INFO dstream.FileInputDStream: New files at time 1472106700000 ms:

2016-08-25 14:31:40,094 - [INFO] - from application in Thread-359 


2016-08-25 14:31:40,099 - [INFO] - from application in Thread-359 
16/08/25 14:31:40 INFO scheduler.JobScheduler: Added jobs for time 1472106700000 ms

2016-08-25 14:31:40,780 - [INFO] - from application in Thread-359 
16/08/25 14:31:40 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:31:45,014 - [INFO] - from application in Thread-359 
16/08/25 14:31:45 INFO dstream.FileInputDStream: Finding new files took 9 ms

2016-08-25 14:31:45,014 - [INFO] - from application in Thread-359 
16/08/25 14:31:45 INFO dstream.FileInputDStream: New files at time 1472106705000 ms:

2016-08-25 14:31:45,014 - [INFO] - from application in Thread-359 


2016-08-25 14:31:45,020 - [INFO] - from application in Thread-359 
16/08/25 14:31:45 INFO scheduler.JobScheduler: Added jobs for time 1472106705000 ms

2016-08-25 14:31:50,581 - [INFO] - from application in Thread-359 
16/08/25 14:31:50 INFO dstream.FileInputDStream: Finding new files took 577 ms

2016-08-25 14:31:50,581 - [INFO] - from application in Thread-359 
16/08/25 14:31:50 INFO dstream.FileInputDStream: New files at time 1472106710000 ms:

2016-08-25 14:31:50,581 - [INFO] - from application in Thread-359 


2016-08-25 14:31:50,585 - [INFO] - from application in Thread-359 
16/08/25 14:31:50 INFO scheduler.JobScheduler: Added jobs for time 1472106710000 ms

2016-08-25 14:31:55,015 - [INFO] - from application in Thread-359 
16/08/25 14:31:55 INFO dstream.FileInputDStream: Finding new files took 8 ms

2016-08-25 14:31:55,015 - [INFO] - from application in Thread-359 
16/08/25 14:31:55 INFO dstream.FileInputDStream: New files at time 1472106715000 ms:

2016-08-25 14:31:55,015 - [INFO] - from application in Thread-359 


2016-08-25 14:31:55,020 - [INFO] - from application in Thread-359 
16/08/25 14:31:55 INFO scheduler.JobScheduler: Added jobs for time 1472106715000 ms

2016-08-25 14:31:55,780 - [INFO] - from application in Thread-359 
16/08/25 14:31:55 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:32:00,018 - [INFO] - from application in Thread-359 
16/08/25 14:32:00 INFO dstream.FileInputDStream: Finding new files took 14 ms

2016-08-25 14:32:00,018 - [INFO] - from application in Thread-359 
16/08/25 14:32:00 INFO dstream.FileInputDStream: New files at time 1472106720000 ms:

2016-08-25 14:32:00,019 - [INFO] - from application in Thread-359 


2016-08-25 14:32:00,025 - [INFO] - from application in Thread-359 
16/08/25 14:32:00 INFO scheduler.JobScheduler: Added jobs for time 1472106720000 ms

2016-08-25 14:32:05,009 - [INFO] - from application in Thread-359 
16/08/25 14:32:05 INFO dstream.FileInputDStream: Finding new files took 4 ms

2016-08-25 14:32:05,009 - [INFO] - from application in Thread-359 
16/08/25 14:32:05 INFO dstream.FileInputDStream: New files at time 1472106725000 ms:

2016-08-25 14:32:05,009 - [INFO] - from application in Thread-359 


2016-08-25 14:32:05,014 - [INFO] - from application in Thread-359 
16/08/25 14:32:05 INFO scheduler.JobScheduler: Added jobs for time 1472106725000 ms

2016-08-25 14:32:10,252 - [INFO] - from application in Thread-359 
16/08/25 14:32:10 INFO dstream.FileInputDStream: Finding new files took 248 ms

2016-08-25 14:32:10,253 - [INFO] - from application in Thread-359 
16/08/25 14:32:10 INFO dstream.FileInputDStream: New files at time 1472106730000 ms:

2016-08-25 14:32:10,253 - [INFO] - from application in Thread-359 


2016-08-25 14:32:10,258 - [INFO] - from application in Thread-359 
16/08/25 14:32:10 INFO scheduler.JobScheduler: Added jobs for time 1472106730000 ms

2016-08-25 14:32:10,777 - [INFO] - from application in Thread-359 
16/08/25 14:32:10 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:32:15,090 - [INFO] - from application in Thread-359 
16/08/25 14:32:15 INFO dstream.FileInputDStream: Finding new files took 85 ms

2016-08-25 14:32:15,090 - [INFO] - from application in Thread-359 
16/08/25 14:32:15 INFO dstream.FileInputDStream: New files at time 1472106735000 ms:

2016-08-25 14:32:15,090 - [INFO] - from application in Thread-359 


2016-08-25 14:32:15,095 - [INFO] - from application in Thread-359 
16/08/25 14:32:15 INFO scheduler.JobScheduler: Added jobs for time 1472106735000 ms

2016-08-25 14:32:20,028 - [INFO] - from application in Thread-359 
16/08/25 14:32:20 INFO dstream.FileInputDStream: Finding new files took 24 ms

2016-08-25 14:32:20,028 - [INFO] - from application in Thread-359 
16/08/25 14:32:20 INFO dstream.FileInputDStream: New files at time 1472106740000 ms:

2016-08-25 14:32:20,028 - [INFO] - from application in Thread-359 


2016-08-25 14:32:20,033 - [INFO] - from application in Thread-359 
16/08/25 14:32:20 INFO scheduler.JobScheduler: Added jobs for time 1472106740000 ms

2016-08-25 14:32:25,211 - [INFO] - from application in Thread-359 
16/08/25 14:32:25 INFO dstream.FileInputDStream: Finding new files took 207 ms

2016-08-25 14:32:25,211 - [INFO] - from application in Thread-359 
16/08/25 14:32:25 INFO dstream.FileInputDStream: New files at time 1472106745000 ms:

2016-08-25 14:32:25,211 - [INFO] - from application in Thread-359 


2016-08-25 14:32:25,215 - [INFO] - from application in Thread-359 
16/08/25 14:32:25 INFO scheduler.JobScheduler: Added jobs for time 1472106745000 ms

2016-08-25 14:32:25,777 - [INFO] - from application in Thread-359 
16/08/25 14:32:25 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:32:30,009 - [INFO] - from application in Thread-359 
16/08/25 14:32:30 INFO dstream.FileInputDStream: Finding new files took 6 ms

2016-08-25 14:32:30,009 - [INFO] - from application in Thread-359 
16/08/25 14:32:30 INFO dstream.FileInputDStream: New files at time 1472106750000 ms:

2016-08-25 14:32:30,009 - [INFO] - from application in Thread-359 


2016-08-25 14:32:30,015 - [INFO] - from application in Thread-359 
16/08/25 14:32:30 INFO scheduler.JobScheduler: Added jobs for time 1472106750000 ms

2016-08-25 14:32:35,010 - [INFO] - from application in Thread-359 
16/08/25 14:32:35 INFO dstream.FileInputDStream: Finding new files took 5 ms

2016-08-25 14:32:35,010 - [INFO] - from application in Thread-359 
16/08/25 14:32:35 INFO dstream.FileInputDStream: New files at time 1472106755000 ms:

2016-08-25 14:32:35,010 - [INFO] - from application in Thread-359 


2016-08-25 14:32:35,015 - [INFO] - from application in Thread-359 
16/08/25 14:32:35 INFO scheduler.JobScheduler: Added jobs for time 1472106755000 ms

2016-08-25 14:32:40,021 - [INFO] - from application in Thread-359 
16/08/25 14:32:40 INFO dstream.FileInputDStream: Finding new files took 16 ms

2016-08-25 14:32:40,021 - [INFO] - from application in Thread-359 
16/08/25 14:32:40 INFO dstream.FileInputDStream: New files at time 1472106760000 ms:

2016-08-25 14:32:40,021 - [INFO] - from application in Thread-359 


2016-08-25 14:32:40,025 - [INFO] - from application in Thread-359 
16/08/25 14:32:40 INFO scheduler.JobScheduler: Added jobs for time 1472106760000 ms

2016-08-25 14:32:40,779 - [INFO] - from application in Thread-359 
16/08/25 14:32:40 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:32:45,101 - [INFO] - from application in Thread-359 
16/08/25 14:32:45 INFO dstream.FileInputDStream: Finding new files took 97 ms

2016-08-25 14:32:45,101 - [INFO] - from application in Thread-359 
16/08/25 14:32:45 INFO dstream.FileInputDStream: New files at time 1472106765000 ms:

2016-08-25 14:32:45,101 - [INFO] - from application in Thread-359 


2016-08-25 14:32:45,106 - [INFO] - from application in Thread-359 
16/08/25 14:32:45 INFO scheduler.JobScheduler: Added jobs for time 1472106765000 ms

2016-08-25 14:32:50,012 - [INFO] - from application in Thread-359 
16/08/25 14:32:50 INFO dstream.FileInputDStream: Finding new files took 7 ms

2016-08-25 14:32:50,012 - [INFO] - from application in Thread-359 
16/08/25 14:32:50 INFO dstream.FileInputDStream: New files at time 1472106770000 ms:

2016-08-25 14:32:50,012 - [INFO] - from application in Thread-359 


2016-08-25 14:32:50,016 - [INFO] - from application in Thread-359 
16/08/25 14:32:50 INFO scheduler.JobScheduler: Added jobs for time 1472106770000 ms

2016-08-25 14:32:55,027 - [INFO] - from application in Thread-359 
16/08/25 14:32:55 INFO dstream.FileInputDStream: Finding new files took 23 ms

2016-08-25 14:32:55,027 - [INFO] - from application in Thread-359 
16/08/25 14:32:55 INFO dstream.FileInputDStream: New files at time 1472106775000 ms:

2016-08-25 14:32:55,027 - [INFO] - from application in Thread-359 


2016-08-25 14:32:55,032 - [INFO] - from application in Thread-359 
16/08/25 14:32:55 INFO scheduler.JobScheduler: Added jobs for time 1472106775000 ms

2016-08-25 14:32:55,778 - [INFO] - from application in Thread-359 
16/08/25 14:32:55 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:33:00,011 - [INFO] - from application in Thread-359 
16/08/25 14:33:00 INFO dstream.FileInputDStream: Finding new files took 7 ms

2016-08-25 14:33:00,011 - [INFO] - from application in Thread-359 
16/08/25 14:33:00 INFO dstream.FileInputDStream: New files at time 1472106780000 ms:

2016-08-25 14:33:00,011 - [INFO] - from application in Thread-359 


2016-08-25 14:33:00,017 - [INFO] - from application in Thread-359 
16/08/25 14:33:00 INFO scheduler.JobScheduler: Added jobs for time 1472106780000 ms

2016-08-25 14:33:05,031 - [INFO] - from application in Thread-359 
16/08/25 14:33:05 INFO dstream.FileInputDStream: Finding new files took 27 ms

2016-08-25 14:33:05,031 - [INFO] - from application in Thread-359 
16/08/25 14:33:05 INFO dstream.FileInputDStream: New files at time 1472106785000 ms:

2016-08-25 14:33:05,031 - [INFO] - from application in Thread-359 


2016-08-25 14:33:05,036 - [INFO] - from application in Thread-359 
16/08/25 14:33:05 INFO scheduler.JobScheduler: Added jobs for time 1472106785000 ms

2016-08-25 14:33:10,027 - [INFO] - from application in Thread-359 
16/08/25 14:33:10 INFO dstream.FileInputDStream: Finding new files took 24 ms

2016-08-25 14:33:10,027 - [INFO] - from application in Thread-359 
16/08/25 14:33:10 INFO dstream.FileInputDStream: New files at time 1472106790000 ms:

2016-08-25 14:33:10,027 - [INFO] - from application in Thread-359 


2016-08-25 14:33:10,031 - [INFO] - from application in Thread-359 
16/08/25 14:33:10 INFO scheduler.JobScheduler: Added jobs for time 1472106790000 ms

2016-08-25 14:33:10,779 - [INFO] - from application in Thread-359 
16/08/25 14:33:10 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:33:15,013 - [INFO] - from application in Thread-359 
16/08/25 14:33:15 INFO dstream.FileInputDStream: Finding new files took 9 ms

2016-08-25 14:33:15,013 - [INFO] - from application in Thread-359 
16/08/25 14:33:15 INFO dstream.FileInputDStream: New files at time 1472106795000 ms:

2016-08-25 14:33:15,013 - [INFO] - from application in Thread-359 


2016-08-25 14:33:15,017 - [INFO] - from application in Thread-359 
16/08/25 14:33:15 INFO scheduler.JobScheduler: Added jobs for time 1472106795000 ms

2016-08-25 14:33:20,116 - [INFO] - from application in Thread-359 
16/08/25 14:33:20 INFO dstream.FileInputDStream: Finding new files took 109 ms

2016-08-25 14:33:20,116 - [INFO] - from application in Thread-359 
16/08/25 14:33:20 INFO dstream.FileInputDStream: New files at time 1472106800000 ms:

2016-08-25 14:33:20,116 - [INFO] - from application in Thread-359 


2016-08-25 14:33:20,121 - [INFO] - from application in Thread-359 
16/08/25 14:33:20 INFO scheduler.JobScheduler: Added jobs for time 1472106800000 ms

2016-08-25 14:33:25,014 - [INFO] - from application in Thread-359 
16/08/25 14:33:25 INFO dstream.FileInputDStream: Finding new files took 9 ms

2016-08-25 14:33:25,014 - [INFO] - from application in Thread-359 
16/08/25 14:33:25 INFO dstream.FileInputDStream: New files at time 1472106805000 ms:

2016-08-25 14:33:25,014 - [INFO] - from application in Thread-359 


2016-08-25 14:33:25,018 - [INFO] - from application in Thread-359 
16/08/25 14:33:25 INFO scheduler.JobScheduler: Added jobs for time 1472106805000 ms

2016-08-25 14:33:25,778 - [INFO] - from application in Thread-359 
16/08/25 14:33:25 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:33:30,023 - [INFO] - from application in Thread-359 
16/08/25 14:33:30 INFO dstream.FileInputDStream: Finding new files took 18 ms

2016-08-25 14:33:30,023 - [INFO] - from application in Thread-359 
16/08/25 14:33:30 INFO dstream.FileInputDStream: New files at time 1472106810000 ms:

2016-08-25 14:33:30,023 - [INFO] - from application in Thread-359 


2016-08-25 14:33:30,029 - [INFO] - from application in Thread-359 
16/08/25 14:33:30 INFO scheduler.JobScheduler: Added jobs for time 1472106810000 ms

2016-08-25 14:33:35,022 - [INFO] - from application in Thread-359 
16/08/25 14:33:35 INFO dstream.FileInputDStream: Finding new files took 19 ms

2016-08-25 14:33:35,022 - [INFO] - from application in Thread-359 
16/08/25 14:33:35 INFO dstream.FileInputDStream: New files at time 1472106815000 ms:

2016-08-25 14:33:35,022 - [INFO] - from application in Thread-359 


2016-08-25 14:33:35,027 - [INFO] - from application in Thread-359 
16/08/25 14:33:35 INFO scheduler.JobScheduler: Added jobs for time 1472106815000 ms

2016-08-25 14:33:40,149 - [INFO] - from application in Thread-359 
16/08/25 14:33:40 INFO dstream.FileInputDStream: Finding new files took 145 ms

2016-08-25 14:33:40,150 - [INFO] - from application in Thread-359 
16/08/25 14:33:40 INFO dstream.FileInputDStream: New files at time 1472106820000 ms:

2016-08-25 14:33:40,150 - [INFO] - from application in Thread-359 


2016-08-25 14:33:40,155 - [INFO] - from application in Thread-359 
16/08/25 14:33:40 INFO scheduler.JobScheduler: Added jobs for time 1472106820000 ms

2016-08-25 14:33:40,779 - [INFO] - from application in Thread-359 
16/08/25 14:33:40 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:33:45,042 - [INFO] - from application in Thread-359 
16/08/25 14:33:45 INFO dstream.FileInputDStream: Finding new files took 38 ms

2016-08-25 14:33:45,042 - [INFO] - from application in Thread-359 
16/08/25 14:33:45 INFO dstream.FileInputDStream: New files at time 1472106825000 ms:

2016-08-25 14:33:45,042 - [INFO] - from application in Thread-359 


2016-08-25 14:33:45,045 - [INFO] - from application in Thread-359 
16/08/25 14:33:45 INFO scheduler.JobScheduler: Added jobs for time 1472106825000 ms

2016-08-25 14:33:50,121 - [INFO] - from application in Thread-359 
16/08/25 14:33:50 INFO dstream.FileInputDStream: Finding new files took 116 ms

2016-08-25 14:33:50,121 - [INFO] - from application in Thread-359 
16/08/25 14:33:50 INFO dstream.FileInputDStream: New files at time 1472106830000 ms:

2016-08-25 14:33:50,121 - [INFO] - from application in Thread-359 


2016-08-25 14:33:50,125 - [INFO] - from application in Thread-359 
16/08/25 14:33:50 INFO scheduler.JobScheduler: Added jobs for time 1472106830000 ms

2016-08-25 14:33:55,009 - [INFO] - from application in Thread-359 
16/08/25 14:33:55 INFO dstream.FileInputDStream: Finding new files took 5 ms

2016-08-25 14:33:55,009 - [INFO] - from application in Thread-359 
16/08/25 14:33:55 INFO dstream.FileInputDStream: New files at time 1472106835000 ms:

2016-08-25 14:33:55,009 - [INFO] - from application in Thread-359 


2016-08-25 14:33:55,013 - [INFO] - from application in Thread-359 
16/08/25 14:33:55 INFO scheduler.JobScheduler: Added jobs for time 1472106835000 ms

2016-08-25 14:33:55,779 - [INFO] - from application in Thread-359 
16/08/25 14:33:55 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:34:00,039 - [INFO] - from application in Thread-359 
16/08/25 14:34:00 INFO dstream.FileInputDStream: Finding new files took 33 ms

2016-08-25 14:34:00,039 - [INFO] - from application in Thread-359 
16/08/25 14:34:00 INFO dstream.FileInputDStream: New files at time 1472106840000 ms:

2016-08-25 14:34:00,039 - [INFO] - from application in Thread-359 


2016-08-25 14:34:00,043 - [INFO] - from application in Thread-359 
16/08/25 14:34:00 INFO scheduler.JobScheduler: Added jobs for time 1472106840000 ms

2016-08-25 14:34:05,028 - [INFO] - from application in Thread-359 
16/08/25 14:34:05 INFO dstream.FileInputDStream: Finding new files took 24 ms

2016-08-25 14:34:05,028 - [INFO] - from application in Thread-359 
16/08/25 14:34:05 INFO dstream.FileInputDStream: New files at time 1472106845000 ms:

2016-08-25 14:34:05,028 - [INFO] - from application in Thread-359 


2016-08-25 14:34:05,032 - [INFO] - from application in Thread-359 
16/08/25 14:34:05 INFO scheduler.JobScheduler: Added jobs for time 1472106845000 ms

2016-08-25 14:34:10,062 - [INFO] - from application in Thread-359 
16/08/25 14:34:10 INFO dstream.FileInputDStream: Finding new files took 57 ms

2016-08-25 14:34:10,062 - [INFO] - from application in Thread-359 
16/08/25 14:34:10 INFO dstream.FileInputDStream: New files at time 1472106850000 ms:

2016-08-25 14:34:10,062 - [INFO] - from application in Thread-359 


2016-08-25 14:34:10,067 - [INFO] - from application in Thread-359 
16/08/25 14:34:10 INFO scheduler.JobScheduler: Added jobs for time 1472106850000 ms

2016-08-25 14:34:10,779 - [INFO] - from application in Thread-359 
16/08/25 14:34:10 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:34:15,012 - [INFO] - from application in Thread-359 
16/08/25 14:34:15 INFO dstream.FileInputDStream: Finding new files took 8 ms

2016-08-25 14:34:15,012 - [INFO] - from application in Thread-359 
16/08/25 14:34:15 INFO dstream.FileInputDStream: New files at time 1472106855000 ms:

2016-08-25 14:34:15,013 - [INFO] - from application in Thread-359 


2016-08-25 14:34:15,016 - [INFO] - from application in Thread-359 
16/08/25 14:34:15 INFO scheduler.JobScheduler: Added jobs for time 1472106855000 ms

2016-08-25 14:34:20,020 - [INFO] - from application in Thread-359 
16/08/25 14:34:20 INFO dstream.FileInputDStream: Finding new files took 15 ms

2016-08-25 14:34:20,020 - [INFO] - from application in Thread-359 
16/08/25 14:34:20 INFO dstream.FileInputDStream: New files at time 1472106860000 ms:

2016-08-25 14:34:20,020 - [INFO] - from application in Thread-359 


2016-08-25 14:34:20,024 - [INFO] - from application in Thread-359 
16/08/25 14:34:20 INFO scheduler.JobScheduler: Added jobs for time 1472106860000 ms

2016-08-25 14:34:25,107 - [INFO] - from application in Thread-359 
16/08/25 14:34:25 INFO dstream.FileInputDStream: Finding new files took 101 ms

2016-08-25 14:34:25,109 - [INFO] - from application in Thread-359 
16/08/25 14:34:25 INFO dstream.FileInputDStream: New files at time 1472106865000 ms:

2016-08-25 14:34:25,109 - [INFO] - from application in Thread-359 


2016-08-25 14:34:25,113 - [INFO] - from application in Thread-359 
16/08/25 14:34:25 INFO scheduler.JobScheduler: Added jobs for time 1472106865000 ms

2016-08-25 14:34:25,777 - [INFO] - from application in Thread-359 
16/08/25 14:34:25 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:34:30,388 - [INFO] - from application in Thread-359 
16/08/25 14:34:30 INFO dstream.FileInputDStream: Finding new files took 382 ms

2016-08-25 14:34:30,388 - [INFO] - from application in Thread-359 
16/08/25 14:34:30 INFO dstream.FileInputDStream: New files at time 1472106870000 ms:

2016-08-25 14:34:30,388 - [INFO] - from application in Thread-359 


2016-08-25 14:34:30,393 - [INFO] - from application in Thread-359 
16/08/25 14:34:30 INFO scheduler.JobScheduler: Added jobs for time 1472106870000 ms

2016-08-25 14:34:35,017 - [INFO] - from application in Thread-359 
16/08/25 14:34:35 INFO dstream.FileInputDStream: Finding new files took 14 ms

2016-08-25 14:34:35,019 - [INFO] - from application in Thread-359 
16/08/25 14:34:35 INFO dstream.FileInputDStream: New files at time 1472106875000 ms:

2016-08-25 14:34:35,019 - [INFO] - from application in Thread-359 


2016-08-25 14:34:35,020 - [INFO] - from application in Thread-359 
16/08/25 14:34:35 INFO scheduler.JobScheduler: Added jobs for time 1472106875000 ms

2016-08-25 14:34:40,273 - [INFO] - from application in Thread-359 
16/08/25 14:34:40 INFO dstream.FileInputDStream: Finding new files took 269 ms

2016-08-25 14:34:40,274 - [INFO] - from application in Thread-359 
16/08/25 14:34:40 INFO dstream.FileInputDStream: New files at time 1472106880000 ms:

2016-08-25 14:34:40,274 - [INFO] - from application in Thread-359 


2016-08-25 14:34:40,279 - [INFO] - from application in Thread-359 
16/08/25 14:34:40 INFO scheduler.JobScheduler: Added jobs for time 1472106880000 ms

2016-08-25 14:34:40,779 - [INFO] - from application in Thread-359 
16/08/25 14:34:40 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:34:45,029 - [INFO] - from application in Thread-359 
16/08/25 14:34:45 INFO dstream.FileInputDStream: Finding new files took 24 ms

2016-08-25 14:34:45,029 - [INFO] - from application in Thread-359 
16/08/25 14:34:45 INFO dstream.FileInputDStream: New files at time 1472106885000 ms:

2016-08-25 14:34:45,029 - [INFO] - from application in Thread-359 


2016-08-25 14:34:45,033 - [INFO] - from application in Thread-359 
16/08/25 14:34:45 INFO scheduler.JobScheduler: Added jobs for time 1472106885000 ms

2016-08-25 14:34:50,016 - [INFO] - from application in Thread-359 
16/08/25 14:34:50 INFO dstream.FileInputDStream: Finding new files took 13 ms

2016-08-25 14:34:50,017 - [INFO] - from application in Thread-359 
16/08/25 14:34:50 INFO dstream.FileInputDStream: New files at time 1472106890000 ms:

2016-08-25 14:34:50,017 - [INFO] - from application in Thread-359 


2016-08-25 14:34:50,020 - [INFO] - from application in Thread-359 
16/08/25 14:34:50 INFO scheduler.JobScheduler: Added jobs for time 1472106890000 ms

2016-08-25 14:34:55,123 - [INFO] - from application in Thread-359 
16/08/25 14:34:55 INFO dstream.FileInputDStream: Finding new files took 119 ms

2016-08-25 14:34:55,123 - [INFO] - from application in Thread-359 
16/08/25 14:34:55 INFO dstream.FileInputDStream: New files at time 1472106895000 ms:

2016-08-25 14:34:55,123 - [INFO] - from application in Thread-359 


2016-08-25 14:34:55,127 - [INFO] - from application in Thread-359 
16/08/25 14:34:55 INFO scheduler.JobScheduler: Added jobs for time 1472106895000 ms

2016-08-25 14:34:55,779 - [INFO] - from application in Thread-359 
16/08/25 14:34:55 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:35:00,033 - [INFO] - from application in Thread-359 
16/08/25 14:35:00 INFO dstream.FileInputDStream: Finding new files took 28 ms

2016-08-25 14:35:00,034 - [INFO] - from application in Thread-359 
16/08/25 14:35:00 INFO dstream.FileInputDStream: New files at time 1472106900000 ms:

2016-08-25 14:35:00,034 - [INFO] - from application in Thread-359 


2016-08-25 14:35:00,038 - [INFO] - from application in Thread-359 
16/08/25 14:35:00 INFO scheduler.JobScheduler: Added jobs for time 1472106900000 ms

2016-08-25 14:35:05,161 - [INFO] - from application in Thread-359 
16/08/25 14:35:05 INFO dstream.FileInputDStream: Finding new files took 157 ms

2016-08-25 14:35:05,161 - [INFO] - from application in Thread-359 
16/08/25 14:35:05 INFO dstream.FileInputDStream: New files at time 1472106905000 ms:

2016-08-25 14:35:05,161 - [INFO] - from application in Thread-359 


2016-08-25 14:35:05,164 - [INFO] - from application in Thread-359 
16/08/25 14:35:05 INFO scheduler.JobScheduler: Added jobs for time 1472106905000 ms

2016-08-25 14:35:10,021 - [INFO] - from application in Thread-359 
16/08/25 14:35:10 INFO dstream.FileInputDStream: Finding new files took 17 ms

2016-08-25 14:35:10,021 - [INFO] - from application in Thread-359 
16/08/25 14:35:10 INFO dstream.FileInputDStream: New files at time 1472106910000 ms:

2016-08-25 14:35:10,021 - [INFO] - from application in Thread-359 


2016-08-25 14:35:10,027 - [INFO] - from application in Thread-359 
16/08/25 14:35:10 INFO scheduler.JobScheduler: Added jobs for time 1472106910000 ms

2016-08-25 14:35:10,779 - [INFO] - from application in Thread-359 
16/08/25 14:35:10 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:35:15,047 - [INFO] - from application in Thread-359 
16/08/25 14:35:15 INFO dstream.FileInputDStream: Finding new files took 43 ms

2016-08-25 14:35:15,047 - [INFO] - from application in Thread-359 
16/08/25 14:35:15 INFO dstream.FileInputDStream: New files at time 1472106915000 ms:

2016-08-25 14:35:15,047 - [INFO] - from application in Thread-359 


2016-08-25 14:35:15,051 - [INFO] - from application in Thread-359 
16/08/25 14:35:15 INFO scheduler.JobScheduler: Added jobs for time 1472106915000 ms

2016-08-25 14:35:20,012 - [INFO] - from application in Thread-359 
16/08/25 14:35:20 INFO dstream.FileInputDStream: Finding new files took 8 ms

2016-08-25 14:35:20,012 - [INFO] - from application in Thread-359 
16/08/25 14:35:20 INFO dstream.FileInputDStream: New files at time 1472106920000 ms:

2016-08-25 14:35:20,012 - [INFO] - from application in Thread-359 


2016-08-25 14:35:20,016 - [INFO] - from application in Thread-359 
16/08/25 14:35:20 INFO scheduler.JobScheduler: Added jobs for time 1472106920000 ms

2016-08-25 14:35:25,008 - [INFO] - from application in Thread-359 
16/08/25 14:35:25 INFO dstream.FileInputDStream: Finding new files took 2 ms

2016-08-25 14:35:25,008 - [INFO] - from application in Thread-359 
16/08/25 14:35:25 INFO dstream.FileInputDStream: New files at time 1472106925000 ms:

2016-08-25 14:35:25,008 - [INFO] - from application in Thread-359 


2016-08-25 14:35:25,012 - [INFO] - from application in Thread-359 
16/08/25 14:35:25 INFO scheduler.JobScheduler: Added jobs for time 1472106925000 ms

2016-08-25 14:35:25,776 - [INFO] - from application in Thread-359 
16/08/25 14:35:25 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:35:30,146 - [INFO] - from application in Thread-359 
16/08/25 14:35:30 INFO dstream.FileInputDStream: Finding new files took 141 ms

2016-08-25 14:35:30,146 - [INFO] - from application in Thread-359 
16/08/25 14:35:30 INFO dstream.FileInputDStream: New files at time 1472106930000 ms:

2016-08-25 14:35:30,146 - [INFO] - from application in Thread-359 


2016-08-25 14:35:30,151 - [INFO] - from application in Thread-359 
16/08/25 14:35:30 INFO scheduler.JobScheduler: Added jobs for time 1472106930000 ms

2016-08-25 14:35:35,094 - [INFO] - from application in Thread-359 
16/08/25 14:35:35 INFO dstream.FileInputDStream: Finding new files took 88 ms

2016-08-25 14:35:35,094 - [INFO] - from application in Thread-359 
16/08/25 14:35:35 INFO dstream.FileInputDStream: New files at time 1472106935000 ms:

2016-08-25 14:35:35,094 - [INFO] - from application in Thread-359 


2016-08-25 14:35:35,098 - [INFO] - from application in Thread-359 
16/08/25 14:35:35 INFO scheduler.JobScheduler: Added jobs for time 1472106935000 ms

2016-08-25 14:35:40,022 - [INFO] - from application in Thread-359 
16/08/25 14:35:40 INFO dstream.FileInputDStream: Finding new files took 18 ms

2016-08-25 14:35:40,022 - [INFO] - from application in Thread-359 
16/08/25 14:35:40 INFO dstream.FileInputDStream: New files at time 1472106940000 ms:

2016-08-25 14:35:40,022 - [INFO] - from application in Thread-359 


2016-08-25 14:35:40,026 - [INFO] - from application in Thread-359 
16/08/25 14:35:40 INFO scheduler.JobScheduler: Added jobs for time 1472106940000 ms

2016-08-25 14:35:40,777 - [INFO] - from application in Thread-359 
16/08/25 14:35:40 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:35:45,009 - [INFO] - from application in Thread-359 
16/08/25 14:35:45 INFO dstream.FileInputDStream: Finding new files took 6 ms

2016-08-25 14:35:45,009 - [INFO] - from application in Thread-359 
16/08/25 14:35:45 INFO dstream.FileInputDStream: New files at time 1472106945000 ms:

2016-08-25 14:35:45,009 - [INFO] - from application in Thread-359 


2016-08-25 14:35:45,012 - [INFO] - from application in Thread-359 
16/08/25 14:35:45 INFO scheduler.JobScheduler: Added jobs for time 1472106945000 ms

2016-08-25 14:35:50,036 - [INFO] - from application in Thread-359 
16/08/25 14:35:50 INFO dstream.FileInputDStream: Finding new files took 33 ms

2016-08-25 14:35:50,036 - [INFO] - from application in Thread-359 
16/08/25 14:35:50 INFO dstream.FileInputDStream: New files at time 1472106950000 ms:

2016-08-25 14:35:50,036 - [INFO] - from application in Thread-359 


2016-08-25 14:35:50,039 - [INFO] - from application in Thread-359 
16/08/25 14:35:50 INFO scheduler.JobScheduler: Added jobs for time 1472106950000 ms

2016-08-25 14:35:55,010 - [INFO] - from application in Thread-359 
16/08/25 14:35:55 INFO dstream.FileInputDStream: Finding new files took 6 ms

2016-08-25 14:35:55,010 - [INFO] - from application in Thread-359 
16/08/25 14:35:55 INFO dstream.FileInputDStream: New files at time 1472106955000 ms:

2016-08-25 14:35:55,010 - [INFO] - from application in Thread-359 


2016-08-25 14:35:55,013 - [INFO] - from application in Thread-359 
16/08/25 14:35:55 INFO scheduler.JobScheduler: Added jobs for time 1472106955000 ms

2016-08-25 14:35:55,778 - [INFO] - from application in Thread-359 
16/08/25 14:35:55 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:36:00,129 - [INFO] - from application in Thread-359 
16/08/25 14:36:00 INFO dstream.FileInputDStream: Finding new files took 125 ms

2016-08-25 14:36:00,129 - [INFO] - from application in Thread-359 
16/08/25 14:36:00 INFO dstream.FileInputDStream: New files at time 1472106960000 ms:

2016-08-25 14:36:00,129 - [INFO] - from application in Thread-359 


2016-08-25 14:36:00,132 - [INFO] - from application in Thread-359 
16/08/25 14:36:00 INFO scheduler.JobScheduler: Added jobs for time 1472106960000 ms

2016-08-25 14:36:05,047 - [INFO] - from application in Thread-359 
16/08/25 14:36:05 INFO dstream.FileInputDStream: Finding new files took 42 ms

2016-08-25 14:36:05,047 - [INFO] - from application in Thread-359 
16/08/25 14:36:05 INFO dstream.FileInputDStream: New files at time 1472106965000 ms:

2016-08-25 14:36:05,047 - [INFO] - from application in Thread-359 


2016-08-25 14:36:05,051 - [INFO] - from application in Thread-359 
16/08/25 14:36:05 INFO scheduler.JobScheduler: Added jobs for time 1472106965000 ms

2016-08-25 14:36:10,073 - [INFO] - from application in Thread-359 
16/08/25 14:36:10 INFO dstream.FileInputDStream: Finding new files took 70 ms

2016-08-25 14:36:10,073 - [INFO] - from application in Thread-359 
16/08/25 14:36:10 INFO dstream.FileInputDStream: New files at time 1472106970000 ms:

2016-08-25 14:36:10,073 - [INFO] - from application in Thread-359 


2016-08-25 14:36:10,076 - [INFO] - from application in Thread-359 
16/08/25 14:36:10 INFO scheduler.JobScheduler: Added jobs for time 1472106970000 ms

2016-08-25 14:36:10,777 - [INFO] - from application in Thread-359 
16/08/25 14:36:10 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:36:15,027 - [INFO] - from application in Thread-359 
16/08/25 14:36:15 INFO dstream.FileInputDStream: Finding new files took 24 ms

2016-08-25 14:36:15,027 - [INFO] - from application in Thread-359 
16/08/25 14:36:15 INFO dstream.FileInputDStream: New files at time 1472106975000 ms:

2016-08-25 14:36:15,027 - [INFO] - from application in Thread-359 


2016-08-25 14:36:15,032 - [INFO] - from application in Thread-359 
16/08/25 14:36:15 INFO scheduler.JobScheduler: Added jobs for time 1472106975000 ms

2016-08-25 14:36:20,057 - [INFO] - from application in Thread-359 
16/08/25 14:36:20 INFO dstream.FileInputDStream: Finding new files took 52 ms

2016-08-25 14:36:20,057 - [INFO] - from application in Thread-359 
16/08/25 14:36:20 INFO dstream.FileInputDStream: New files at time 1472106980000 ms:

2016-08-25 14:36:20,057 - [INFO] - from application in Thread-359 


2016-08-25 14:36:20,061 - [INFO] - from application in Thread-359 
16/08/25 14:36:20 INFO scheduler.JobScheduler: Added jobs for time 1472106980000 ms

2016-08-25 14:36:25,008 - [INFO] - from application in Thread-359 
16/08/25 14:36:25 INFO dstream.FileInputDStream: Finding new files took 5 ms

2016-08-25 14:36:25,008 - [INFO] - from application in Thread-359 
16/08/25 14:36:25 INFO dstream.FileInputDStream: New files at time 1472106985000 ms:

2016-08-25 14:36:25,008 - [INFO] - from application in Thread-359 


2016-08-25 14:36:25,012 - [INFO] - from application in Thread-359 
16/08/25 14:36:25 INFO scheduler.JobScheduler: Added jobs for time 1472106985000 ms

2016-08-25 14:36:25,779 - [INFO] - from application in Thread-359 
16/08/25 14:36:25 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:36:30,036 - [INFO] - from application in Thread-359 
16/08/25 14:36:30 INFO dstream.FileInputDStream: Finding new files took 33 ms

2016-08-25 14:36:30,036 - [INFO] - from application in Thread-359 
16/08/25 14:36:30 INFO dstream.FileInputDStream: New files at time 1472106990000 ms:

2016-08-25 14:36:30,037 - [INFO] - from application in Thread-359 


2016-08-25 14:36:30,041 - [INFO] - from application in Thread-359 
16/08/25 14:36:30 INFO scheduler.JobScheduler: Added jobs for time 1472106990000 ms

2016-08-25 14:36:35,173 - [INFO] - from application in Thread-359 
16/08/25 14:36:35 INFO dstream.FileInputDStream: Finding new files took 169 ms

2016-08-25 14:36:35,173 - [INFO] - from application in Thread-359 
16/08/25 14:36:35 INFO dstream.FileInputDStream: New files at time 1472106995000 ms:

2016-08-25 14:36:35,173 - [INFO] - from application in Thread-359 


2016-08-25 14:36:35,177 - [INFO] - from application in Thread-359 
16/08/25 14:36:35 INFO scheduler.JobScheduler: Added jobs for time 1472106995000 ms

2016-08-25 14:36:40,061 - [INFO] - from application in Thread-359 
16/08/25 14:36:40 INFO dstream.FileInputDStream: Finding new files took 58 ms

2016-08-25 14:36:40,061 - [INFO] - from application in Thread-359 
16/08/25 14:36:40 INFO dstream.FileInputDStream: New files at time 1472107000000 ms:

2016-08-25 14:36:40,061 - [INFO] - from application in Thread-359 


2016-08-25 14:36:40,064 - [INFO] - from application in Thread-359 
16/08/25 14:36:40 INFO scheduler.JobScheduler: Added jobs for time 1472107000000 ms

2016-08-25 14:36:40,779 - [INFO] - from application in Thread-359 
16/08/25 14:36:40 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:36:45,028 - [INFO] - from application in Thread-359 
16/08/25 14:36:45 INFO dstream.FileInputDStream: Finding new files took 25 ms

2016-08-25 14:36:45,028 - [INFO] - from application in Thread-359 
16/08/25 14:36:45 INFO dstream.FileInputDStream: New files at time 1472107005000 ms:

2016-08-25 14:36:45,028 - [INFO] - from application in Thread-359 


2016-08-25 14:36:45,032 - [INFO] - from application in Thread-359 
16/08/25 14:36:45 INFO scheduler.JobScheduler: Added jobs for time 1472107005000 ms

2016-08-25 14:36:50,022 - [INFO] - from application in Thread-359 
16/08/25 14:36:50 INFO dstream.FileInputDStream: Finding new files took 18 ms

2016-08-25 14:36:50,022 - [INFO] - from application in Thread-359 
16/08/25 14:36:50 INFO dstream.FileInputDStream: New files at time 1472107010000 ms:

2016-08-25 14:36:50,022 - [INFO] - from application in Thread-359 


2016-08-25 14:36:50,025 - [INFO] - from application in Thread-359 
16/08/25 14:36:50 INFO scheduler.JobScheduler: Added jobs for time 1472107010000 ms

2016-08-25 14:36:55,043 - [INFO] - from application in Thread-359 
16/08/25 14:36:55 INFO dstream.FileInputDStream: Finding new files took 40 ms

2016-08-25 14:36:55,043 - [INFO] - from application in Thread-359 
16/08/25 14:36:55 INFO dstream.FileInputDStream: New files at time 1472107015000 ms:

2016-08-25 14:36:55,043 - [INFO] - from application in Thread-359 


2016-08-25 14:36:55,045 - [INFO] - from application in Thread-359 
16/08/25 14:36:55 INFO scheduler.JobScheduler: Added jobs for time 1472107015000 ms

2016-08-25 14:36:55,777 - [INFO] - from application in Thread-359 
16/08/25 14:36:55 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:37:00,074 - [INFO] - from application in Thread-359 
16/08/25 14:37:00 INFO dstream.FileInputDStream: Finding new files took 70 ms

2016-08-25 14:37:00,074 - [INFO] - from application in Thread-359 
16/08/25 14:37:00 INFO dstream.FileInputDStream: New files at time 1472107020000 ms:

2016-08-25 14:37:00,074 - [INFO] - from application in Thread-359 


2016-08-25 14:37:00,078 - [INFO] - from application in Thread-359 
16/08/25 14:37:00 INFO scheduler.JobScheduler: Added jobs for time 1472107020000 ms

2016-08-25 14:37:05,153 - [INFO] - from application in Thread-359 
16/08/25 14:37:05 INFO dstream.FileInputDStream: Finding new files took 150 ms

2016-08-25 14:37:05,153 - [INFO] - from application in Thread-359 
16/08/25 14:37:05 INFO dstream.FileInputDStream: New files at time 1472107025000 ms:

2016-08-25 14:37:05,153 - [INFO] - from application in Thread-359 


2016-08-25 14:37:05,157 - [INFO] - from application in Thread-359 
16/08/25 14:37:05 INFO scheduler.JobScheduler: Added jobs for time 1472107025000 ms

2016-08-25 14:37:10,012 - [INFO] - from application in Thread-359 
16/08/25 14:37:10 INFO dstream.FileInputDStream: Finding new files took 7 ms

2016-08-25 14:37:10,012 - [INFO] - from application in Thread-359 
16/08/25 14:37:10 INFO dstream.FileInputDStream: New files at time 1472107030000 ms:

2016-08-25 14:37:10,012 - [INFO] - from application in Thread-359 


2016-08-25 14:37:10,015 - [INFO] - from application in Thread-359 
16/08/25 14:37:10 INFO scheduler.JobScheduler: Added jobs for time 1472107030000 ms

2016-08-25 14:37:10,779 - [INFO] - from application in Thread-359 
16/08/25 14:37:10 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:37:15,006 - [INFO] - from application in Thread-359 
16/08/25 14:37:15 INFO dstream.FileInputDStream: Finding new files took 5 ms

2016-08-25 14:37:15,006 - [INFO] - from application in Thread-359 
16/08/25 14:37:15 INFO dstream.FileInputDStream: New files at time 1472107035000 ms:

2016-08-25 14:37:15,006 - [INFO] - from application in Thread-359 


2016-08-25 14:37:15,010 - [INFO] - from application in Thread-359 
16/08/25 14:37:15 INFO scheduler.JobScheduler: Added jobs for time 1472107035000 ms

2016-08-25 14:37:20,045 - [INFO] - from application in Thread-359 
16/08/25 14:37:20 INFO dstream.FileInputDStream: Finding new files took 41 ms

2016-08-25 14:37:20,045 - [INFO] - from application in Thread-359 
16/08/25 14:37:20 INFO dstream.FileInputDStream: New files at time 1472107040000 ms:

2016-08-25 14:37:20,045 - [INFO] - from application in Thread-359 


2016-08-25 14:37:20,049 - [INFO] - from application in Thread-359 
16/08/25 14:37:20 INFO scheduler.JobScheduler: Added jobs for time 1472107040000 ms

2016-08-25 14:37:25,061 - [INFO] - from application in Thread-359 
16/08/25 14:37:25 INFO dstream.FileInputDStream: Finding new files took 57 ms

2016-08-25 14:37:25,061 - [INFO] - from application in Thread-359 
16/08/25 14:37:25 INFO dstream.FileInputDStream: New files at time 1472107045000 ms:

2016-08-25 14:37:25,061 - [INFO] - from application in Thread-359 


2016-08-25 14:37:25,064 - [INFO] - from application in Thread-359 
16/08/25 14:37:25 INFO scheduler.JobScheduler: Added jobs for time 1472107045000 ms

2016-08-25 14:37:25,779 - [INFO] - from application in Thread-359 
16/08/25 14:37:25 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:37:30,058 - [INFO] - from application in Thread-359 
16/08/25 14:37:30 INFO dstream.FileInputDStream: Finding new files took 55 ms

2016-08-25 14:37:30,058 - [INFO] - from application in Thread-359 
16/08/25 14:37:30 INFO dstream.FileInputDStream: New files at time 1472107050000 ms:

2016-08-25 14:37:30,058 - [INFO] - from application in Thread-359 


2016-08-25 14:37:30,062 - [INFO] - from application in Thread-359 
16/08/25 14:37:30 INFO scheduler.JobScheduler: Added jobs for time 1472107050000 ms

2016-08-25 14:37:35,015 - [INFO] - from application in Thread-359 
16/08/25 14:37:35 INFO dstream.FileInputDStream: Finding new files took 11 ms

2016-08-25 14:37:35,015 - [INFO] - from application in Thread-359 
16/08/25 14:37:35 INFO dstream.FileInputDStream: New files at time 1472107055000 ms:

2016-08-25 14:37:35,015 - [INFO] - from application in Thread-359 


2016-08-25 14:37:35,018 - [INFO] - from application in Thread-359 
16/08/25 14:37:35 INFO scheduler.JobScheduler: Added jobs for time 1472107055000 ms

2016-08-25 14:37:40,779 - [INFO] - from application in Thread-359 
16/08/25 14:37:40 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:37:40,849 - [INFO] - from application in Thread-359 
16/08/25 14:37:40 INFO dstream.FileInputDStream: Finding new files took 846 ms

2016-08-25 14:37:40,850 - [INFO] - from application in Thread-359 
16/08/25 14:37:40 INFO dstream.FileInputDStream: New files at time 1472107060000 ms:

2016-08-25 14:37:40,850 - [INFO] - from application in Thread-359 


2016-08-25 14:37:40,854 - [INFO] - from application in Thread-359 
16/08/25 14:37:40 INFO scheduler.JobScheduler: Added jobs for time 1472107060000 ms

2016-08-25 14:37:45,010 - [INFO] - from application in Thread-359 
16/08/25 14:37:45 INFO dstream.FileInputDStream: Finding new files took 7 ms

2016-08-25 14:37:45,010 - [INFO] - from application in Thread-359 
16/08/25 14:37:45 INFO dstream.FileInputDStream: New files at time 1472107065000 ms:

2016-08-25 14:37:45,010 - [INFO] - from application in Thread-359 


2016-08-25 14:37:45,015 - [INFO] - from application in Thread-359 
16/08/25 14:37:45 INFO scheduler.JobScheduler: Added jobs for time 1472107065000 ms

2016-08-25 14:37:50,019 - [INFO] - from application in Thread-359 
16/08/25 14:37:50 INFO dstream.FileInputDStream: Finding new files took 15 ms

2016-08-25 14:37:50,019 - [INFO] - from application in Thread-359 
16/08/25 14:37:50 INFO dstream.FileInputDStream: New files at time 1472107070000 ms:

2016-08-25 14:37:50,019 - [INFO] - from application in Thread-359 


2016-08-25 14:37:50,022 - [INFO] - from application in Thread-359 
16/08/25 14:37:50 INFO scheduler.JobScheduler: Added jobs for time 1472107070000 ms

2016-08-25 14:37:55,278 - [INFO] - from application in Thread-359 
16/08/25 14:37:55 INFO dstream.FileInputDStream: Finding new files took 273 ms

2016-08-25 14:37:55,278 - [INFO] - from application in Thread-359 
16/08/25 14:37:55 INFO dstream.FileInputDStream: New files at time 1472107075000 ms:

2016-08-25 14:37:55,278 - [INFO] - from application in Thread-359 


2016-08-25 14:37:55,282 - [INFO] - from application in Thread-359 
16/08/25 14:37:55 INFO scheduler.JobScheduler: Added jobs for time 1472107075000 ms

2016-08-25 14:37:55,777 - [INFO] - from application in Thread-359 
16/08/25 14:37:55 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:38:00,057 - [INFO] - from application in Thread-359 
16/08/25 14:38:00 INFO dstream.FileInputDStream: Finding new files took 53 ms

2016-08-25 14:38:00,057 - [INFO] - from application in Thread-359 
16/08/25 14:38:00 INFO dstream.FileInputDStream: New files at time 1472107080000 ms:

2016-08-25 14:38:00,057 - [INFO] - from application in Thread-359 


2016-08-25 14:38:00,060 - [INFO] - from application in Thread-359 
16/08/25 14:38:00 INFO scheduler.JobScheduler: Added jobs for time 1472107080000 ms

2016-08-25 14:38:05,072 - [INFO] - from application in Thread-359 
16/08/25 14:38:05 INFO dstream.FileInputDStream: Finding new files took 67 ms

2016-08-25 14:38:05,072 - [INFO] - from application in Thread-359 
16/08/25 14:38:05 INFO dstream.FileInputDStream: New files at time 1472107085000 ms:

2016-08-25 14:38:05,072 - [INFO] - from application in Thread-359 


2016-08-25 14:38:05,077 - [INFO] - from application in Thread-359 
16/08/25 14:38:05 INFO scheduler.JobScheduler: Added jobs for time 1472107085000 ms

2016-08-25 14:38:10,185 - [INFO] - from application in Thread-359 
16/08/25 14:38:10 INFO dstream.FileInputDStream: Finding new files took 181 ms

2016-08-25 14:38:10,185 - [INFO] - from application in Thread-359 
16/08/25 14:38:10 INFO dstream.FileInputDStream: New files at time 1472107090000 ms:

2016-08-25 14:38:10,185 - [INFO] - from application in Thread-359 


2016-08-25 14:38:10,189 - [INFO] - from application in Thread-359 
16/08/25 14:38:10 INFO scheduler.JobScheduler: Added jobs for time 1472107090000 ms

2016-08-25 14:38:10,778 - [INFO] - from application in Thread-359 
16/08/25 14:38:10 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:38:15,012 - [INFO] - from application in Thread-359 
16/08/25 14:38:15 INFO dstream.FileInputDStream: Finding new files took 8 ms

2016-08-25 14:38:15,012 - [INFO] - from application in Thread-359 
16/08/25 14:38:15 INFO dstream.FileInputDStream: New files at time 1472107095000 ms:

2016-08-25 14:38:15,012 - [INFO] - from application in Thread-359 


2016-08-25 14:38:15,015 - [INFO] - from application in Thread-359 
16/08/25 14:38:15 INFO scheduler.JobScheduler: Added jobs for time 1472107095000 ms

2016-08-25 14:38:20,046 - [INFO] - from application in Thread-359 
16/08/25 14:38:20 INFO dstream.FileInputDStream: Finding new files took 42 ms

2016-08-25 14:38:20,046 - [INFO] - from application in Thread-359 
16/08/25 14:38:20 INFO dstream.FileInputDStream: New files at time 1472107100000 ms:

2016-08-25 14:38:20,046 - [INFO] - from application in Thread-359 


2016-08-25 14:38:20,050 - [INFO] - from application in Thread-359 
16/08/25 14:38:20 INFO scheduler.JobScheduler: Added jobs for time 1472107100000 ms

2016-08-25 14:38:25,012 - [INFO] - from application in Thread-359 
16/08/25 14:38:25 INFO dstream.FileInputDStream: Finding new files took 7 ms

2016-08-25 14:38:25,012 - [INFO] - from application in Thread-359 
16/08/25 14:38:25 INFO dstream.FileInputDStream: New files at time 1472107105000 ms:

2016-08-25 14:38:25,012 - [INFO] - from application in Thread-359 


2016-08-25 14:38:25,015 - [INFO] - from application in Thread-359 
16/08/25 14:38:25 INFO scheduler.JobScheduler: Added jobs for time 1472107105000 ms

2016-08-25 14:38:25,778 - [INFO] - from application in Thread-359 
16/08/25 14:38:25 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:38:30,081 - [INFO] - from application in Thread-359 
16/08/25 14:38:30 INFO dstream.FileInputDStream: Finding new files took 76 ms

2016-08-25 14:38:30,081 - [INFO] - from application in Thread-359 
16/08/25 14:38:30 INFO dstream.FileInputDStream: New files at time 1472107110000 ms:

2016-08-25 14:38:30,081 - [INFO] - from application in Thread-359 


2016-08-25 14:38:30,086 - [INFO] - from application in Thread-359 
16/08/25 14:38:30 INFO scheduler.JobScheduler: Added jobs for time 1472107110000 ms

2016-08-25 14:38:35,038 - [INFO] - from application in Thread-359 
16/08/25 14:38:35 INFO dstream.FileInputDStream: Finding new files took 34 ms

2016-08-25 14:38:35,038 - [INFO] - from application in Thread-359 
16/08/25 14:38:35 INFO dstream.FileInputDStream: New files at time 1472107115000 ms:

2016-08-25 14:38:35,038 - [INFO] - from application in Thread-359 


2016-08-25 14:38:35,041 - [INFO] - from application in Thread-359 
16/08/25 14:38:35 INFO scheduler.JobScheduler: Added jobs for time 1472107115000 ms

2016-08-25 14:38:40,016 - [INFO] - from application in Thread-359 
16/08/25 14:38:40 INFO dstream.FileInputDStream: Finding new files took 13 ms

2016-08-25 14:38:40,016 - [INFO] - from application in Thread-359 
16/08/25 14:38:40 INFO dstream.FileInputDStream: New files at time 1472107120000 ms:

2016-08-25 14:38:40,016 - [INFO] - from application in Thread-359 


2016-08-25 14:38:40,021 - [INFO] - from application in Thread-359 
16/08/25 14:38:40 INFO scheduler.JobScheduler: Added jobs for time 1472107120000 ms

2016-08-25 14:38:40,779 - [INFO] - from application in Thread-359 
16/08/25 14:38:40 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:38:45,006 - [INFO] - from application in Thread-359 
16/08/25 14:38:45 INFO dstream.FileInputDStream: Finding new files took 5 ms

2016-08-25 14:38:45,006 - [INFO] - from application in Thread-359 
16/08/25 14:38:45 INFO dstream.FileInputDStream: New files at time 1472107125000 ms:

2016-08-25 14:38:45,006 - [INFO] - from application in Thread-359 


2016-08-25 14:38:45,011 - [INFO] - from application in Thread-359 
16/08/25 14:38:45 INFO scheduler.JobScheduler: Added jobs for time 1472107125000 ms

2016-08-25 14:38:50,016 - [INFO] - from application in Thread-359 
16/08/25 14:38:50 INFO dstream.FileInputDStream: Finding new files took 12 ms

2016-08-25 14:38:50,016 - [INFO] - from application in Thread-359 
16/08/25 14:38:50 INFO dstream.FileInputDStream: New files at time 1472107130000 ms:

2016-08-25 14:38:50,016 - [INFO] - from application in Thread-359 


2016-08-25 14:38:50,019 - [INFO] - from application in Thread-359 
16/08/25 14:38:50 INFO scheduler.JobScheduler: Added jobs for time 1472107130000 ms

2016-08-25 14:38:55,014 - [INFO] - from application in Thread-359 
16/08/25 14:38:55 INFO dstream.FileInputDStream: Finding new files took 11 ms

2016-08-25 14:38:55,014 - [INFO] - from application in Thread-359 
16/08/25 14:38:55 INFO dstream.FileInputDStream: New files at time 1472107135000 ms:

2016-08-25 14:38:55,014 - [INFO] - from application in Thread-359 


2016-08-25 14:38:55,017 - [INFO] - from application in Thread-359 
16/08/25 14:38:55 INFO scheduler.JobScheduler: Added jobs for time 1472107135000 ms

2016-08-25 14:38:55,777 - [INFO] - from application in Thread-359 
16/08/25 14:38:55 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:39:00,011 - [INFO] - from application in Thread-359 
16/08/25 14:39:00 INFO dstream.FileInputDStream: Finding new files took 7 ms

2016-08-25 14:39:00,011 - [INFO] - from application in Thread-359 
16/08/25 14:39:00 INFO dstream.FileInputDStream: New files at time 1472107140000 ms:

2016-08-25 14:39:00,011 - [INFO] - from application in Thread-359 


2016-08-25 14:39:00,014 - [INFO] - from application in Thread-359 
16/08/25 14:39:00 INFO scheduler.JobScheduler: Added jobs for time 1472107140000 ms

2016-08-25 14:39:05,068 - [INFO] - from application in Thread-359 
16/08/25 14:39:05 INFO dstream.FileInputDStream: Finding new files took 65 ms

2016-08-25 14:39:05,068 - [INFO] - from application in Thread-359 
16/08/25 14:39:05 INFO dstream.FileInputDStream: New files at time 1472107145000 ms:

2016-08-25 14:39:05,068 - [INFO] - from application in Thread-359 


2016-08-25 14:39:05,072 - [INFO] - from application in Thread-359 
16/08/25 14:39:05 INFO scheduler.JobScheduler: Added jobs for time 1472107145000 ms

2016-08-25 14:39:10,023 - [INFO] - from application in Thread-359 
16/08/25 14:39:10 INFO dstream.FileInputDStream: Finding new files took 20 ms

2016-08-25 14:39:10,023 - [INFO] - from application in Thread-359 
16/08/25 14:39:10 INFO dstream.FileInputDStream: New files at time 1472107150000 ms:

2016-08-25 14:39:10,023 - [INFO] - from application in Thread-359 


2016-08-25 14:39:10,025 - [INFO] - from application in Thread-359 
16/08/25 14:39:10 INFO scheduler.JobScheduler: Added jobs for time 1472107150000 ms

2016-08-25 14:39:10,778 - [INFO] - from application in Thread-359 
16/08/25 14:39:10 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 14:39:12,815 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR cluster.SparkDeploySchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED

2016-08-25 14:39:12,817 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 

2016-08-25 14:39:12,821 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.TaskSchedulerImpl: Cancelling stage 1

2016-08-25 14:39:12,822 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.DAGScheduler: ResultStage 1 (print at HDFSWordCount.scala:20) failed in 542.046 s

2016-08-25 14:39:12,823 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.DAGScheduler: Job 0 failed: print at HDFSWordCount.scala:20, took 542.191500 s

2016-08-25 14:39:12,824 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106610000 ms.0 from job set of time 1472106610000 ms

2016-08-25 14:39:12,825 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 542.824 s for time 1472106610000 ms (execution: 542.223 s)

2016-08-25 14:39:12,827 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106615000 ms.0 from job set of time 1472106615000 ms

2016-08-25 14:39:12,831 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106610000 ms.0

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1283)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1271)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1270)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1270)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at scala.Option.foreach(Option.scala:236)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:697)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1496)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1458)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1447)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:567)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,832 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO dstream.FileInputDStream: Cleared 0 old files that were older than 1472106550000 ms: 

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106615000 ms.0 from job set of time 1472106615000 ms

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 537.831 s for time 1472106615000 ms (execution: 0.004 s)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1283)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1271)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1270)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1270)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at scala.Option.foreach(Option.scala:236)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:697)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1496)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1458)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1447)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:567)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106620000 ms.0 from job set of time 1472106620000 ms

2016-08-25 14:39:12,833 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106620000 ms.0 from job set of time 1472106620000 ms

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 532.833 s for time 1472106620000 ms (execution: 0.001 s)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106625000 ms.0 from job set of time 1472106625000 ms

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106615000 ms.0

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,834 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106620000 ms.0

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106625000 ms.0 from job set of time 1472106625000 ms

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 527.834 s for time 1472106625000 ms (execution: 0.000 s)

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.ReceivedBlockTracker: Deleting batches ArrayBuffer()

2016-08-25 14:39:12,835 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106630000 ms.0 from job set of time 1472106630000 ms

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106625000 ms.0

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO streaming.StreamingContext: Invoking stop(stopGracefully=false) from shutdown hook

2016-08-25 14:39:12,836 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobGenerator: Stopping JobGenerator immediately

2016-08-25 14:39:12,837 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO util.RecurringTimer: Stopped timer for JobGenerator after time 1472107150000

2016-08-25 14:39:12,837 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.InputInfoTracker: remove old batch metadata: 

2016-08-25 14:39:12,837 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106630000 ms.0 from job set of time 1472106630000 ms

2016-08-25 14:39:12,838 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 522.837 s for time 1472106630000 ms (execution: 0.002 s)

2016-08-25 14:39:12,838 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106635000 ms.0 from job set of time 1472106635000 ms

2016-08-25 14:39:12,838 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO rdd.ShuffledRDD: Removing RDD 4 from persistence list

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106630000 ms.0

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,839 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,840 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobGenerator: Stopped JobGenerator

2016-08-25 14:39:12,840 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106635000 ms.0 from job set of time 1472106635000 ms

2016-08-25 14:39:12,840 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 517.840 s for time 1472106635000 ms (execution: 0.002 s)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106640000 ms.0 from job set of time 1472106640000 ms

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106635000 ms.0

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,841 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,842 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106640000 ms.0 from job set of time 1472106640000 ms

2016-08-25 14:39:12,843 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 512.842 s for time 1472106640000 ms (execution: 0.001 s)

2016-08-25 14:39:12,843 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106645000 ms.0 from job set of time 1472106645000 ms

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106640000 ms.0

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static/streaming,null}

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/streaming/batch/json,null}

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/streaming/batch,null}

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/streaming/json,null}

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/streaming,null}

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}

2016-08-25 14:39:12,844 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}

2016-08-25 14:39:12,845 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}

2016-08-25 14:39:12,845 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}

2016-08-25 14:39:12,845 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}

2016-08-25 14:39:12,845 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}

2016-08-25 14:39:12,845 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}

2016-08-25 14:39:12,845 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}

2016-08-25 14:39:12,845 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}

2016-08-25 14:39:12,845 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106645000 ms.0 from job set of time 1472106645000 ms

2016-08-25 14:39:12,845 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}

2016-08-25 14:39:12,845 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}

2016-08-25 14:39:12,845 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 507.845 s for time 1472106645000 ms (execution: 0.002 s)

2016-08-25 14:39:12,845 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106650000 ms.0 from job set of time 1472106650000 ms

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106645000 ms.0

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,846 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO storage.BlockManager: Removing RDD 4

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}

2016-08-25 14:39:12,847 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}

2016-08-25 14:39:12,848 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106650000 ms.0 from job set of time 1472106650000 ms

2016-08-25 14:39:12,848 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 502.848 s for time 1472106650000 ms (execution: 0.002 s)

2016-08-25 14:39:12,849 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106655000 ms.0 from job set of time 1472106655000 ms

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106650000 ms.0

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,850 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,851 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106655000 ms.0 from job set of time 1472106655000 ms

2016-08-25 14:39:12,851 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 497.851 s for time 1472106655000 ms (execution: 0.002 s)

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106660000 ms.0 from job set of time 1472106660000 ms

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106655000 ms.0

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,852 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,853 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,854 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106660000 ms.0 from job set of time 1472106660000 ms

2016-08-25 14:39:12,855 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 492.854 s for time 1472106660000 ms (execution: 0.002 s)

2016-08-25 14:39:12,855 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106665000 ms.0 from job set of time 1472106665000 ms

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106660000 ms.0

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,856 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,857 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106665000 ms.0 from job set of time 1472106665000 ms

2016-08-25 14:39:12,857 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 487.857 s for time 1472106665000 ms (execution: 0.002 s)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106670000 ms.0 from job set of time 1472106670000 ms

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106665000 ms.0

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,858 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,859 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106670000 ms.0 from job set of time 1472106670000 ms

2016-08-25 14:39:12,860 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 482.859 s for time 1472106670000 ms (execution: 0.001 s)

2016-08-25 14:39:12,860 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106675000 ms.0 from job set of time 1472106675000 ms

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106670000 ms.0

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,861 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,862 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106675000 ms.0 from job set of time 1472106675000 ms

2016-08-25 14:39:12,862 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 477.862 s for time 1472106675000 ms (execution: 0.002 s)

2016-08-25 14:39:12,862 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106680000 ms.0 from job set of time 1472106680000 ms

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106675000 ms.0

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,863 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,864 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106680000 ms.0 from job set of time 1472106680000 ms

2016-08-25 14:39:12,864 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 472.864 s for time 1472106680000 ms (execution: 0.002 s)

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106685000 ms.0 from job set of time 1472106685000 ms

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106680000 ms.0

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,865 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,866 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,867 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106685000 ms.0 from job set of time 1472106685000 ms

2016-08-25 14:39:12,867 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 467.866 s for time 1472106685000 ms (execution: 0.001 s)

2016-08-25 14:39:12,867 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106690000 ms.0 from job set of time 1472106690000 ms

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106685000 ms.0

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,868 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,871 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106690000 ms.0 from job set of time 1472106690000 ms

2016-08-25 14:39:12,871 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 462.871 s for time 1472106690000 ms (execution: 0.004 s)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106695000 ms.0 from job set of time 1472106695000 ms

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106690000 ms.0

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,872 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,873 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,873 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,875 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106695000 ms.0 from job set of time 1472106695000 ms

2016-08-25 14:39:12,875 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 457.875 s for time 1472106695000 ms (execution: 0.003 s)

2016-08-25 14:39:12,876 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106700000 ms.0 from job set of time 1472106700000 ms

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106695000 ms.0

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,877 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,878 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,878 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,878 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,878 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,879 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106700000 ms.0 from job set of time 1472106700000 ms

2016-08-25 14:39:12,879 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 452.878 s for time 1472106700000 ms (execution: 0.002 s)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106705000 ms.0 from job set of time 1472106705000 ms

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106700000 ms.0

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,881 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106705000 ms.0 from job set of time 1472106705000 ms

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 447.881 s for time 1472106705000 ms (execution: 0.002 s)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106710000 ms.0 from job set of time 1472106710000 ms

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106705000 ms.0

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,882 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106710000 ms.0 from job set of time 1472106710000 ms

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 442.882 s for time 1472106710000 ms (execution: 0.000 s)

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106715000 ms.0 from job set of time 1472106715000 ms

2016-08-25 14:39:12,883 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106710000 ms.0

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,884 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,885 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106715000 ms.0 from job set of time 1472106715000 ms

2016-08-25 14:39:12,885 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 437.885 s for time 1472106715000 ms (execution: 0.002 s)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106720000 ms.0 from job set of time 1472106720000 ms

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106715000 ms.0

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,886 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,888 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106720000 ms.0 from job set of time 1472106720000 ms

2016-08-25 14:39:12,888 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 432.887 s for time 1472106720000 ms (execution: 0.001 s)

2016-08-25 14:39:12,888 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106725000 ms.0 from job set of time 1472106725000 ms

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106720000 ms.0

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,889 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,890 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106725000 ms.0 from job set of time 1472106725000 ms

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 427.890 s for time 1472106725000 ms (execution: 0.002 s)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106730000 ms.0 from job set of time 1472106730000 ms

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106725000 ms.0

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,891 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106730000 ms.0 from job set of time 1472106730000 ms

2016-08-25 14:39:12,892 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 422.892 s for time 1472106730000 ms (execution: 0.001 s)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106735000 ms.0 from job set of time 1472106735000 ms

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106730000 ms.0

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,893 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,894 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106735000 ms.0 from job set of time 1472106735000 ms

2016-08-25 14:39:12,894 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 417.894 s for time 1472106735000 ms (execution: 0.001 s)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106740000 ms.0 from job set of time 1472106740000 ms

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106735000 ms.0

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,895 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,896 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106740000 ms.0 from job set of time 1472106740000 ms

2016-08-25 14:39:12,896 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 412.896 s for time 1472106740000 ms (execution: 0.001 s)

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106745000 ms.0 from job set of time 1472106745000 ms

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106740000 ms.0

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,897 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,898 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO ui.SparkUI: Stopped Spark web UI at http://10.236.66.144:4040

2016-08-25 14:39:12,899 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106745000 ms.0 from job set of time 1472106745000 ms

2016-08-25 14:39:12,899 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 407.899 s for time 1472106745000 ms (execution: 0.002 s)

2016-08-25 14:39:12,899 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106750000 ms.0 from job set of time 1472106750000 ms

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106745000 ms.0

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,900 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,901 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106750000 ms.0 from job set of time 1472106750000 ms

2016-08-25 14:39:12,901 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.DAGScheduler: Stopping DAGScheduler

2016-08-25 14:39:12,901 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 402.901 s for time 1472106750000 ms (execution: 0.002 s)

2016-08-25 14:39:12,902 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106755000 ms.0 from job set of time 1472106755000 ms

2016-08-25 14:39:12,902 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106750000 ms.0

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,903 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO cluster.SparkDeploySchedulerBackend: Shutting down all executors

2016-08-25 14:39:12,904 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106755000 ms.0 from job set of time 1472106755000 ms

2016-08-25 14:39:12,904 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 397.904 s for time 1472106755000 ms (execution: 0.002 s)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106760000 ms.0 from job set of time 1472106760000 ms

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106755000 ms.0

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,905 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,906 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,906 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,906 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,906 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO cluster.SparkDeploySchedulerBackend: Asking each executor to shut down

2016-08-25 14:39:12,907 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106760000 ms.0 from job set of time 1472106760000 ms

2016-08-25 14:39:12,907 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 392.906 s for time 1472106760000 ms (execution: 0.001 s)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106765000 ms.0 from job set of time 1472106765000 ms

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106760000 ms.0

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,908 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,909 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,909 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,909 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,909 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,909 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,909 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,909 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,909 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,909 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,909 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,909 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106765000 ms.0 from job set of time 1472106765000 ms

2016-08-25 14:39:12,909 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 387.909 s for time 1472106765000 ms (execution: 0.002 s)

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106770000 ms.0 from job set of time 1472106770000 ms

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106765000 ms.0

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,910 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,911 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,912 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106770000 ms.0 from job set of time 1472106770000 ms

2016-08-25 14:39:12,912 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 382.912 s for time 1472106770000 ms (execution: 0.002 s)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106775000 ms.0 from job set of time 1472106775000 ms

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106770000 ms.0

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,913 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,914 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106775000 ms.0 from job set of time 1472106775000 ms

2016-08-25 14:39:12,915 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 377.914 s for time 1472106775000 ms (execution: 0.001 s)

2016-08-25 14:39:12,916 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106780000 ms.0 from job set of time 1472106780000 ms

2016-08-25 14:39:12,916 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106775000 ms.0

2016-08-25 14:39:12,916 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,916 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,916 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,916 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106780000 ms.0 from job set of time 1472106780000 ms

2016-08-25 14:39:12,917 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 372.917 s for time 1472106780000 ms (execution: 0.002 s)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106785000 ms.0 from job set of time 1472106785000 ms

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106780000 ms.0

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,918 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,919 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,919 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,919 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,919 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,919 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,919 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,920 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106785000 ms.0 from job set of time 1472106785000 ms

2016-08-25 14:39:12,920 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 367.919 s for time 1472106785000 ms (execution: 0.001 s)

2016-08-25 14:39:12,920 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106790000 ms.0 from job set of time 1472106790000 ms

2016-08-25 14:39:12,920 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106785000 ms.0

2016-08-25 14:39:12,920 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,920 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,920 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,920 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,921 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,922 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106790000 ms.0 from job set of time 1472106790000 ms

2016-08-25 14:39:12,922 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 362.922 s for time 1472106790000 ms (execution: 0.002 s)

2016-08-25 14:39:12,922 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106795000 ms.0 from job set of time 1472106795000 ms

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106790000 ms.0

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,923 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,924 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106795000 ms.0 from job set of time 1472106795000 ms

2016-08-25 14:39:12,924 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 357.924 s for time 1472106795000 ms (execution: 0.002 s)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106800000 ms.0 from job set of time 1472106800000 ms

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106795000 ms.0

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,925 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,926 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106800000 ms.0 from job set of time 1472106800000 ms

2016-08-25 14:39:12,926 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 352.926 s for time 1472106800000 ms (execution: 0.001 s)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106805000 ms.0 from job set of time 1472106805000 ms

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106800000 ms.0

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,927 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,928 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106805000 ms.0 from job set of time 1472106805000 ms

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 347.928 s for time 1472106805000 ms (execution: 0.001 s)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106810000 ms.0 from job set of time 1472106810000 ms

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106805000 ms.0

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,929 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,930 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106810000 ms.0 from job set of time 1472106810000 ms

2016-08-25 14:39:12,930 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 342.930 s for time 1472106810000 ms (execution: 0.001 s)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106815000 ms.0 from job set of time 1472106815000 ms

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106810000 ms.0

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,931 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,932 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,932 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,932 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,932 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,932 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106815000 ms.0 from job set of time 1472106815000 ms

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 337.933 s for time 1472106815000 ms (execution: 0.002 s)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106820000 ms.0 from job set of time 1472106820000 ms

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106815000 ms.0

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,933 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,934 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,934 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,934 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,934 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,934 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,934 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106820000 ms.0 from job set of time 1472106820000 ms

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 332.934 s for time 1472106820000 ms (execution: 0.001 s)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106825000 ms.0 from job set of time 1472106825000 ms

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106820000 ms.0

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,935 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,937 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106825000 ms.0 from job set of time 1472106825000 ms

2016-08-25 14:39:12,937 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 327.937 s for time 1472106825000 ms (execution: 0.002 s)

2016-08-25 14:39:12,937 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106830000 ms.0 from job set of time 1472106830000 ms

2016-08-25 14:39:12,937 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106825000 ms.0

2016-08-25 14:39:12,937 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,937 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,937 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,937 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,938 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106830000 ms.0 from job set of time 1472106830000 ms

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 322.938 s for time 1472106830000 ms (execution: 0.001 s)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106835000 ms.0 from job set of time 1472106835000 ms

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106830000 ms.0

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,939 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,940 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106835000 ms.0 from job set of time 1472106835000 ms

2016-08-25 14:39:12,940 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 317.940 s for time 1472106835000 ms (execution: 0.001 s)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106840000 ms.0 from job set of time 1472106840000 ms

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106835000 ms.0

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,941 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106840000 ms.0 from job set of time 1472106840000 ms

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 312.942 s for time 1472106840000 ms (execution: 0.002 s)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106845000 ms.0 from job set of time 1472106845000 ms

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106840000 ms.0

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,942 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,943 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,943 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,943 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,943 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,943 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106845000 ms.0 from job set of time 1472106845000 ms

2016-08-25 14:39:12,943 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 307.943 s for time 1472106845000 ms (execution: 0.001 s)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106850000 ms.0 from job set of time 1472106850000 ms

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106845000 ms.0

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,944 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106850000 ms.0 from job set of time 1472106850000 ms

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 302.945 s for time 1472106850000 ms (execution: 0.002 s)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106855000 ms.0 from job set of time 1472106855000 ms

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106850000 ms.0

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,945 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106855000 ms.0 from job set of time 1472106855000 ms

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 297.946 s for time 1472106855000 ms (execution: 0.001 s)

2016-08-25 14:39:12,946 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106860000 ms.0 from job set of time 1472106860000 ms

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106855000 ms.0

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,947 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106860000 ms.0 from job set of time 1472106860000 ms

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 292.947 s for time 1472106860000 ms (execution: 0.001 s)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106865000 ms.0 from job set of time 1472106865000 ms

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106860000 ms.0

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,948 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,949 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106865000 ms.0 from job set of time 1472106865000 ms

2016-08-25 14:39:12,949 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 287.949 s for time 1472106865000 ms (execution: 0.001 s)

2016-08-25 14:39:12,949 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106870000 ms.0 from job set of time 1472106870000 ms

2016-08-25 14:39:12,949 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106865000 ms.0

2016-08-25 14:39:12,949 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,949 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,949 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,950 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106870000 ms.0 from job set of time 1472106870000 ms

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 282.951 s for time 1472106870000 ms (execution: 0.002 s)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106875000 ms.0 from job set of time 1472106875000 ms

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106870000 ms.0

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,951 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,952 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,952 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,952 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,952 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,952 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,952 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,952 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,952 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,952 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,952 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106875000 ms.0 from job set of time 1472106875000 ms

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 277.952 s for time 1472106875000 ms (execution: 0.001 s)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106880000 ms.0 from job set of time 1472106880000 ms

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106875000 ms.0

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,953 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,954 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106880000 ms.0 from job set of time 1472106880000 ms

2016-08-25 14:39:12,954 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 272.954 s for time 1472106880000 ms (execution: 0.001 s)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106885000 ms.0 from job set of time 1472106885000 ms

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106880000 ms.0

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,955 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,956 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106885000 ms.0 from job set of time 1472106885000 ms

2016-08-25 14:39:12,956 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 267.956 s for time 1472106885000 ms (execution: 0.001 s)

2016-08-25 14:39:12,956 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106890000 ms.0 from job set of time 1472106890000 ms

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106885000 ms.0

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,957 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,958 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106890000 ms.0 from job set of time 1472106890000 ms

2016-08-25 14:39:12,958 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 262.958 s for time 1472106890000 ms (execution: 0.002 s)

2016-08-25 14:39:12,958 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106895000 ms.0 from job set of time 1472106895000 ms

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106890000 ms.0

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,959 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106895000 ms.0 from job set of time 1472106895000 ms

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 257.960 s for time 1472106895000 ms (execution: 0.002 s)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106900000 ms.0 from job set of time 1472106900000 ms

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106895000 ms.0

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,960 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,961 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,961 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,961 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106900000 ms.0 from job set of time 1472106900000 ms

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 252.962 s for time 1472106900000 ms (execution: 0.002 s)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106905000 ms.0 from job set of time 1472106905000 ms

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106900000 ms.0

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,962 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,963 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,963 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,963 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,963 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,963 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,963 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,963 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,963 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,963 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,963 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,963 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106905000 ms.0 from job set of time 1472106905000 ms

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 247.963 s for time 1472106905000 ms (execution: 0.001 s)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106910000 ms.0 from job set of time 1472106910000 ms

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106905000 ms.0

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,964 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,965 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106910000 ms.0 from job set of time 1472106910000 ms

2016-08-25 14:39:12,965 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 242.965 s for time 1472106910000 ms (execution: 0.001 s)

2016-08-25 14:39:12,965 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106915000 ms.0 from job set of time 1472106915000 ms

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106910000 ms.0

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,966 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106915000 ms.0 from job set of time 1472106915000 ms

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 237.966 s for time 1472106915000 ms (execution: 0.001 s)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106920000 ms.0 from job set of time 1472106920000 ms

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106915000 ms.0

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,967 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,968 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106920000 ms.0 from job set of time 1472106920000 ms

2016-08-25 14:39:12,968 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 232.968 s for time 1472106920000 ms (execution: 0.001 s)

2016-08-25 14:39:12,968 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106925000 ms.0 from job set of time 1472106925000 ms

2016-08-25 14:39:12,968 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106920000 ms.0

2016-08-25 14:39:12,968 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,969 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106925000 ms.0 from job set of time 1472106925000 ms

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 227.970 s for time 1472106925000 ms (execution: 0.002 s)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106930000 ms.0 from job set of time 1472106930000 ms

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106925000 ms.0

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,970 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,971 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,971 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,971 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,971 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,971 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,971 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,971 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,971 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,971 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,971 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106930000 ms.0 from job set of time 1472106930000 ms

2016-08-25 14:39:12,971 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 222.971 s for time 1472106930000 ms (execution: 0.001 s)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106935000 ms.0 from job set of time 1472106935000 ms

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106930000 ms.0

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,972 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,973 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106935000 ms.0 from job set of time 1472106935000 ms

2016-08-25 14:39:12,973 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 217.973 s for time 1472106935000 ms (execution: 0.001 s)

2016-08-25 14:39:12,973 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106940000 ms.0 from job set of time 1472106940000 ms

2016-08-25 14:39:12,973 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106935000 ms.0

2016-08-25 14:39:12,973 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,973 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,973 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,973 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,973 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,974 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106940000 ms.0 from job set of time 1472106940000 ms

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 212.974 s for time 1472106940000 ms (execution: 0.001 s)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106945000 ms.0 from job set of time 1472106945000 ms

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106940000 ms.0

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,975 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,976 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106945000 ms.0 from job set of time 1472106945000 ms

2016-08-25 14:39:12,976 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 207.976 s for time 1472106945000 ms (execution: 0.001 s)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106950000 ms.0 from job set of time 1472106950000 ms

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106945000 ms.0

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,977 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,978 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106950000 ms.0 from job set of time 1472106950000 ms

2016-08-25 14:39:12,978 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 202.978 s for time 1472106950000 ms (execution: 0.002 s)

2016-08-25 14:39:12,978 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106955000 ms.0 from job set of time 1472106955000 ms

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106950000 ms.0

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,979 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106955000 ms.0 from job set of time 1472106955000 ms

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 197.980 s for time 1472106955000 ms (execution: 0.002 s)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106960000 ms.0 from job set of time 1472106960000 ms

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106955000 ms.0

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,980 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,981 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,981 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,981 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,981 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,981 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,981 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,981 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,981 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,981 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,981 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,981 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106960000 ms.0 from job set of time 1472106960000 ms

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 192.981 s for time 1472106960000 ms (execution: 0.001 s)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106965000 ms.0 from job set of time 1472106965000 ms

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106960000 ms.0

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,982 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,983 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106965000 ms.0 from job set of time 1472106965000 ms

2016-08-25 14:39:12,983 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 187.983 s for time 1472106965000 ms (execution: 0.001 s)

2016-08-25 14:39:12,983 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106970000 ms.0 from job set of time 1472106970000 ms

2016-08-25 14:39:12,983 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106965000 ms.0

2016-08-25 14:39:12,983 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,983 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,983 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,983 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,983 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,983 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,983 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,984 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106970000 ms.0 from job set of time 1472106970000 ms

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 182.985 s for time 1472106970000 ms (execution: 0.002 s)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106975000 ms.0 from job set of time 1472106975000 ms

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106970000 ms.0

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,985 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106975000 ms.0 from job set of time 1472106975000 ms

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 177.987 s for time 1472106975000 ms (execution: 0.002 s)

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106980000 ms.0 from job set of time 1472106980000 ms

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106975000 ms.0

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,987 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,988 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106980000 ms.0 from job set of time 1472106980000 ms

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 172.988 s for time 1472106980000 ms (execution: 0.001 s)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106985000 ms.0 from job set of time 1472106985000 ms

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106980000 ms.0

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,989 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,990 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106985000 ms.0 from job set of time 1472106985000 ms

2016-08-25 14:39:12,990 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 167.990 s for time 1472106985000 ms (execution: 0.001 s)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106990000 ms.0 from job set of time 1472106990000 ms

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106985000 ms.0

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,991 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,992 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106990000 ms.0 from job set of time 1472106990000 ms

2016-08-25 14:39:12,993 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 162.992 s for time 1472106990000 ms (execution: 0.002 s)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472106995000 ms.0 from job set of time 1472106995000 ms

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106990000 ms.0

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472106995000 ms.0 from job set of time 1472106995000 ms

2016-08-25 14:39:12,994 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 157.994 s for time 1472106995000 ms (execution: 0.001 s)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472107000000 ms.0 from job set of time 1472107000000 ms

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472106995000 ms.0

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,995 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,996 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472107000000 ms.0 from job set of time 1472107000000 ms

2016-08-25 14:39:12,996 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 152.996 s for time 1472107000000 ms (execution: 0.001 s)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472107005000 ms.0 from job set of time 1472107005000 ms

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472107000000 ms.0

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,997 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472107005000 ms.0 from job set of time 1472107005000 ms

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 147.998 s for time 1472107005000 ms (execution: 0.001 s)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Starting job streaming job 1472107010000 ms.0 from job set of time 1472107010000 ms

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 ERROR scheduler.JobScheduler: Error running job streaming job 1472107005000 ms.0

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,998 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Finished job streaming job 1472107010000 ms.0 from job set of time 1472107010000 ms

2016-08-25 14:39:12,999 - [INFO] - from application in Thread-359 
16/08/25 14:39:12 INFO scheduler.JobScheduler: Total delay: 142.999 s for time 1472107010000 ms (execution: 0.001 s)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107015000 ms.0 from job set of time 1472107015000 ms

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107010000 ms.0

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,000 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,001 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107015000 ms.0 from job set of time 1472107015000 ms

2016-08-25 14:39:13,001 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 138.001 s for time 1472107015000 ms (execution: 0.001 s)

2016-08-25 14:39:13,001 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107020000 ms.0 from job set of time 1472107020000 ms

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107015000 ms.0

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,002 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,003 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107020000 ms.0 from job set of time 1472107020000 ms

2016-08-25 14:39:13,003 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 133.003 s for time 1472107020000 ms (execution: 0.002 s)

2016-08-25 14:39:13,003 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107025000 ms.0 from job set of time 1472107025000 ms

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107020000 ms.0

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,004 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107025000 ms.0 from job set of time 1472107025000 ms

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 128.005 s for time 1472107025000 ms (execution: 0.002 s)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107030000 ms.0 from job set of time 1472107030000 ms

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107025000 ms.0

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,005 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,006 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107030000 ms.0 from job set of time 1472107030000 ms

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 123.007 s for time 1472107030000 ms (execution: 0.002 s)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107035000 ms.0 from job set of time 1472107035000 ms

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107030000 ms.0

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,007 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,008 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107035000 ms.0 from job set of time 1472107035000 ms

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 118.008 s for time 1472107035000 ms (execution: 0.001 s)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107040000 ms.0 from job set of time 1472107040000 ms

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107035000 ms.0

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,009 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,010 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,010 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,010 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107040000 ms.0 from job set of time 1472107040000 ms

2016-08-25 14:39:13,010 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 113.010 s for time 1472107040000 ms (execution: 0.001 s)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107045000 ms.0 from job set of time 1472107045000 ms

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107040000 ms.0

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,011 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,012 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107045000 ms.0 from job set of time 1472107045000 ms

2016-08-25 14:39:13,012 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 108.012 s for time 1472107045000 ms (execution: 0.001 s)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107050000 ms.0 from job set of time 1472107050000 ms

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107045000 ms.0

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,013 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,014 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107050000 ms.0 from job set of time 1472107050000 ms

2016-08-25 14:39:13,014 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 103.014 s for time 1472107050000 ms (execution: 0.002 s)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107055000 ms.0 from job set of time 1472107055000 ms

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107050000 ms.0

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,015 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,016 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107055000 ms.0 from job set of time 1472107055000 ms

2016-08-25 14:39:13,016 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 98.016 s for time 1472107055000 ms (execution: 0.002 s)

2016-08-25 14:39:13,016 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107060000 ms.0 from job set of time 1472107060000 ms

2016-08-25 14:39:13,016 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107055000 ms.0

2016-08-25 14:39:13,016 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,017 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107060000 ms.0 from job set of time 1472107060000 ms

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 93.018 s for time 1472107060000 ms (execution: 0.002 s)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107065000 ms.0 from job set of time 1472107065000 ms

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107060000 ms.0

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,018 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,019 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,019 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,019 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,019 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,019 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,019 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,019 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,019 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,019 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,019 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107065000 ms.0 from job set of time 1472107065000 ms

2016-08-25 14:39:13,020 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 88.019 s for time 1472107065000 ms (execution: 0.001 s)

2016-08-25 14:39:13,020 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107070000 ms.0 from job set of time 1472107070000 ms

2016-08-25 14:39:13,020 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107065000 ms.0

2016-08-25 14:39:13,020 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,020 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,020 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,020 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,020 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,020 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,021 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,022 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107070000 ms.0 from job set of time 1472107070000 ms

2016-08-25 14:39:13,022 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 83.022 s for time 1472107070000 ms (execution: 0.002 s)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107075000 ms.0 from job set of time 1472107075000 ms

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107070000 ms.0

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,023 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,024 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107075000 ms.0 from job set of time 1472107075000 ms

2016-08-25 14:39:13,024 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 78.024 s for time 1472107075000 ms (execution: 0.002 s)

2016-08-25 14:39:13,024 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107080000 ms.0 from job set of time 1472107080000 ms

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107075000 ms.0

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,025 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107080000 ms.0 from job set of time 1472107080000 ms

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 73.026 s for time 1472107080000 ms (execution: 0.002 s)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107085000 ms.0 from job set of time 1472107085000 ms

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107080000 ms.0

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,026 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,027 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107085000 ms.0 from job set of time 1472107085000 ms

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 68.028 s for time 1472107085000 ms (execution: 0.002 s)

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107090000 ms.0 from job set of time 1472107090000 ms

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107085000 ms.0

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,028 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,029 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107090000 ms.0 from job set of time 1472107090000 ms

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 63.030 s for time 1472107090000 ms (execution: 0.002 s)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107095000 ms.0 from job set of time 1472107095000 ms

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107090000 ms.0

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,030 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,031 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,031 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,031 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,031 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,031 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107095000 ms.0 from job set of time 1472107095000 ms

2016-08-25 14:39:13,031 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 58.031 s for time 1472107095000 ms (execution: 0.001 s)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107100000 ms.0 from job set of time 1472107100000 ms

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107095000 ms.0

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,032 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,033 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107100000 ms.0 from job set of time 1472107100000 ms

2016-08-25 14:39:13,033 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 53.033 s for time 1472107100000 ms (execution: 0.001 s)

2016-08-25 14:39:13,033 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107105000 ms.0 from job set of time 1472107105000 ms

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107100000 ms.0

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,034 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,035 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107105000 ms.0 from job set of time 1472107105000 ms

2016-08-25 14:39:13,035 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 48.035 s for time 1472107105000 ms (execution: 0.002 s)

2016-08-25 14:39:13,035 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107110000 ms.0 from job set of time 1472107110000 ms

2016-08-25 14:39:13,035 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107105000 ms.0

2016-08-25 14:39:13,035 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,035 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,035 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,035 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,035 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,035 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,035 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,035 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,036 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107110000 ms.0 from job set of time 1472107110000 ms

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 43.037 s for time 1472107110000 ms (execution: 0.002 s)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107115000 ms.0 from job set of time 1472107115000 ms

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107110000 ms.0

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,037 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,038 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107115000 ms.0 from job set of time 1472107115000 ms

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 38.038 s for time 1472107115000 ms (execution: 0.001 s)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107120000 ms.0 from job set of time 1472107120000 ms

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107115000 ms.0

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,039 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,040 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107120000 ms.0 from job set of time 1472107120000 ms

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 33.040 s for time 1472107120000 ms (execution: 0.001 s)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107125000 ms.0 from job set of time 1472107125000 ms

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107120000 ms.0

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,041 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107125000 ms.0 from job set of time 1472107125000 ms

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 28.043 s for time 1472107125000 ms (execution: 0.002 s)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107130000 ms.0 from job set of time 1472107130000 ms

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107125000 ms.0

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,043 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,044 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,044 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,044 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,044 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,044 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,044 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,044 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,044 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,044 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,044 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,045 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107130000 ms.0 from job set of time 1472107130000 ms

2016-08-25 14:39:13,045 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 23.045 s for time 1472107130000 ms (execution: 0.002 s)

2016-08-25 14:39:13,045 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107135000 ms.0 from job set of time 1472107135000 ms

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107130000 ms.0

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,046 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,047 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107135000 ms.0 from job set of time 1472107135000 ms

2016-08-25 14:39:13,047 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 18.047 s for time 1472107135000 ms (execution: 0.002 s)

2016-08-25 14:39:13,047 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107140000 ms.0 from job set of time 1472107140000 ms

2016-08-25 14:39:13,047 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107135000 ms.0

2016-08-25 14:39:13,047 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,047 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,047 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,047 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,047 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,048 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,049 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107140000 ms.0 from job set of time 1472107140000 ms

2016-08-25 14:39:13,049 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 13.049 s for time 1472107140000 ms (execution: 0.002 s)

2016-08-25 14:39:13,049 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107145000 ms.0 from job set of time 1472107145000 ms

2016-08-25 14:39:13,049 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107140000 ms.0

2016-08-25 14:39:13,049 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,049 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,049 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,049 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,049 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,049 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,050 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,051 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107145000 ms.0 from job set of time 1472107145000 ms

2016-08-25 14:39:13,051 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 8.051 s for time 1472107145000 ms (execution: 0.002 s)

2016-08-25 14:39:13,051 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Starting job streaming job 1472107150000 ms.0 from job set of time 1472107150000 ms

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.JobScheduler: Error running job streaming job 1472107145000 ms.0

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 14:39:13,052 - [INFO] - from application in Thread-359 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 14:39:13,053 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Finished job streaming job 1472107150000 ms.0 from job set of time 1472107150000 ms

2016-08-25 14:39:13,053 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Total delay: 3.053 s for time 1472107150000 ms (execution: 0.002 s)

2016-08-25 14:39:13,055 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 ERROR scheduler.StreamingListenerBus: StreamingListenerBus has already stopped! Dropping event StreamingListenerBatchCompleted(BatchInfo(1472107150000 ms,Map(0 -> StreamInputInfo(0,0,Map(files -> List(), Description -> ))),1472107150025,Some(1472107153051),Some(1472107153053)))

2016-08-25 14:39:13,055 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO scheduler.JobScheduler: Stopped JobScheduler

2016-08-25 14:39:13,058 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO streaming.StreamingContext: StreamingContext stopped successfully

2016-08-25 14:39:13,058 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO storage.DiskBlockManager: Shutdown hook called

2016-08-25 14:39:13,060 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO util.ShutdownHookManager: Shutdown hook called

2016-08-25 14:39:13,061 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO util.ShutdownHookManager: Deleting directory /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/spark-cf4c1657-3a09-41f3-8515-f8a7a70a88b2/httpd-09de6ac7-1fc2-49d0-b80b-95988a540997

2016-08-25 14:39:13,064 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO util.ShutdownHookManager: Deleting directory /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/spark-cf4c1657-3a09-41f3-8515-f8a7a70a88b2/userFiles-76667780-7c86-49e1-8a57-6548db576779

2016-08-25 14:39:13,064 - [INFO] - from application in Thread-359 
16/08/25 14:39:13 INFO util.ShutdownHookManager: Deleting directory /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/spark-cf4c1657-3a09-41f3-8515-f8a7a70a88b2

2016-08-25 14:39:13,576 - [INFO] - from application in ForkJoinPool-4-worker-3 
执行结束!

2016-08-25 14:48:27,149 - [ERROR] - from application in New I/O worker #3 


! @717abb100 - Internal server error, for (GET) [/tasklist] ->

play.PlayExceptions$CompilationException: Compilation error[type mismatch;
 found   : String
 required: Long]
	at play.PlayReloader$$anon$1$$anonfun$reload$2$$anonfun$apply$14$$anonfun$apply$16.apply(PlayReloader.scala:304) ~[na:na]
	at play.PlayReloader$$anon$1$$anonfun$reload$2$$anonfun$apply$14$$anonfun$apply$16.apply(PlayReloader.scala:304) ~[na:na]
	at scala.Option.map(Option.scala:145) ~[scala-library-2.10.4.jar:na]
	at play.PlayReloader$$anon$1$$anonfun$reload$2$$anonfun$apply$14.apply(PlayReloader.scala:304) ~[na:na]
	at play.PlayReloader$$anon$1$$anonfun$reload$2$$anonfun$apply$14.apply(PlayReloader.scala:298) ~[na:na]
	at scala.Option.map(Option.scala:145) ~[scala-library-2.10.4.jar:na]
	at play.PlayReloader$$anon$1$$anonfun$reload$2.apply(PlayReloader.scala:298) ~[na:na]
	at play.PlayReloader$$anon$1$$anonfun$reload$2.apply(PlayReloader.scala:296) ~[na:na]
	at scala.util.Either$LeftProjection.map(Either.scala:377) ~[scala-library-2.10.4.jar:na]
	at play.PlayReloader$$anon$1.reload(PlayReloader.scala:296) ~[na:na]
	at play.core.ReloadableApplication$$anonfun$get$1.apply(ApplicationProvider.scala:104) ~[play_2.10-2.2.6.jar:2.2.6]
	at play.core.ReloadableApplication$$anonfun$get$1.apply(ApplicationProvider.scala:102) ~[play_2.10-2.2.6.jar:2.2.6]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[scala-library-2.10.4.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1361) ~[scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[scala-library-2.10.4.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[scala-library-2.10.4.jar:na]

2016-08-25 14:48:59,823 - [INFO] - from play in play-internal-execution-context-36 
Shutdown application default Akka system.

2016-08-25 14:49:01,699 - [INFO] - from play in play-internal-execution-context-36 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-25 14:49:02,490 - [INFO] - from play in play-internal-execution-context-36 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-25 14:49:02,496 - [INFO] - from play in play-internal-execution-context-36 
Application started (Dev)

2016-08-25 14:49:03,896 - [INFO] - from play in play-internal-execution-context-36 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-25 14:49:04,659 - [INFO] - from play in play-internal-execution-context-36 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-25 14:49:04,664 - [INFO] - from play in play-internal-execution-context-36 
Application started (Dev)

2016-08-25 14:52:39,614 - [INFO] - from play in play-internal-execution-context-36 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-25 14:52:40,824 - [INFO] - from play in play-internal-execution-context-36 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-25 14:52:40,831 - [INFO] - from play in play-internal-execution-context-36 
Application started (Dev)

2016-08-25 14:54:21,368 - [INFO] - from play in play-internal-execution-context-36 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-25 14:54:22,805 - [INFO] - from play in play-internal-execution-context-36 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-25 14:54:22,810 - [INFO] - from play in play-internal-execution-context-36 
Application started (Dev)

2016-08-25 14:55:41,480 - [INFO] - from play in play-internal-execution-context-36 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-25 14:55:42,601 - [INFO] - from play in play-internal-execution-context-36 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-25 14:55:42,606 - [INFO] - from play in play-internal-execution-context-36 
Application started (Dev)

2016-08-25 15:03:16,208 - [INFO] - from play in New I/O worker #4 
Starting application default Akka system.

2016-08-25 15:03:20,311 - [INFO] - from application in play-akka.actor.default-dispatcher-1280 
用户名=>liangkai1@staff.weibo.com

2016-08-25 15:03:39,600 - [INFO] - from application in play-akka.actor.default-dispatcher-1274 
执行模式=>standalone

2016-08-25 15:03:39,602 - [INFO] - from application in jobSystem-akka.actor.default-dispatcher-4 
select mode 2

2016-08-25 15:03:39,614 - [INFO] - from application in pool-717-thread-1 
args ArrayBuffer(/usr/local/spark/bin/spark-submit, --master, spark://localhost:7077, --class, com.weibo.spark.stream.HDFSWordCount, --num-executors, 2, --executor-memory, 2g, --driver-memory, 2g, --total-executor-cores, 2, /tmp/file/sparkStream.jar, 1111)

2016-08-25 15:03:40,340 - [INFO] - from application in Thread-371 
16/08/25 15:03:40 INFO spark.SparkContext: Running Spark version 1.5.2

2016-08-25 15:03:40,669 - [INFO] - from application in Thread-371 
16/08/25 15:03:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

2016-08-25 15:03:40,776 - [INFO] - from application in Thread-371 
16/08/25 15:03:40 INFO spark.SecurityManager: Changing view acls to: king

2016-08-25 15:03:40,776 - [INFO] - from application in Thread-371 
16/08/25 15:03:40 INFO spark.SecurityManager: Changing modify acls to: king

2016-08-25 15:03:40,777 - [INFO] - from application in Thread-371 
16/08/25 15:03:40 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(king); users with modify permissions: Set(king)

2016-08-25 15:03:41,300 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO slf4j.Slf4jLogger: Slf4jLogger started

2016-08-25 15:03:41,334 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO Remoting: Starting remoting

2016-08-25 15:03:41,463 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.236.66.144:52186]

2016-08-25 15:03:41,470 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO util.Utils: Successfully started service 'sparkDriver' on port 52186.

2016-08-25 15:03:41,487 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO spark.SparkEnv: Registering MapOutputTracker

2016-08-25 15:03:41,503 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO spark.SparkEnv: Registering BlockManagerMaster

2016-08-25 15:03:41,521 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO storage.DiskBlockManager: Created local directory at /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/blockmgr-80cc0437-e771-4b9c-9ff3-9ca34abe7e64

2016-08-25 15:03:41,526 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO storage.MemoryStore: MemoryStore started with capacity 1060.0 MB

2016-08-25 15:03:41,573 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO spark.HttpFileServer: HTTP File server directory is /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/spark-1f1f4063-e2aa-4012-ab1c-debb67a3e0fc/httpd-4bdde0ca-4f98-47b2-8ff7-26e8da9ceef2

2016-08-25 15:03:41,577 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO spark.HttpServer: Starting HTTP Server

2016-08-25 15:03:41,618 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO server.Server: jetty-8.y.z-SNAPSHOT

2016-08-25 15:03:41,634 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52187

2016-08-25 15:03:41,634 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO util.Utils: Successfully started service 'HTTP file server' on port 52187.

2016-08-25 15:03:41,645 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO spark.SparkEnv: Registering OutputCommitCoordinator

2016-08-25 15:03:41,732 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO server.Server: jetty-8.y.z-SNAPSHOT

2016-08-25 15:03:41,743 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040

2016-08-25 15:03:41,743 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.

2016-08-25 15:03:41,744 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO ui.SparkUI: Started SparkUI at http://10.236.66.144:4040

2016-08-25 15:03:41,779 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO spark.SparkContext: Added JAR file:/tmp/file/sparkStream.jar at http://10.236.66.144:52187/jars/sparkStream.jar with timestamp 1472108621778

2016-08-25 15:03:41,833 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 WARN metrics.MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.

2016-08-25 15:03:41,843 - [INFO] - from application in Thread-371 
16/08/25 15:03:41 INFO client.AppClient$ClientEndpoint: Connecting to master spark://localhost:7077...

2016-08-25 15:03:41,982 - [INFO] - from application in play-akka.actor.default-dispatcher-1274 
用户任务Id====>app-20160825150341-0014

2016-08-25 15:03:42,082 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52190.

2016-08-25 15:03:42,083 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO netty.NettyBlockTransferService: Server created on 52190

2016-08-25 15:03:42,084 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO storage.BlockManagerMaster: Trying to register BlockManager

2016-08-25 15:03:42,086 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.236.66.144:52190 with 1060.0 MB RAM, BlockManagerId(driver, 10.236.66.144, 52190)

2016-08-25 15:03:42,087 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO storage.BlockManagerMaster: Registered BlockManager

2016-08-25 15:03:42,206 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO cluster.SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

2016-08-25 15:03:42,445 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FileInputDStream: Duration for remembering RDDs set to 60000 ms for org.apache.spark.streaming.dstream.FileInputDStream@e1e2e5e

2016-08-25 15:03:42,508 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.ForEachDStream: metadataCleanupDelay = -1

2016-08-25 15:03:42,509 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.ShuffledDStream: metadataCleanupDelay = -1

2016-08-25 15:03:42,509 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.MappedDStream: metadataCleanupDelay = -1

2016-08-25 15:03:42,509 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FlatMappedDStream: metadataCleanupDelay = -1

2016-08-25 15:03:42,509 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.MappedDStream: metadataCleanupDelay = -1

2016-08-25 15:03:42,509 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FileInputDStream: metadataCleanupDelay = -1

2016-08-25 15:03:42,509 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FileInputDStream: Slide time = 5000 ms

2016-08-25 15:03:42,510 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FileInputDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:03:42,510 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FileInputDStream: Checkpoint interval = null

2016-08-25 15:03:42,510 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FileInputDStream: Remember duration = 60000 ms

2016-08-25 15:03:42,510 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@e1e2e5e

2016-08-25 15:03:42,510 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.MappedDStream: Slide time = 5000 ms

2016-08-25 15:03:42,510 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.MappedDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:03:42,510 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.MappedDStream: Checkpoint interval = null

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.MappedDStream: Remember duration = 5000 ms

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@2a412c80

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FlatMappedDStream: Slide time = 5000 ms

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FlatMappedDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FlatMappedDStream: Checkpoint interval = null

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FlatMappedDStream: Remember duration = 5000 ms

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.FlatMappedDStream: Initialized and validated org.apache.spark.streaming.dstream.FlatMappedDStream@4ea5396f

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.MappedDStream: Slide time = 5000 ms

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.MappedDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.MappedDStream: Checkpoint interval = null

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.MappedDStream: Remember duration = 5000 ms

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@442921ad

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.ShuffledDStream: Slide time = 5000 ms

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.ShuffledDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.ShuffledDStream: Checkpoint interval = null

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.ShuffledDStream: Remember duration = 5000 ms

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@78e67056

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.ForEachDStream: Slide time = 5000 ms

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.ForEachDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.ForEachDStream: Checkpoint interval = null

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.ForEachDStream: Remember duration = 5000 ms

2016-08-25 15:03:42,511 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO dstream.ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@5be076e6

2016-08-25 15:03:42,539 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO util.RecurringTimer: Started timer for JobGenerator at time 1472108625000

2016-08-25 15:03:42,540 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO scheduler.JobGenerator: Started JobGenerator at 1472108625000 ms

2016-08-25 15:03:42,540 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO scheduler.JobScheduler: Started JobScheduler

2016-08-25 15:03:42,544 - [INFO] - from application in Thread-371 
16/08/25 15:03:42 INFO streaming.StreamingContext: StreamingContext started

2016-08-25 15:03:45,701 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO dstream.FileInputDStream: Finding new files took 688 ms

2016-08-25 15:03:45,702 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO dstream.FileInputDStream: New files at time 1472108625000 ms:

2016-08-25 15:03:45,702 - [INFO] - from application in Thread-371 


2016-08-25 15:03:45,723 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO scheduler.JobScheduler: Added jobs for time 1472108625000 ms

2016-08-25 15:03:45,725 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO scheduler.JobScheduler: Starting job streaming job 1472108625000 ms.0 from job set of time 1472108625000 ms

2016-08-25 15:03:45,750 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO spark.SparkContext: Starting job: print at HDFSWordCount.scala:20

2016-08-25 15:03:45,764 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO scheduler.DAGScheduler: Registering RDD 3 (map at HDFSWordCount.scala:17)

2016-08-25 15:03:45,766 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO scheduler.DAGScheduler: Got job 0 (print at HDFSWordCount.scala:20) with 1 output partitions

2016-08-25 15:03:45,766 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO scheduler.DAGScheduler: Final stage: ResultStage 1(print at HDFSWordCount.scala:20)

2016-08-25 15:03:45,767 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)

2016-08-25 15:03:45,768 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO scheduler.DAGScheduler: Missing parents: List()

2016-08-25 15:03:45,773 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at HDFSWordCount.scala:18), which has no missing parents

2016-08-25 15:03:45,851 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO storage.MemoryStore: ensureFreeSpace(2344) called with curMem=0, maxMem=1111511531

2016-08-25 15:03:45,853 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1060.0 MB)

2016-08-25 15:03:45,861 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO storage.MemoryStore: ensureFreeSpace(1435) called with curMem=2344, maxMem=1111511531

2016-08-25 15:03:45,862 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1435.0 B, free 1060.0 MB)

2016-08-25 15:03:45,864 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.236.66.144:52190 (size: 1435.0 B, free: 1060.0 MB)

2016-08-25 15:03:45,865 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861

2016-08-25 15:03:45,868 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at HDFSWordCount.scala:18)

2016-08-25 15:03:45,869 - [INFO] - from application in Thread-371 
16/08/25 15:03:45 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks

2016-08-25 15:03:50,043 - [INFO] - from application in Thread-371 
16/08/25 15:03:50 INFO dstream.FileInputDStream: Finding new files took 37 ms

2016-08-25 15:03:50,043 - [INFO] - from application in Thread-371 
16/08/25 15:03:50 INFO dstream.FileInputDStream: New files at time 1472108630000 ms:

2016-08-25 15:03:50,043 - [INFO] - from application in Thread-371 


2016-08-25 15:03:50,049 - [INFO] - from application in Thread-371 
16/08/25 15:03:50 INFO scheduler.JobScheduler: Added jobs for time 1472108630000 ms

2016-08-25 15:03:55,043 - [INFO] - from application in Thread-371 
16/08/25 15:03:55 INFO dstream.FileInputDStream: Finding new files took 38 ms

2016-08-25 15:03:55,043 - [INFO] - from application in Thread-371 
16/08/25 15:03:55 INFO dstream.FileInputDStream: New files at time 1472108635000 ms:

2016-08-25 15:03:55,043 - [INFO] - from application in Thread-371 


2016-08-25 15:03:55,050 - [INFO] - from application in Thread-371 
16/08/25 15:03:55 INFO scheduler.JobScheduler: Added jobs for time 1472108635000 ms

2016-08-25 15:04:00,012 - [INFO] - from application in Thread-371 
16/08/25 15:04:00 INFO dstream.FileInputDStream: Finding new files took 7 ms

2016-08-25 15:04:00,012 - [INFO] - from application in Thread-371 
16/08/25 15:04:00 INFO dstream.FileInputDStream: New files at time 1472108640000 ms:

2016-08-25 15:04:00,012 - [INFO] - from application in Thread-371 


2016-08-25 15:04:00,018 - [INFO] - from application in Thread-371 
16/08/25 15:04:00 INFO scheduler.JobScheduler: Added jobs for time 1472108640000 ms

2016-08-25 15:04:00,880 - [INFO] - from application in Thread-371 
16/08/25 15:04:00 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:04:05,142 - [INFO] - from application in Thread-371 
16/08/25 15:04:05 INFO dstream.FileInputDStream: Finding new files took 137 ms

2016-08-25 15:04:05,143 - [INFO] - from application in Thread-371 
16/08/25 15:04:05 INFO dstream.FileInputDStream: New files at time 1472108645000 ms:

2016-08-25 15:04:05,143 - [INFO] - from application in Thread-371 


2016-08-25 15:04:05,150 - [INFO] - from application in Thread-371 
16/08/25 15:04:05 INFO scheduler.JobScheduler: Added jobs for time 1472108645000 ms

2016-08-25 15:04:10,017 - [INFO] - from application in Thread-371 
16/08/25 15:04:10 INFO dstream.FileInputDStream: Finding new files took 12 ms

2016-08-25 15:04:10,017 - [INFO] - from application in Thread-371 
16/08/25 15:04:10 INFO dstream.FileInputDStream: New files at time 1472108650000 ms:

2016-08-25 15:04:10,017 - [INFO] - from application in Thread-371 


2016-08-25 15:04:10,025 - [INFO] - from application in Thread-371 
16/08/25 15:04:10 INFO scheduler.JobScheduler: Added jobs for time 1472108650000 ms

2016-08-25 15:04:15,026 - [INFO] - from application in Thread-371 
16/08/25 15:04:15 INFO dstream.FileInputDStream: Finding new files took 20 ms

2016-08-25 15:04:15,027 - [INFO] - from application in Thread-371 
16/08/25 15:04:15 INFO dstream.FileInputDStream: New files at time 1472108655000 ms:

2016-08-25 15:04:15,027 - [INFO] - from application in Thread-371 


2016-08-25 15:04:15,034 - [INFO] - from application in Thread-371 
16/08/25 15:04:15 INFO scheduler.JobScheduler: Added jobs for time 1472108655000 ms

2016-08-25 15:04:15,878 - [INFO] - from application in Thread-371 
16/08/25 15:04:15 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:04:20,035 - [INFO] - from application in Thread-371 
16/08/25 15:04:20 INFO dstream.FileInputDStream: Finding new files took 31 ms

2016-08-25 15:04:20,035 - [INFO] - from application in Thread-371 
16/08/25 15:04:20 INFO dstream.FileInputDStream: New files at time 1472108660000 ms:

2016-08-25 15:04:20,035 - [INFO] - from application in Thread-371 


2016-08-25 15:04:20,042 - [INFO] - from application in Thread-371 
16/08/25 15:04:20 INFO scheduler.JobScheduler: Added jobs for time 1472108660000 ms

2016-08-25 15:04:25,051 - [INFO] - from application in Thread-371 
16/08/25 15:04:25 INFO dstream.FileInputDStream: Finding new files took 46 ms

2016-08-25 15:04:25,051 - [INFO] - from application in Thread-371 
16/08/25 15:04:25 INFO dstream.FileInputDStream: New files at time 1472108665000 ms:

2016-08-25 15:04:25,052 - [INFO] - from application in Thread-371 


2016-08-25 15:04:25,057 - [INFO] - from application in Thread-371 
16/08/25 15:04:25 INFO scheduler.JobScheduler: Added jobs for time 1472108665000 ms

2016-08-25 15:04:30,034 - [INFO] - from application in Thread-371 
16/08/25 15:04:30 INFO dstream.FileInputDStream: Finding new files took 31 ms

2016-08-25 15:04:30,034 - [INFO] - from application in Thread-371 
16/08/25 15:04:30 INFO dstream.FileInputDStream: New files at time 1472108670000 ms:

2016-08-25 15:04:30,034 - [INFO] - from application in Thread-371 


2016-08-25 15:04:30,041 - [INFO] - from application in Thread-371 
16/08/25 15:04:30 INFO scheduler.JobScheduler: Added jobs for time 1472108670000 ms

2016-08-25 15:04:30,877 - [INFO] - from application in Thread-371 
16/08/25 15:04:30 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:04:35,036 - [INFO] - from application in Thread-371 
16/08/25 15:04:35 INFO dstream.FileInputDStream: Finding new files took 30 ms

2016-08-25 15:04:35,036 - [INFO] - from application in Thread-371 
16/08/25 15:04:35 INFO dstream.FileInputDStream: New files at time 1472108675000 ms:

2016-08-25 15:04:35,036 - [INFO] - from application in Thread-371 


2016-08-25 15:04:35,042 - [INFO] - from application in Thread-371 
16/08/25 15:04:35 INFO scheduler.JobScheduler: Added jobs for time 1472108675000 ms

2016-08-25 15:04:40,017 - [INFO] - from application in Thread-371 
16/08/25 15:04:40 INFO dstream.FileInputDStream: Finding new files took 12 ms

2016-08-25 15:04:40,018 - [INFO] - from application in Thread-371 
16/08/25 15:04:40 INFO dstream.FileInputDStream: New files at time 1472108680000 ms:

2016-08-25 15:04:40,018 - [INFO] - from application in Thread-371 


2016-08-25 15:04:40,024 - [INFO] - from application in Thread-371 
16/08/25 15:04:40 INFO scheduler.JobScheduler: Added jobs for time 1472108680000 ms

2016-08-25 15:04:45,013 - [INFO] - from application in Thread-371 
16/08/25 15:04:45 INFO dstream.FileInputDStream: Finding new files took 8 ms

2016-08-25 15:04:45,013 - [INFO] - from application in Thread-371 
16/08/25 15:04:45 INFO dstream.FileInputDStream: New files at time 1472108685000 ms:

2016-08-25 15:04:45,013 - [INFO] - from application in Thread-371 


2016-08-25 15:04:45,020 - [INFO] - from application in Thread-371 
16/08/25 15:04:45 INFO scheduler.JobScheduler: Added jobs for time 1472108685000 ms

2016-08-25 15:04:45,878 - [INFO] - from application in Thread-371 
16/08/25 15:04:45 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:04:50,019 - [INFO] - from application in Thread-371 
16/08/25 15:04:50 INFO dstream.FileInputDStream: Finding new files took 14 ms

2016-08-25 15:04:50,019 - [INFO] - from application in Thread-371 
16/08/25 15:04:50 INFO dstream.FileInputDStream: New files at time 1472108690000 ms:

2016-08-25 15:04:50,019 - [INFO] - from application in Thread-371 


2016-08-25 15:04:50,027 - [INFO] - from application in Thread-371 
16/08/25 15:04:50 INFO scheduler.JobScheduler: Added jobs for time 1472108690000 ms

2016-08-25 15:04:52,592 - [INFO] - from play in play-internal-execution-context-37 
Shutdown application default Akka system.

2016-08-25 15:04:53,526 - [INFO] - from play in play-internal-execution-context-37 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-25 15:04:54,443 - [INFO] - from play in play-internal-execution-context-37 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-25 15:04:54,449 - [INFO] - from play in play-internal-execution-context-37 
Application started (Dev)

2016-08-25 15:04:55,014 - [INFO] - from application in Thread-371 
16/08/25 15:04:55 INFO dstream.FileInputDStream: Finding new files took 9 ms

2016-08-25 15:04:55,016 - [INFO] - from application in Thread-371 
16/08/25 15:04:55 INFO dstream.FileInputDStream: New files at time 1472108695000 ms:

2016-08-25 15:04:55,016 - [INFO] - from application in Thread-371 


2016-08-25 15:04:55,019 - [INFO] - from application in Thread-371 
16/08/25 15:04:55 INFO scheduler.JobScheduler: Added jobs for time 1472108695000 ms

2016-08-25 15:05:00,048 - [INFO] - from application in Thread-371 
16/08/25 15:05:00 INFO dstream.FileInputDStream: Finding new files took 44 ms

2016-08-25 15:05:00,048 - [INFO] - from application in Thread-371 
16/08/25 15:05:00 INFO dstream.FileInputDStream: New files at time 1472108700000 ms:

2016-08-25 15:05:00,048 - [INFO] - from application in Thread-371 


2016-08-25 15:05:00,054 - [INFO] - from application in Thread-371 
16/08/25 15:05:00 INFO scheduler.JobScheduler: Added jobs for time 1472108700000 ms

2016-08-25 15:05:00,877 - [INFO] - from application in Thread-371 
16/08/25 15:05:00 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:05:05,050 - [INFO] - from application in Thread-371 
16/08/25 15:05:05 INFO dstream.FileInputDStream: Finding new files took 45 ms

2016-08-25 15:05:05,050 - [INFO] - from application in Thread-371 
16/08/25 15:05:05 INFO dstream.FileInputDStream: New files at time 1472108705000 ms:

2016-08-25 15:05:05,050 - [INFO] - from application in Thread-371 


2016-08-25 15:05:05,054 - [INFO] - from application in Thread-371 
16/08/25 15:05:05 INFO scheduler.JobScheduler: Added jobs for time 1472108705000 ms

2016-08-25 15:05:10,140 - [INFO] - from application in Thread-371 
16/08/25 15:05:10 INFO dstream.FileInputDStream: Finding new files took 135 ms

2016-08-25 15:05:10,140 - [INFO] - from application in Thread-371 
16/08/25 15:05:10 INFO dstream.FileInputDStream: New files at time 1472108710000 ms:

2016-08-25 15:05:10,140 - [INFO] - from application in Thread-371 


2016-08-25 15:05:10,144 - [INFO] - from application in Thread-371 
16/08/25 15:05:10 INFO scheduler.JobScheduler: Added jobs for time 1472108710000 ms

2016-08-25 15:05:15,068 - [INFO] - from application in Thread-371 
16/08/25 15:05:15 INFO dstream.FileInputDStream: Finding new files took 66 ms

2016-08-25 15:05:15,068 - [INFO] - from application in Thread-371 
16/08/25 15:05:15 INFO dstream.FileInputDStream: New files at time 1472108715000 ms:

2016-08-25 15:05:15,068 - [INFO] - from application in Thread-371 


2016-08-25 15:05:15,074 - [INFO] - from application in Thread-371 
16/08/25 15:05:15 INFO scheduler.JobScheduler: Added jobs for time 1472108715000 ms

2016-08-25 15:05:15,878 - [INFO] - from application in Thread-371 
16/08/25 15:05:15 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:05:18,303 - [INFO] - from play in play-internal-execution-context-37 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-25 15:05:19,632 - [INFO] - from play in play-internal-execution-context-37 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-25 15:05:19,637 - [INFO] - from play in play-internal-execution-context-37 
Application started (Dev)

2016-08-25 15:05:20,015 - [INFO] - from application in Thread-371 
16/08/25 15:05:20 INFO dstream.FileInputDStream: Finding new files took 11 ms

2016-08-25 15:05:20,018 - [INFO] - from application in Thread-371 
16/08/25 15:05:20 INFO dstream.FileInputDStream: New files at time 1472108720000 ms:

2016-08-25 15:05:20,018 - [INFO] - from application in Thread-371 


2016-08-25 15:05:20,021 - [INFO] - from application in Thread-371 
16/08/25 15:05:20 INFO scheduler.JobScheduler: Added jobs for time 1472108720000 ms

2016-08-25 15:05:25,024 - [INFO] - from application in Thread-371 
16/08/25 15:05:25 INFO dstream.FileInputDStream: Finding new files took 21 ms

2016-08-25 15:05:25,025 - [INFO] - from application in Thread-371 
16/08/25 15:05:25 INFO dstream.FileInputDStream: New files at time 1472108725000 ms:

2016-08-25 15:05:25,025 - [INFO] - from application in Thread-371 


2016-08-25 15:05:25,029 - [INFO] - from application in Thread-371 
16/08/25 15:05:25 INFO scheduler.JobScheduler: Added jobs for time 1472108725000 ms

2016-08-25 15:05:30,067 - [INFO] - from application in Thread-371 
16/08/25 15:05:30 INFO dstream.FileInputDStream: Finding new files took 63 ms

2016-08-25 15:05:30,067 - [INFO] - from application in Thread-371 
16/08/25 15:05:30 INFO dstream.FileInputDStream: New files at time 1472108730000 ms:

2016-08-25 15:05:30,067 - [INFO] - from application in Thread-371 


2016-08-25 15:05:30,072 - [INFO] - from application in Thread-371 
16/08/25 15:05:30 INFO scheduler.JobScheduler: Added jobs for time 1472108730000 ms

2016-08-25 15:05:30,878 - [INFO] - from application in Thread-371 
16/08/25 15:05:30 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:05:35,016 - [INFO] - from application in Thread-371 
16/08/25 15:05:35 INFO dstream.FileInputDStream: Finding new files took 11 ms

2016-08-25 15:05:35,016 - [INFO] - from application in Thread-371 
16/08/25 15:05:35 INFO dstream.FileInputDStream: New files at time 1472108735000 ms:

2016-08-25 15:05:35,016 - [INFO] - from application in Thread-371 


2016-08-25 15:05:35,020 - [INFO] - from application in Thread-371 
16/08/25 15:05:35 INFO scheduler.JobScheduler: Added jobs for time 1472108735000 ms

2016-08-25 15:05:40,010 - [INFO] - from application in Thread-371 
16/08/25 15:05:40 INFO dstream.FileInputDStream: Finding new files took 5 ms

2016-08-25 15:05:40,010 - [INFO] - from application in Thread-371 
16/08/25 15:05:40 INFO dstream.FileInputDStream: New files at time 1472108740000 ms:

2016-08-25 15:05:40,010 - [INFO] - from application in Thread-371 


2016-08-25 15:05:40,015 - [INFO] - from application in Thread-371 
16/08/25 15:05:40 INFO scheduler.JobScheduler: Added jobs for time 1472108740000 ms

2016-08-25 15:05:45,021 - [INFO] - from application in Thread-371 
16/08/25 15:05:45 INFO dstream.FileInputDStream: Finding new files took 16 ms

2016-08-25 15:05:45,021 - [INFO] - from application in Thread-371 
16/08/25 15:05:45 INFO dstream.FileInputDStream: New files at time 1472108745000 ms:

2016-08-25 15:05:45,021 - [INFO] - from application in Thread-371 


2016-08-25 15:05:45,027 - [INFO] - from application in Thread-371 
16/08/25 15:05:45 INFO scheduler.JobScheduler: Added jobs for time 1472108745000 ms

2016-08-25 15:05:45,877 - [INFO] - from application in Thread-371 
16/08/25 15:05:45 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:05:50,039 - [INFO] - from application in Thread-371 
16/08/25 15:05:50 INFO dstream.FileInputDStream: Finding new files took 35 ms

2016-08-25 15:05:50,039 - [INFO] - from application in Thread-371 
16/08/25 15:05:50 INFO dstream.FileInputDStream: New files at time 1472108750000 ms:

2016-08-25 15:05:50,039 - [INFO] - from application in Thread-371 


2016-08-25 15:05:50,044 - [INFO] - from application in Thread-371 
16/08/25 15:05:50 INFO scheduler.JobScheduler: Added jobs for time 1472108750000 ms

2016-08-25 15:05:55,017 - [INFO] - from application in Thread-371 
16/08/25 15:05:55 INFO dstream.FileInputDStream: Finding new files took 10 ms

2016-08-25 15:05:55,017 - [INFO] - from application in Thread-371 
16/08/25 15:05:55 INFO dstream.FileInputDStream: New files at time 1472108755000 ms:

2016-08-25 15:05:55,017 - [INFO] - from application in Thread-371 


2016-08-25 15:05:55,024 - [INFO] - from application in Thread-371 
16/08/25 15:05:55 INFO scheduler.JobScheduler: Added jobs for time 1472108755000 ms

2016-08-25 15:06:00,031 - [INFO] - from application in Thread-371 
16/08/25 15:06:00 INFO dstream.FileInputDStream: Finding new files took 27 ms

2016-08-25 15:06:00,031 - [INFO] - from application in Thread-371 
16/08/25 15:06:00 INFO dstream.FileInputDStream: New files at time 1472108760000 ms:

2016-08-25 15:06:00,031 - [INFO] - from application in Thread-371 


2016-08-25 15:06:00,036 - [INFO] - from application in Thread-371 
16/08/25 15:06:00 INFO scheduler.JobScheduler: Added jobs for time 1472108760000 ms

2016-08-25 15:06:00,878 - [INFO] - from application in Thread-371 
16/08/25 15:06:00 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:06:05,063 - [INFO] - from application in Thread-371 
16/08/25 15:06:05 INFO dstream.FileInputDStream: Finding new files took 57 ms

2016-08-25 15:06:05,063 - [INFO] - from application in Thread-371 
16/08/25 15:06:05 INFO dstream.FileInputDStream: New files at time 1472108765000 ms:

2016-08-25 15:06:05,063 - [INFO] - from application in Thread-371 


2016-08-25 15:06:05,068 - [INFO] - from application in Thread-371 
16/08/25 15:06:05 INFO scheduler.JobScheduler: Added jobs for time 1472108765000 ms

2016-08-25 15:06:10,014 - [INFO] - from application in Thread-371 
16/08/25 15:06:10 INFO dstream.FileInputDStream: Finding new files took 10 ms

2016-08-25 15:06:10,014 - [INFO] - from application in Thread-371 
16/08/25 15:06:10 INFO dstream.FileInputDStream: New files at time 1472108770000 ms:

2016-08-25 15:06:10,014 - [INFO] - from application in Thread-371 


2016-08-25 15:06:10,018 - [INFO] - from application in Thread-371 
16/08/25 15:06:10 INFO scheduler.JobScheduler: Added jobs for time 1472108770000 ms

2016-08-25 15:06:15,166 - [INFO] - from application in Thread-371 
16/08/25 15:06:15 INFO dstream.FileInputDStream: Finding new files took 164 ms

2016-08-25 15:06:15,166 - [INFO] - from application in Thread-371 
16/08/25 15:06:15 INFO dstream.FileInputDStream: New files at time 1472108775000 ms:

2016-08-25 15:06:15,166 - [INFO] - from application in Thread-371 


2016-08-25 15:06:15,171 - [INFO] - from application in Thread-371 
16/08/25 15:06:15 INFO scheduler.JobScheduler: Added jobs for time 1472108775000 ms

2016-08-25 15:06:15,878 - [INFO] - from application in Thread-371 
16/08/25 15:06:15 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:06:18,612 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR cluster.SparkDeploySchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED

2016-08-25 15:06:18,613 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 

2016-08-25 15:06:18,618 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.TaskSchedulerImpl: Cancelling stage 1

2016-08-25 15:06:18,619 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.DAGScheduler: ResultStage 1 (print at HDFSWordCount.scala:20) failed in 152.743 s

2016-08-25 15:06:18,620 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.DAGScheduler: Job 0 failed: print at HDFSWordCount.scala:20, took 152.869413 s

2016-08-25 15:06:18,621 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108625000 ms.0 from job set of time 1472108625000 ms

2016-08-25 15:06:18,622 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 153.621 s for time 1472108625000 ms (execution: 152.897 s)

2016-08-25 15:06:18,624 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108630000 ms.0 from job set of time 1472108630000 ms

2016-08-25 15:06:18,624 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108630000 ms.0 from job set of time 1472108630000 ms

2016-08-25 15:06:18,624 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 148.624 s for time 1472108630000 ms (execution: 0.001 s)

2016-08-25 15:06:18,625 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108635000 ms.0 from job set of time 1472108635000 ms

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108625000 ms.0

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1283)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1271)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1270)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1270)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at scala.Option.foreach(Option.scala:236)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:697)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1496)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1458)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1447)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:567)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824)

2016-08-25 15:06:18,627 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO dstream.FileInputDStream: Cleared 0 old files that were older than 1472108565000 ms: 

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108630000 ms.0

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,628 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
Exception in thread "main" 16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108635000 ms.0 from job set of time 1472108635000 ms

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1283)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1271)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1270)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1270)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at scala.Option.foreach(Option.scala:236)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:697)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1496)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1458)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1447)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:567)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,629 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 143.627 s for time 1472108635000 ms (execution: 0.002 s)

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108640000 ms.0 from job set of time 1472108640000 ms

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108635000 ms.0

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,630 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108640000 ms.0 from job set of time 1472108640000 ms

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 138.631 s for time 1472108640000 ms (execution: 0.001 s)

2016-08-25 15:06:18,631 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.ReceivedBlockTracker: Deleting batches ArrayBuffer()

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108645000 ms.0 from job set of time 1472108645000 ms

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108640000 ms.0

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,632 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO streaming.StreamingContext: Invoking stop(stopGracefully=false) from shutdown hook

2016-08-25 15:06:18,633 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobGenerator: Stopping JobGenerator immediately

2016-08-25 15:06:18,634 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO util.RecurringTimer: Stopped timer for JobGenerator after time 1472108775000

2016-08-25 15:06:18,634 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108645000 ms.0 from job set of time 1472108645000 ms

2016-08-25 15:06:18,634 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.InputInfoTracker: remove old batch metadata: 

2016-08-25 15:06:18,634 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 133.634 s for time 1472108645000 ms (execution: 0.002 s)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108650000 ms.0 from job set of time 1472108650000 ms

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108645000 ms.0

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,635 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO rdd.ShuffledRDD: Removing RDD 4 from persistence list

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobGenerator: Stopped JobGenerator

2016-08-25 15:06:18,636 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108650000 ms.0 from job set of time 1472108650000 ms

2016-08-25 15:06:18,637 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 128.636 s for time 1472108650000 ms (execution: 0.001 s)

2016-08-25 15:06:18,637 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108655000 ms.0 from job set of time 1472108655000 ms

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108650000 ms.0

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,638 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,639 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108655000 ms.0 from job set of time 1472108655000 ms

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 123.639 s for time 1472108655000 ms (execution: 0.002 s)

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108660000 ms.0 from job set of time 1472108660000 ms

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108655000 ms.0

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,640 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static/streaming,null}

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/streaming/batch/json,null}

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/streaming/batch,null}

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/streaming/json,null}

2016-08-25 15:06:18,641 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/streaming,null}

2016-08-25 15:06:18,642 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}

2016-08-25 15:06:18,642 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}

2016-08-25 15:06:18,642 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}

2016-08-25 15:06:18,642 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}

2016-08-25 15:06:18,642 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}

2016-08-25 15:06:18,642 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}

2016-08-25 15:06:18,643 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}

2016-08-25 15:06:18,643 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}

2016-08-25 15:06:18,643 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}

2016-08-25 15:06:18,643 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO storage.BlockManager: Removing RDD 4

2016-08-25 15:06:18,643 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}

2016-08-25 15:06:18,643 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}

2016-08-25 15:06:18,643 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108660000 ms.0 from job set of time 1472108660000 ms

2016-08-25 15:06:18,643 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}

2016-08-25 15:06:18,643 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}

2016-08-25 15:06:18,643 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}

2016-08-25 15:06:18,643 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 118.642 s for time 1472108660000 ms (execution: 0.002 s)

2016-08-25 15:06:18,643 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108665000 ms.0 from job set of time 1472108665000 ms

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108660000 ms.0

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,644 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}

2016-08-25 15:06:18,645 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108665000 ms.0 from job set of time 1472108665000 ms

2016-08-25 15:06:18,646 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 113.645 s for time 1472108665000 ms (execution: 0.001 s)

2016-08-25 15:06:18,646 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108670000 ms.0 from job set of time 1472108670000 ms

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108665000 ms.0

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,647 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,648 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108670000 ms.0 from job set of time 1472108670000 ms

2016-08-25 15:06:18,648 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 108.648 s for time 1472108670000 ms (execution: 0.002 s)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108675000 ms.0 from job set of time 1472108675000 ms

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108670000 ms.0

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,649 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,650 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,650 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,650 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,650 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,650 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,651 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108675000 ms.0 from job set of time 1472108675000 ms

2016-08-25 15:06:18,651 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 103.651 s for time 1472108675000 ms (execution: 0.002 s)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108680000 ms.0 from job set of time 1472108680000 ms

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108675000 ms.0

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,652 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,653 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,653 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,653 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,653 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,653 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,654 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108680000 ms.0 from job set of time 1472108680000 ms

2016-08-25 15:06:18,654 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 98.654 s for time 1472108680000 ms (execution: 0.002 s)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108685000 ms.0 from job set of time 1472108685000 ms

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108680000 ms.0

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,655 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,657 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108685000 ms.0 from job set of time 1472108685000 ms

2016-08-25 15:06:18,657 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 93.656 s for time 1472108685000 ms (execution: 0.001 s)

2016-08-25 15:06:18,657 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108690000 ms.0 from job set of time 1472108690000 ms

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108685000 ms.0

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,658 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,659 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108690000 ms.0 from job set of time 1472108690000 ms

2016-08-25 15:06:18,659 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 88.659 s for time 1472108690000 ms (execution: 0.002 s)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108695000 ms.0 from job set of time 1472108695000 ms

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108690000 ms.0

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,660 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,661 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,661 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,661 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,661 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,662 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108695000 ms.0 from job set of time 1472108695000 ms

2016-08-25 15:06:18,662 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 83.662 s for time 1472108695000 ms (execution: 0.002 s)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108700000 ms.0 from job set of time 1472108700000 ms

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108695000 ms.0

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,663 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,665 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108700000 ms.0 from job set of time 1472108700000 ms

2016-08-25 15:06:18,665 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 78.665 s for time 1472108700000 ms (execution: 0.002 s)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108705000 ms.0 from job set of time 1472108705000 ms

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108700000 ms.0

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,666 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,668 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108705000 ms.0 from job set of time 1472108705000 ms

2016-08-25 15:06:18,668 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 73.668 s for time 1472108705000 ms (execution: 0.003 s)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108710000 ms.0 from job set of time 1472108710000 ms

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108705000 ms.0

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,669 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,670 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108710000 ms.0 from job set of time 1472108710000 ms

2016-08-25 15:06:18,670 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 68.670 s for time 1472108710000 ms (execution: 0.001 s)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108715000 ms.0 from job set of time 1472108715000 ms

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108710000 ms.0

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,671 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,672 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,672 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,672 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,672 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,672 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,672 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,672 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,672 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,672 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,672 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,673 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108715000 ms.0 from job set of time 1472108715000 ms

2016-08-25 15:06:18,673 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 63.672 s for time 1472108715000 ms (execution: 0.001 s)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108720000 ms.0 from job set of time 1472108720000 ms

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108715000 ms.0

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,674 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,675 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108720000 ms.0 from job set of time 1472108720000 ms

2016-08-25 15:06:18,675 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 58.675 s for time 1472108720000 ms (execution: 0.002 s)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108725000 ms.0 from job set of time 1472108725000 ms

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108720000 ms.0

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,676 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,677 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,677 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,677 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,677 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,677 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,677 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,677 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,678 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108725000 ms.0 from job set of time 1472108725000 ms

2016-08-25 15:06:18,678 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 53.678 s for time 1472108725000 ms (execution: 0.002 s)

2016-08-25 15:06:18,679 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108730000 ms.0 from job set of time 1472108730000 ms

2016-08-25 15:06:18,679 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108725000 ms.0

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,680 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,681 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108730000 ms.0 from job set of time 1472108730000 ms

2016-08-25 15:06:18,681 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 48.681 s for time 1472108730000 ms (execution: 0.002 s)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108735000 ms.0 from job set of time 1472108735000 ms

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108730000 ms.0

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,682 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,684 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108735000 ms.0 from job set of time 1472108735000 ms

2016-08-25 15:06:18,684 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 43.684 s for time 1472108735000 ms (execution: 0.002 s)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108740000 ms.0 from job set of time 1472108740000 ms

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108735000 ms.0

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,685 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,686 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108740000 ms.0 from job set of time 1472108740000 ms

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 38.686 s for time 1472108740000 ms (execution: 0.002 s)

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108745000 ms.0 from job set of time 1472108745000 ms

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108740000 ms.0

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,687 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,688 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,689 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108745000 ms.0 from job set of time 1472108745000 ms

2016-08-25 15:06:18,689 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 33.689 s for time 1472108745000 ms (execution: 0.002 s)

2016-08-25 15:06:18,689 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108750000 ms.0 from job set of time 1472108750000 ms

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108745000 ms.0

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,690 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,691 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108750000 ms.0 from job set of time 1472108750000 ms

2016-08-25 15:06:18,691 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 28.691 s for time 1472108750000 ms (execution: 0.002 s)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108755000 ms.0 from job set of time 1472108755000 ms

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108750000 ms.0

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,692 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,693 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108755000 ms.0 from job set of time 1472108755000 ms

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 23.693 s for time 1472108755000 ms (execution: 0.001 s)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108760000 ms.0 from job set of time 1472108760000 ms

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108755000 ms.0

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,694 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,695 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,695 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,695 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,695 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,695 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,695 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,695 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,695 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,695 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,695 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,695 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,695 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,696 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108760000 ms.0 from job set of time 1472108760000 ms

2016-08-25 15:06:18,696 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 18.696 s for time 1472108760000 ms (execution: 0.002 s)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108765000 ms.0 from job set of time 1472108765000 ms

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108760000 ms.0

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,697 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO ui.SparkUI: Stopped Spark web UI at http://10.236.66.144:4040

2016-08-25 15:06:18,698 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108765000 ms.0 from job set of time 1472108765000 ms

2016-08-25 15:06:18,699 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 13.698 s for time 1472108765000 ms (execution: 0.002 s)

2016-08-25 15:06:18,699 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108770000 ms.0 from job set of time 1472108770000 ms

2016-08-25 15:06:18,699 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108765000 ms.0

2016-08-25 15:06:18,699 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,699 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,699 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,700 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.DAGScheduler: Stopping DAGScheduler

2016-08-25 15:06:18,701 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO cluster.SparkDeploySchedulerBackend: Shutting down all executors

2016-08-25 15:06:18,701 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108770000 ms.0 from job set of time 1472108770000 ms

2016-08-25 15:06:18,702 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 8.701 s for time 1472108770000 ms (execution: 0.002 s)

2016-08-25 15:06:18,702 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Starting job streaming job 1472108775000 ms.0 from job set of time 1472108775000 ms

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.JobScheduler: Error running job streaming job 1472108770000 ms.0

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
java.lang.IllegalStateException: SparkContext has been shutdown

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1816)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1302)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:722)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream$$anonfun$print$2$$anonfun$foreachFunc$5$1.apply(DStream.scala:721)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:42)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:399)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:40)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:40)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at scala.util.Try$.apply(Try.scala:161)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:34)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:218)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:218)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:217)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

2016-08-25 15:06:18,703 - [INFO] - from application in Thread-371 
	at java.lang.Thread.run(Thread.java:744)

2016-08-25 15:06:18,704 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO cluster.SparkDeploySchedulerBackend: Asking each executor to shut down

2016-08-25 15:06:18,705 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Finished job streaming job 1472108775000 ms.0 from job set of time 1472108775000 ms

2016-08-25 15:06:18,705 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Total delay: 3.704 s for time 1472108775000 ms (execution: 0.002 s)

2016-08-25 15:06:18,706 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 ERROR scheduler.StreamingListenerBus: StreamingListenerBus has already stopped! Dropping event StreamingListenerBatchCompleted(BatchInfo(1472108775000 ms,Map(0 -> StreamInputInfo(0,0,Map(files -> List(), Description -> ))),1472108775171,Some(1472108778702),Some(1472108778704)))

2016-08-25 15:06:18,706 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO scheduler.JobScheduler: Stopped JobScheduler

2016-08-25 15:06:18,710 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO streaming.StreamingContext: StreamingContext stopped successfully

2016-08-25 15:06:18,710 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO storage.DiskBlockManager: Shutdown hook called

2016-08-25 15:06:18,712 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO util.ShutdownHookManager: Shutdown hook called

2016-08-25 15:06:18,713 - [INFO] - from application in Thread-371 
16/08/25 15:06:18 INFO util.ShutdownHookManager: Deleting directory /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/spark-1f1f4063-e2aa-4012-ab1c-debb67a3e0fc

2016-08-25 15:06:19,212 - [INFO] - from application in ForkJoinPool-4-worker-9 
执行结束!

2016-08-25 15:06:23,730 - [INFO] - from play in play-internal-execution-context-37 
database [default] connected at jdbc:mysql://10.73.33.41/playdb?useUnicode=true&characterEncoding=utf-8

2016-08-25 15:06:24,643 - [INFO] - from play in play-internal-execution-context-37 
database [test] connected at jdbc:mysql://10.73.33.41/test?useUnicode=true&characterEncoding=utf-8

2016-08-25 15:06:24,647 - [INFO] - from play in play-internal-execution-context-37 
Application started (Dev)

2016-08-25 15:06:27,752 - [INFO] - from play in New I/O worker #10 
Starting application default Akka system.

2016-08-25 15:06:33,383 - [INFO] - from application in play-akka.actor.default-dispatcher-1305 
用户名=>liangkai1@staff.weibo.com

2016-08-25 15:07:11,594 - [INFO] - from application in play-akka.actor.default-dispatcher-1301 
执行模式=>standalone

2016-08-25 15:07:11,596 - [INFO] - from application in jobSystem-akka.actor.default-dispatcher-4 
select mode 2

2016-08-25 15:07:11,604 - [INFO] - from application in pool-733-thread-1 
args ArrayBuffer(/usr/local/spark/bin/spark-submit, --master, spark://localhost:7077, --class, com.weibo.spark.stream.HDFSWordCount, --num-executors, 2, --executor-memory, 2g, --driver-memory, 2g, --total-executor-cores, 2, /tmp/file/sparkStream.jar, )

2016-08-25 15:07:12,275 - [INFO] - from application in Thread-379 
16/08/25 15:07:12 INFO spark.SparkContext: Running Spark version 1.5.2

2016-08-25 15:07:12,564 - [INFO] - from application in Thread-379 
16/08/25 15:07:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

2016-08-25 15:07:12,662 - [INFO] - from application in Thread-379 
16/08/25 15:07:12 INFO spark.SecurityManager: Changing view acls to: king

2016-08-25 15:07:12,662 - [INFO] - from application in Thread-379 
16/08/25 15:07:12 INFO spark.SecurityManager: Changing modify acls to: king

2016-08-25 15:07:12,663 - [INFO] - from application in Thread-379 
16/08/25 15:07:12 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(king); users with modify permissions: Set(king)

2016-08-25 15:07:13,175 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO slf4j.Slf4jLogger: Slf4jLogger started

2016-08-25 15:07:13,209 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO Remoting: Starting remoting

2016-08-25 15:07:13,336 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.236.66.144:52311]

2016-08-25 15:07:13,342 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO util.Utils: Successfully started service 'sparkDriver' on port 52311.

2016-08-25 15:07:13,360 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO spark.SparkEnv: Registering MapOutputTracker

2016-08-25 15:07:13,373 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO spark.SparkEnv: Registering BlockManagerMaster

2016-08-25 15:07:13,393 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO storage.DiskBlockManager: Created local directory at /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/blockmgr-938797a2-71a3-4990-8c05-4c77c56b6ebb

2016-08-25 15:07:13,399 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO storage.MemoryStore: MemoryStore started with capacity 1060.0 MB

2016-08-25 15:07:13,451 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO spark.HttpFileServer: HTTP File server directory is /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/spark-b09e974e-d855-4ae3-b1ac-448b74323c2e/httpd-769799c4-c735-48f0-95b1-810bd3e426c1

2016-08-25 15:07:13,454 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO spark.HttpServer: Starting HTTP Server

2016-08-25 15:07:13,493 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO server.Server: jetty-8.y.z-SNAPSHOT

2016-08-25 15:07:13,507 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52312

2016-08-25 15:07:13,507 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO util.Utils: Successfully started service 'HTTP file server' on port 52312.

2016-08-25 15:07:13,518 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO spark.SparkEnv: Registering OutputCommitCoordinator

2016-08-25 15:07:13,595 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO server.Server: jetty-8.y.z-SNAPSHOT

2016-08-25 15:07:13,603 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040

2016-08-25 15:07:13,604 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.

2016-08-25 15:07:13,605 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO ui.SparkUI: Started SparkUI at http://10.236.66.144:4040

2016-08-25 15:07:13,635 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO spark.SparkContext: Added JAR file:/tmp/file/sparkStream.jar at http://10.236.66.144:52312/jars/sparkStream.jar with timestamp 1472108833634

2016-08-25 15:07:13,687 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 WARN metrics.MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.

2016-08-25 15:07:13,700 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO client.AppClient$ClientEndpoint: Connecting to master spark://localhost:7077...

2016-08-25 15:07:13,844 - [INFO] - from application in play-akka.actor.default-dispatcher-1301 
用户任务Id====>app-20160825150713-0015

2016-08-25 15:07:13,947 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52315.

2016-08-25 15:07:13,948 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO netty.NettyBlockTransferService: Server created on 52315

2016-08-25 15:07:13,949 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO storage.BlockManagerMaster: Trying to register BlockManager

2016-08-25 15:07:13,951 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.236.66.144:52315 with 1060.0 MB RAM, BlockManagerId(driver, 10.236.66.144, 52315)

2016-08-25 15:07:13,953 - [INFO] - from application in Thread-379 
16/08/25 15:07:13 INFO storage.BlockManagerMaster: Registered BlockManager

2016-08-25 15:07:14,072 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO cluster.SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

2016-08-25 15:07:14,323 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FileInputDStream: Duration for remembering RDDs set to 60000 ms for org.apache.spark.streaming.dstream.FileInputDStream@e1e2e5e

2016-08-25 15:07:14,386 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.ForEachDStream: metadataCleanupDelay = -1

2016-08-25 15:07:14,387 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.ShuffledDStream: metadataCleanupDelay = -1

2016-08-25 15:07:14,387 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.MappedDStream: metadataCleanupDelay = -1

2016-08-25 15:07:14,387 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FlatMappedDStream: metadataCleanupDelay = -1

2016-08-25 15:07:14,387 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.MappedDStream: metadataCleanupDelay = -1

2016-08-25 15:07:14,387 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FileInputDStream: metadataCleanupDelay = -1

2016-08-25 15:07:14,387 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FileInputDStream: Slide time = 5000 ms

2016-08-25 15:07:14,388 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FileInputDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:07:14,388 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FileInputDStream: Checkpoint interval = null

2016-08-25 15:07:14,388 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FileInputDStream: Remember duration = 60000 ms

2016-08-25 15:07:14,388 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@e1e2e5e

2016-08-25 15:07:14,388 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.MappedDStream: Slide time = 5000 ms

2016-08-25 15:07:14,388 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.MappedDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.MappedDStream: Checkpoint interval = null

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.MappedDStream: Remember duration = 5000 ms

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@6fd85a1e

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FlatMappedDStream: Slide time = 5000 ms

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FlatMappedDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FlatMappedDStream: Checkpoint interval = null

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FlatMappedDStream: Remember duration = 5000 ms

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.FlatMappedDStream: Initialized and validated org.apache.spark.streaming.dstream.FlatMappedDStream@cfa21c0

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.MappedDStream: Slide time = 5000 ms

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.MappedDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.MappedDStream: Checkpoint interval = null

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.MappedDStream: Remember duration = 5000 ms

2016-08-25 15:07:14,389 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@39de3561

2016-08-25 15:07:14,390 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.ShuffledDStream: Slide time = 5000 ms

2016-08-25 15:07:14,390 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.ShuffledDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:07:14,390 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.ShuffledDStream: Checkpoint interval = null

2016-08-25 15:07:14,390 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.ShuffledDStream: Remember duration = 5000 ms

2016-08-25 15:07:14,390 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@3a5d882e

2016-08-25 15:07:14,390 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.ForEachDStream: Slide time = 5000 ms

2016-08-25 15:07:14,390 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.ForEachDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:07:14,390 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.ForEachDStream: Checkpoint interval = null

2016-08-25 15:07:14,390 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.ForEachDStream: Remember duration = 5000 ms

2016-08-25 15:07:14,390 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO dstream.ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@17783dd1

2016-08-25 15:07:14,416 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO util.RecurringTimer: Started timer for JobGenerator at time 1472108835000

2016-08-25 15:07:14,417 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO scheduler.JobGenerator: Started JobGenerator at 1472108835000 ms

2016-08-25 15:07:14,417 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO scheduler.JobScheduler: Started JobScheduler

2016-08-25 15:07:14,420 - [INFO] - from application in Thread-379 
16/08/25 15:07:14 INFO streaming.StreamingContext: StreamingContext started

2016-08-25 15:07:15,559 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO dstream.FileInputDStream: Finding new files took 546 ms

2016-08-25 15:07:15,560 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO dstream.FileInputDStream: New files at time 1472108835000 ms:

2016-08-25 15:07:15,560 - [INFO] - from application in Thread-379 


2016-08-25 15:07:15,584 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO scheduler.JobScheduler: Added jobs for time 1472108835000 ms

2016-08-25 15:07:15,585 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO scheduler.JobScheduler: Starting job streaming job 1472108835000 ms.0 from job set of time 1472108835000 ms

2016-08-25 15:07:15,606 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO spark.SparkContext: Starting job: print at HDFSWordCount.scala:20

2016-08-25 15:07:15,617 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO scheduler.DAGScheduler: Registering RDD 3 (map at HDFSWordCount.scala:17)

2016-08-25 15:07:15,619 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO scheduler.DAGScheduler: Got job 0 (print at HDFSWordCount.scala:20) with 1 output partitions

2016-08-25 15:07:15,619 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO scheduler.DAGScheduler: Final stage: ResultStage 1(print at HDFSWordCount.scala:20)

2016-08-25 15:07:15,619 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)

2016-08-25 15:07:15,620 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO scheduler.DAGScheduler: Missing parents: List()

2016-08-25 15:07:15,625 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at HDFSWordCount.scala:18), which has no missing parents

2016-08-25 15:07:15,700 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO storage.MemoryStore: ensureFreeSpace(2344) called with curMem=0, maxMem=1111511531

2016-08-25 15:07:15,702 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1060.0 MB)

2016-08-25 15:07:15,710 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO storage.MemoryStore: ensureFreeSpace(1435) called with curMem=2344, maxMem=1111511531

2016-08-25 15:07:15,710 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1435.0 B, free 1060.0 MB)

2016-08-25 15:07:15,712 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.236.66.144:52315 (size: 1435.0 B, free: 1060.0 MB)

2016-08-25 15:07:15,714 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861

2016-08-25 15:07:15,717 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at HDFSWordCount.scala:18)

2016-08-25 15:07:15,717 - [INFO] - from application in Thread-379 
16/08/25 15:07:15 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks

2016-08-25 15:07:20,160 - [INFO] - from application in Thread-379 
16/08/25 15:07:20 INFO dstream.FileInputDStream: Finding new files took 154 ms

2016-08-25 15:07:20,161 - [INFO] - from application in Thread-379 
16/08/25 15:07:20 INFO dstream.FileInputDStream: New files at time 1472108840000 ms:

2016-08-25 15:07:20,161 - [INFO] - from application in Thread-379 


2016-08-25 15:07:20,169 - [INFO] - from application in Thread-379 
16/08/25 15:07:20 INFO scheduler.JobScheduler: Added jobs for time 1472108840000 ms

2016-08-25 15:07:25,014 - [INFO] - from application in Thread-379 
16/08/25 15:07:25 INFO dstream.FileInputDStream: Finding new files took 9 ms

2016-08-25 15:07:25,014 - [INFO] - from application in Thread-379 
16/08/25 15:07:25 INFO dstream.FileInputDStream: New files at time 1472108845000 ms:

2016-08-25 15:07:25,014 - [INFO] - from application in Thread-379 


2016-08-25 15:07:25,021 - [INFO] - from application in Thread-379 
16/08/25 15:07:25 INFO scheduler.JobScheduler: Added jobs for time 1472108845000 ms

2016-08-25 15:07:30,063 - [INFO] - from application in Thread-379 
16/08/25 15:07:30 INFO dstream.FileInputDStream: Finding new files took 56 ms

2016-08-25 15:07:30,063 - [INFO] - from application in Thread-379 
16/08/25 15:07:30 INFO dstream.FileInputDStream: New files at time 1472108850000 ms:

2016-08-25 15:07:30,063 - [INFO] - from application in Thread-379 


2016-08-25 15:07:30,070 - [INFO] - from application in Thread-379 
16/08/25 15:07:30 INFO scheduler.JobScheduler: Added jobs for time 1472108850000 ms

2016-08-25 15:07:30,727 - [INFO] - from application in Thread-379 
16/08/25 15:07:30 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:07:35,301 - [INFO] - from application in Thread-379 
16/08/25 15:07:35 INFO dstream.FileInputDStream: Finding new files took 296 ms

2016-08-25 15:07:35,302 - [INFO] - from application in Thread-379 
16/08/25 15:07:35 INFO dstream.FileInputDStream: New files at time 1472108855000 ms:

2016-08-25 15:07:35,302 - [INFO] - from application in Thread-379 


2016-08-25 15:07:35,307 - [INFO] - from application in Thread-379 
16/08/25 15:07:35 INFO scheduler.JobScheduler: Added jobs for time 1472108855000 ms

2016-08-25 15:07:40,103 - [INFO] - from application in Thread-379 
16/08/25 15:07:40 INFO dstream.FileInputDStream: Finding new files took 98 ms

2016-08-25 15:07:40,103 - [INFO] - from application in Thread-379 
16/08/25 15:07:40 INFO dstream.FileInputDStream: New files at time 1472108860000 ms:

2016-08-25 15:07:40,103 - [INFO] - from application in Thread-379 


2016-08-25 15:07:40,111 - [INFO] - from application in Thread-379 
16/08/25 15:07:40 INFO scheduler.JobScheduler: Added jobs for time 1472108860000 ms

2016-08-25 15:07:45,021 - [INFO] - from application in Thread-379 
16/08/25 15:07:45 INFO dstream.FileInputDStream: Finding new files took 15 ms

2016-08-25 15:07:45,021 - [INFO] - from application in Thread-379 
16/08/25 15:07:45 INFO dstream.FileInputDStream: New files at time 1472108865000 ms:

2016-08-25 15:07:45,021 - [INFO] - from application in Thread-379 


2016-08-25 15:07:45,026 - [INFO] - from application in Thread-379 
16/08/25 15:07:45 INFO scheduler.JobScheduler: Added jobs for time 1472108865000 ms

2016-08-25 15:07:45,727 - [INFO] - from application in Thread-379 
16/08/25 15:07:45 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:07:50,035 - [INFO] - from application in Thread-379 
16/08/25 15:07:50 INFO dstream.FileInputDStream: Finding new files took 27 ms

2016-08-25 15:07:50,035 - [INFO] - from application in Thread-379 
16/08/25 15:07:50 INFO dstream.FileInputDStream: New files at time 1472108870000 ms:

2016-08-25 15:07:50,035 - [INFO] - from application in Thread-379 


2016-08-25 15:07:50,042 - [INFO] - from application in Thread-379 
16/08/25 15:07:50 INFO scheduler.JobScheduler: Added jobs for time 1472108870000 ms

2016-08-25 15:07:51,422 - [INFO] - from application in play-akka.actor.default-dispatcher-1304 
执行模式=>standalone

2016-08-25 15:07:51,423 - [INFO] - from application in jobSystem-akka.actor.default-dispatcher-4 
select mode 2

2016-08-25 15:07:51,423 - [INFO] - from application in pool-733-thread-2 
args ArrayBuffer(/usr/local/spark/bin/spark-submit, --master, spark://localhost:7077, --class, com.weibo.spark.stream.HDFSWordCount, --num-executors, 2, --executor-memory, 2g, --driver-memory, 2g, --total-executor-cores, 12, /tmp/file/sparkStream.jar, )

2016-08-25 15:07:52,090 - [INFO] - from application in Thread-381 
16/08/25 15:07:52 INFO spark.SparkContext: Running Spark version 1.5.2

2016-08-25 15:07:52,406 - [INFO] - from application in Thread-381 
16/08/25 15:07:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

2016-08-25 15:07:52,509 - [INFO] - from application in Thread-381 
16/08/25 15:07:52 INFO spark.SecurityManager: Changing view acls to: king

2016-08-25 15:07:52,509 - [INFO] - from application in Thread-381 
16/08/25 15:07:52 INFO spark.SecurityManager: Changing modify acls to: king

2016-08-25 15:07:52,510 - [INFO] - from application in Thread-381 
16/08/25 15:07:52 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(king); users with modify permissions: Set(king)

2016-08-25 15:07:52,999 - [INFO] - from application in Thread-381 
16/08/25 15:07:52 INFO slf4j.Slf4jLogger: Slf4jLogger started

2016-08-25 15:07:53,029 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO Remoting: Starting remoting

2016-08-25 15:07:53,163 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.236.66.144:52336]

2016-08-25 15:07:53,169 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO util.Utils: Successfully started service 'sparkDriver' on port 52336.

2016-08-25 15:07:53,185 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO spark.SparkEnv: Registering MapOutputTracker

2016-08-25 15:07:53,197 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO spark.SparkEnv: Registering BlockManagerMaster

2016-08-25 15:07:53,216 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO storage.DiskBlockManager: Created local directory at /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/blockmgr-587357f1-0bea-4aa6-b4a7-962ace2afa00

2016-08-25 15:07:53,221 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO storage.MemoryStore: MemoryStore started with capacity 1060.0 MB

2016-08-25 15:07:53,268 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO spark.HttpFileServer: HTTP File server directory is /private/var/folders/c0/zs327zy53v12p389np1zrv200000gn/T/spark-d1f1adce-897d-4b69-9c55-98616a43a2ac/httpd-f78ace0c-b6f5-40be-92f2-ac1bec607bd3

2016-08-25 15:07:53,271 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO spark.HttpServer: Starting HTTP Server

2016-08-25 15:07:53,311 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO server.Server: jetty-8.y.z-SNAPSHOT

2016-08-25 15:07:53,324 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52337

2016-08-25 15:07:53,324 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO util.Utils: Successfully started service 'HTTP file server' on port 52337.

2016-08-25 15:07:53,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO spark.SparkEnv: Registering OutputCommitCoordinator

2016-08-25 15:07:53,424 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO server.Server: jetty-8.y.z-SNAPSHOT

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
java.net.BindException: Address already in use

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at sun.nio.ch.Net.bind0(Native Method)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at sun.nio.ch.Net.bind(Net.java:414)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at sun.nio.ch.Net.bind(Net.java:406)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1920)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1911)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:137)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:474)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:474)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at scala.Option.foreach(Option.scala:236)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:474)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:878)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:81)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at com.weibo.spark.stream.HDFSWordCount$.main(HDFSWordCount.scala:12)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at com.weibo.spark.stream.HDFSWordCount.main(HDFSWordCount.scala)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at java.lang.reflect.Method.invoke(Method.java:483)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:674)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)

2016-08-25 15:07:53,432 - [INFO] - from application in Thread-381 
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 WARN component.AbstractLifeCycle: FAILED org.spark-project.jetty.server.Server@ecf9049: java.net.BindException: Address already in use

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
java.net.BindException: Address already in use

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at sun.nio.ch.Net.bind0(Native Method)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at sun.nio.ch.Net.bind(Net.java:414)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at sun.nio.ch.Net.bind(Net.java:406)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1920)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1911)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:137)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:474)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:474)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at scala.Option.foreach(Option.scala:236)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:474)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:878)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:81)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at com.weibo.spark.stream.HDFSWordCount$.main(HDFSWordCount.scala:12)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at com.weibo.spark.stream.HDFSWordCount.main(HDFSWordCount.scala)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at java.lang.reflect.Method.invoke(Method.java:483)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:674)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)

2016-08-25 15:07:53,433 - [INFO] - from application in Thread-381 
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

2016-08-25 15:07:53,437 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}

2016-08-25 15:07:53,437 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}

2016-08-25 15:07:53,437 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}

2016-08-25 15:07:53,437 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}

2016-08-25 15:07:53,437 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}

2016-08-25 15:07:53,437 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}

2016-08-25 15:07:53,437 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}

2016-08-25 15:07:53,437 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}

2016-08-25 15:07:53,438 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}

2016-08-25 15:07:53,438 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}

2016-08-25 15:07:53,438 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}

2016-08-25 15:07:53,438 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}

2016-08-25 15:07:53,438 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}

2016-08-25 15:07:53,438 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}

2016-08-25 15:07:53,438 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}

2016-08-25 15:07:53,438 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}

2016-08-25 15:07:53,439 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}

2016-08-25 15:07:53,439 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}

2016-08-25 15:07:53,439 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}

2016-08-25 15:07:53,439 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}

2016-08-25 15:07:53,439 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}

2016-08-25 15:07:53,439 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}

2016-08-25 15:07:53,439 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}

2016-08-25 15:07:53,439 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}

2016-08-25 15:07:53,493 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.

2016-08-25 15:07:53,495 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO server.Server: jetty-8.y.z-SNAPSHOT

2016-08-25 15:07:53,503 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4041

2016-08-25 15:07:53,503 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO util.Utils: Successfully started service 'SparkUI' on port 4041.

2016-08-25 15:07:53,504 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO ui.SparkUI: Started SparkUI at http://10.236.66.144:4041

2016-08-25 15:07:53,538 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO spark.SparkContext: Added JAR file:/tmp/file/sparkStream.jar at http://10.236.66.144:52337/jars/sparkStream.jar with timestamp 1472108873538

2016-08-25 15:07:53,595 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 WARN metrics.MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.

2016-08-25 15:07:53,608 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO client.AppClient$ClientEndpoint: Connecting to master spark://localhost:7077...

2016-08-25 15:07:53,747 - [INFO] - from application in play-akka.actor.default-dispatcher-1304 
用户任务Id====>app-20160825150753-0016

2016-08-25 15:07:53,866 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52339.

2016-08-25 15:07:53,867 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO netty.NettyBlockTransferService: Server created on 52339

2016-08-25 15:07:53,868 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO storage.BlockManagerMaster: Trying to register BlockManager

2016-08-25 15:07:53,870 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.236.66.144:52339 with 1060.0 MB RAM, BlockManagerId(driver, 10.236.66.144, 52339)

2016-08-25 15:07:53,872 - [INFO] - from application in Thread-381 
16/08/25 15:07:53 INFO storage.BlockManagerMaster: Registered BlockManager

2016-08-25 15:07:54,044 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO cluster.SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

2016-08-25 15:07:54,262 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FileInputDStream: Duration for remembering RDDs set to 60000 ms for org.apache.spark.streaming.dstream.FileInputDStream@5f780a86

2016-08-25 15:07:54,331 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.ForEachDStream: metadataCleanupDelay = -1

2016-08-25 15:07:54,333 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.ShuffledDStream: metadataCleanupDelay = -1

2016-08-25 15:07:54,333 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.MappedDStream: metadataCleanupDelay = -1

2016-08-25 15:07:54,333 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FlatMappedDStream: metadataCleanupDelay = -1

2016-08-25 15:07:54,334 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.MappedDStream: metadataCleanupDelay = -1

2016-08-25 15:07:54,334 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FileInputDStream: metadataCleanupDelay = -1

2016-08-25 15:07:54,334 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FileInputDStream: Slide time = 5000 ms

2016-08-25 15:07:54,335 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FileInputDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:07:54,335 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FileInputDStream: Checkpoint interval = null

2016-08-25 15:07:54,335 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FileInputDStream: Remember duration = 60000 ms

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@5f780a86

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.MappedDStream: Slide time = 5000 ms

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.MappedDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.MappedDStream: Checkpoint interval = null

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.MappedDStream: Remember duration = 5000 ms

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@4c4bb38e

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FlatMappedDStream: Slide time = 5000 ms

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FlatMappedDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FlatMappedDStream: Checkpoint interval = null

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FlatMappedDStream: Remember duration = 5000 ms

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.FlatMappedDStream: Initialized and validated org.apache.spark.streaming.dstream.FlatMappedDStream@1a0bbbf

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.MappedDStream: Slide time = 5000 ms

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.MappedDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.MappedDStream: Checkpoint interval = null

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.MappedDStream: Remember duration = 5000 ms

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@259d64ca

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.ShuffledDStream: Slide time = 5000 ms

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.ShuffledDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.ShuffledDStream: Checkpoint interval = null

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.ShuffledDStream: Remember duration = 5000 ms

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@123d82a1

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.ForEachDStream: Slide time = 5000 ms

2016-08-25 15:07:54,336 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.ForEachDStream: Storage level = StorageLevel(false, false, false, false, 1)

2016-08-25 15:07:54,337 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.ForEachDStream: Checkpoint interval = null

2016-08-25 15:07:54,337 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.ForEachDStream: Remember duration = 5000 ms

2016-08-25 15:07:54,337 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO dstream.ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@37b84ab

2016-08-25 15:07:54,365 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO util.RecurringTimer: Started timer for JobGenerator at time 1472108875000

2016-08-25 15:07:54,366 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO scheduler.JobGenerator: Started JobGenerator at 1472108875000 ms

2016-08-25 15:07:54,366 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO scheduler.JobScheduler: Started JobScheduler

2016-08-25 15:07:54,370 - [INFO] - from application in Thread-381 
16/08/25 15:07:54 INFO streaming.StreamingContext: StreamingContext started

2016-08-25 15:07:55,010 - [INFO] - from application in Thread-379 
16/08/25 15:07:55 INFO dstream.FileInputDStream: Finding new files took 4 ms

2016-08-25 15:07:55,010 - [INFO] - from application in Thread-379 
16/08/25 15:07:55 INFO dstream.FileInputDStream: New files at time 1472108875000 ms:

2016-08-25 15:07:55,010 - [INFO] - from application in Thread-379 


2016-08-25 15:07:55,020 - [INFO] - from application in Thread-379 
16/08/25 15:07:55 INFO scheduler.JobScheduler: Added jobs for time 1472108875000 ms

2016-08-25 15:07:55,948 - [INFO] - from application in Thread-381 
16/08/25 15:07:55 INFO dstream.FileInputDStream: Finding new files took 931 ms

2016-08-25 15:07:55,950 - [INFO] - from application in Thread-381 
16/08/25 15:07:55 INFO dstream.FileInputDStream: New files at time 1472108875000 ms:

2016-08-25 15:07:55,950 - [INFO] - from application in Thread-381 


2016-08-25 15:07:55,974 - [INFO] - from application in Thread-381 
16/08/25 15:07:55 INFO scheduler.JobScheduler: Added jobs for time 1472108875000 ms

2016-08-25 15:07:55,975 - [INFO] - from application in Thread-381 
16/08/25 15:07:55 INFO scheduler.JobScheduler: Starting job streaming job 1472108875000 ms.0 from job set of time 1472108875000 ms

2016-08-25 15:07:56,007 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO spark.SparkContext: Starting job: print at HDFSWordCount.scala:20

2016-08-25 15:07:56,023 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO scheduler.DAGScheduler: Registering RDD 3 (map at HDFSWordCount.scala:17)

2016-08-25 15:07:56,025 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO scheduler.DAGScheduler: Got job 0 (print at HDFSWordCount.scala:20) with 1 output partitions

2016-08-25 15:07:56,025 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO scheduler.DAGScheduler: Final stage: ResultStage 1(print at HDFSWordCount.scala:20)

2016-08-25 15:07:56,026 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)

2016-08-25 15:07:56,028 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO scheduler.DAGScheduler: Missing parents: List()

2016-08-25 15:07:56,035 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at HDFSWordCount.scala:18), which has no missing parents

2016-08-25 15:07:56,136 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO storage.MemoryStore: ensureFreeSpace(2344) called with curMem=0, maxMem=1111511531

2016-08-25 15:07:56,137 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1060.0 MB)

2016-08-25 15:07:56,146 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO storage.MemoryStore: ensureFreeSpace(1435) called with curMem=2344, maxMem=1111511531

2016-08-25 15:07:56,147 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1435.0 B, free 1060.0 MB)

2016-08-25 15:07:56,151 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.236.66.144:52339 (size: 1435.0 B, free: 1060.0 MB)

2016-08-25 15:07:56,153 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861

2016-08-25 15:07:56,157 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at HDFSWordCount.scala:18)

2016-08-25 15:07:56,158 - [INFO] - from application in Thread-381 
16/08/25 15:07:56 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks

2016-08-25 15:08:00,055 - [INFO] - from application in Thread-379 
16/08/25 15:08:00 INFO dstream.FileInputDStream: Finding new files took 48 ms

2016-08-25 15:08:00,056 - [INFO] - from application in Thread-379 
16/08/25 15:08:00 INFO dstream.FileInputDStream: New files at time 1472108880000 ms:

2016-08-25 15:08:00,056 - [INFO] - from application in Thread-379 


2016-08-25 15:08:00,056 - [INFO] - from application in Thread-381 
16/08/25 15:08:00 INFO dstream.FileInputDStream: Finding new files took 47 ms

2016-08-25 15:08:00,056 - [INFO] - from application in Thread-381 
16/08/25 15:08:00 INFO dstream.FileInputDStream: New files at time 1472108880000 ms:

2016-08-25 15:08:00,056 - [INFO] - from application in Thread-381 


2016-08-25 15:08:00,062 - [INFO] - from application in Thread-379 
16/08/25 15:08:00 INFO scheduler.JobScheduler: Added jobs for time 1472108880000 ms

2016-08-25 15:08:00,065 - [INFO] - from application in Thread-381 
16/08/25 15:08:00 INFO scheduler.JobScheduler: Added jobs for time 1472108880000 ms

2016-08-25 15:08:00,728 - [INFO] - from application in Thread-379 
16/08/25 15:08:00 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:08:05,012 - [INFO] - from application in Thread-379 
16/08/25 15:08:05 INFO dstream.FileInputDStream: Finding new files took 6 ms

2016-08-25 15:08:05,012 - [INFO] - from application in Thread-379 
16/08/25 15:08:05 INFO dstream.FileInputDStream: New files at time 1472108885000 ms:

2016-08-25 15:08:05,013 - [INFO] - from application in Thread-379 


2016-08-25 15:08:05,015 - [INFO] - from application in Thread-381 
16/08/25 15:08:05 INFO dstream.FileInputDStream: Finding new files took 9 ms

2016-08-25 15:08:05,015 - [INFO] - from application in Thread-381 
16/08/25 15:08:05 INFO dstream.FileInputDStream: New files at time 1472108885000 ms:

2016-08-25 15:08:05,015 - [INFO] - from application in Thread-381 


2016-08-25 15:08:05,019 - [INFO] - from application in Thread-379 
16/08/25 15:08:05 INFO scheduler.JobScheduler: Added jobs for time 1472108885000 ms

2016-08-25 15:08:05,022 - [INFO] - from application in Thread-381 
16/08/25 15:08:05 INFO scheduler.JobScheduler: Added jobs for time 1472108885000 ms

2016-08-25 15:08:10,117 - [INFO] - from application in Thread-379 
16/08/25 15:08:10 INFO dstream.FileInputDStream: Finding new files took 112 ms

2016-08-25 15:08:10,117 - [INFO] - from application in Thread-379 
16/08/25 15:08:10 INFO dstream.FileInputDStream: New files at time 1472108890000 ms:

2016-08-25 15:08:10,117 - [INFO] - from application in Thread-379 


2016-08-25 15:08:10,123 - [INFO] - from application in Thread-379 
16/08/25 15:08:10 INFO scheduler.JobScheduler: Added jobs for time 1472108890000 ms

2016-08-25 15:08:11,168 - [INFO] - from application in Thread-381 
16/08/25 15:08:11 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:08:13,215 - [INFO] - from application in Thread-381 
16/08/25 15:08:13 INFO dstream.FileInputDStream: Finding new files took 3211 ms

2016-08-25 15:08:13,215 - [INFO] - from application in Thread-381 
16/08/25 15:08:13 INFO dstream.FileInputDStream: New files at time 1472108890000 ms:

2016-08-25 15:08:13,215 - [INFO] - from application in Thread-381 


2016-08-25 15:08:13,220 - [INFO] - from application in Thread-381 
16/08/25 15:08:13 INFO scheduler.JobScheduler: Added jobs for time 1472108890000 ms

2016-08-25 15:08:15,076 - [INFO] - from application in Thread-379 
16/08/25 15:08:15 INFO dstream.FileInputDStream: Finding new files took 70 ms

2016-08-25 15:08:15,076 - [INFO] - from application in Thread-379 
16/08/25 15:08:15 INFO dstream.FileInputDStream: New files at time 1472108895000 ms:

2016-08-25 15:08:15,076 - [INFO] - from application in Thread-379 


2016-08-25 15:08:15,076 - [INFO] - from application in Thread-381 
16/08/25 15:08:15 INFO dstream.FileInputDStream: Finding new files took 70 ms

2016-08-25 15:08:15,076 - [INFO] - from application in Thread-381 
16/08/25 15:08:15 INFO dstream.FileInputDStream: New files at time 1472108895000 ms:

2016-08-25 15:08:15,076 - [INFO] - from application in Thread-381 


2016-08-25 15:08:15,083 - [INFO] - from application in Thread-381 
16/08/25 15:08:15 INFO scheduler.JobScheduler: Added jobs for time 1472108895000 ms

2016-08-25 15:08:15,084 - [INFO] - from application in Thread-379 
16/08/25 15:08:15 INFO scheduler.JobScheduler: Added jobs for time 1472108895000 ms

2016-08-25 15:08:15,727 - [INFO] - from application in Thread-379 
16/08/25 15:08:15 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

2016-08-25 15:08:20,704 - [INFO] - from application in Thread-379 
16/08/25 15:08:20 INFO dstream.FileInputDStream: Finding new files took 699 ms

2016-08-25 15:08:20,704 - [INFO] - from application in Thread-379 
16/08/25 15:08:20 INFO dstream.FileInputDStream: New files at time 1472108900000 ms:

2016-08-25 15:08:20,704 - [INFO] - from application in Thread-379 


2016-08-25 15:08:20,704 - [INFO] - from application in Thread-381 
16/08/25 15:08:20 INFO dstream.FileInputDStream: Finding new files took 700 ms

2016-08-25 15:08:20,704 - [INFO] - from application in Thread-381 
16/08/25 15:08:20 INFO dstream.FileInputDStream: New files at time 1472108900000 ms:

2016-08-25 15:08:20,704 - [INFO] - from application in Thread-381 


2016-08-25 15:08:20,712 - [INFO] - from application in Thread-379 
16/08/25 15:08:20 INFO scheduler.JobScheduler: Added jobs for time 1472108900000 ms

2016-08-25 15:08:20,714 - [INFO] - from application in Thread-381 
16/08/25 15:08:20 INFO scheduler.JobScheduler: Added jobs for time 1472108900000 ms

