###########  spark&hadoop 配置 #########

spark.home="/usr/local/spark/"

#spark 提交集群master地址
spark.master.url ="10.75.16.220:7077"

#spark rest api 地址
#spark.master.host="10.77.136.159:8080"

#spark rest api
spark.master.host="10.77.136.159:8080"

#yarn rest api 地址
hadoop.yarn.host="10.77.136.159:8088"

#全局IP
spark.host.ha1="10.77.136.159"
spark.host.ha2="10.77.136.160"


########## 任务运行配置 ##########

#task状态更新间隔
#毫秒
task.data-update.interval-ms = 5000

#task 最大启动线程数
task.pool.max = 20

# jar文件保存路径
job.upload.path="/tmp/file/"

# 文件上传超时时间
# 秒
job.upload.timeout.seconds= 100

# 任务提交超时时间
#秒
job.submit.timeout.seconds = 300

#初始化任务参数超时时间
#秒
job.request.timeout.seconds = 50

##### 邮箱配置 ########
email.server.host="smtp.sina.com"
email.default.username="server_noreplay@sina.com"
email.default.password="adminadmin"
email.default.port=25

#接收邮件地址,部署的主机地址
email.default.host="neptunespark.mars.grid.sina.com.cn:9000"
#联系管理员邮箱
email.default.admin="jiazheng1@staff.weibo.com"

#spark sql 文件生成目录
spark.sql.file="/tmp"




